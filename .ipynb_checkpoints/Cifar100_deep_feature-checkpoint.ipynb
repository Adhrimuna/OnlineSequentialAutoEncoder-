{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10 # Keras CIFAR10 dataset\n",
    "#from tqdm import tqdm_notebook as tqdm # Jupyter notebook should use this\n",
    "import vgg16 as vgg16 # modified from  https://www.cs.toronto.edu/~frossard/post/vgg16/\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # choose which GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (50000, 32, 32, 3)\n",
      "Train label shape:  (50000, 10)\n",
      "Test data shape:  (50000, 32, 32, 3)\n",
      "Test label shape:  (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load data\"\"\"\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\"\"\"Convert to one-hot labels\"\"\"\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\"\"\"Display\"\"\"\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train label shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_train.shape)\n",
    "print('Test label shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:  conv1_1_W (3, 3, 3, 64)\n",
      "loading:  conv1_1_b (64,)\n",
      "loading:  conv1_2_W (3, 3, 64, 64)\n",
      "loading:  conv1_2_b (64,)\n",
      "loading:  conv2_1_W (3, 3, 64, 128)\n",
      "loading:  conv2_1_b (128,)\n",
      "loading:  conv2_2_W (3, 3, 128, 128)\n",
      "loading:  conv2_2_b (128,)\n",
      "loading:  conv3_1_W (3, 3, 128, 256)\n",
      "loading:  conv3_1_b (256,)\n",
      "loading:  conv3_2_W (3, 3, 256, 256)\n",
      "loading:  conv3_2_b (256,)\n",
      "loading:  conv3_3_W (3, 3, 256, 256)\n",
      "loading:  conv3_3_b (256,)\n",
      "loading:  conv4_1_W (3, 3, 256, 512)\n",
      "loading:  conv4_1_b (512,)\n",
      "loading:  conv4_2_W (3, 3, 512, 512)\n",
      "loading:  conv4_2_b (512,)\n",
      "loading:  conv4_3_W (3, 3, 512, 512)\n",
      "loading:  conv4_3_b (512,)\n",
      "loading:  conv5_1_W (3, 3, 512, 512)\n",
      "loading:  conv5_1_b (512,)\n",
      "loading:  conv5_2_W (3, 3, 512, 512)\n",
      "loading:  conv5_2_b (512,)\n",
      "loading:  conv5_3_W (3, 3, 512, 512)\n",
      "loading:  conv5_3_b (512,)\n",
      "loading:  fc6_W (25088, 4096)\n",
      "loading:  fc6_b (4096,)\n",
      "loading:  fc7_W (4096, 4096)\n",
      "loading:  fc7_b (4096,)\n",
      "loading:  fc8_W (4096, 1000)\n",
      "loading:  fc8_b (1000,)\n",
      "Imagenet pre-trained VGG16-weights loaded\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "X_224 = tf.image.resize_bicubic(X, [224,224]) # Bicubic interpolation\n",
    "#vgg16_modified = vgg16.vgg16(X)\n",
    "VGG16_modified = vgg16.vgg16(X_224, use_bias_in_fc=False) # Give our resized CIFAR10 to VGG16\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"get fc1 from VGG16\"\"\"\n",
    "fc1 = VGG16_modified.get_fc1()\n",
    "\n",
    "DEEP_FEATURE_LAYER = VGG16_modified.get_fc1()\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#vgg16_model = vgg16.vgg16_modified(X)\n",
    "#parameters = vgg16_model.get_architecture()\n",
    "#DEEP_FEATURE_LAYER = vgg16_model.get_deep_feature()\n",
    "\n",
    "VGG16_architecture = VGG16_modified.get_architecture()\n",
    "weights = np.load('vgg16_weights.npz')\n",
    "keys = sorted(weights.keys())\n",
    "for i, v in enumerate(keys):\n",
    "    try:\n",
    "        sess.run(VGG16_architecture[i].assign(weights[v]))\n",
    "        print(str('loading: '), v, np.shape(weights[v]))\n",
    "    except:\n",
    "        break       \n",
    "print('Imagenet pre-trained VGG16-weights loaded')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(4096)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEEP_FEATURE_LAYER.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x = []\n",
    "df_test_x = []\n",
    "for x in x_train:\n",
    "    df = sess.run(DEEP_FEATURE_LAYER, feed_dict={X: [x]})\n",
    "    df_train_x.append(df[0])\n",
    "for x in x_test:\n",
    "    df = sess.run(DEEP_FEATURE_LAYER, feed_dict={X: [x]})\n",
    "    df_test_x.append(df[0])\n",
    "df_train_x = np.array(df_train_x)\n",
    "df_test_x = np.array(df_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save numpy array to file'''\n",
    "np.save(arr=df_train_x, file='train_x_deep_feature')\n",
    "np.save(arr=y_train, file='train_y_labels')\n",
    "np.save(arr=df_test_x, file='test_x_deep_feature')\n",
    "np.save(arr=y_test, file='test_y_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "df_train_x = []\n",
    "df_test_x = []\n",
    "EPOCHS = 1  # total number of training epochs\n",
    "epoch = 0\n",
    "total_steps = int(len(x_train)/BATCH_SIZE)\n",
    "loss_value = 0\n",
    "for step in range(total_steps):\n",
    "    #get training batch\n",
    "    if step*BATCH_SIZE + BATCH_SIZE < len(x_train):\n",
    "        BATCH_X = x_train[step*BATCH_SIZE: step*BATCH_SIZE+BATCH_SIZE]\n",
    "        BATCH_Y = y_train[step*BATCH_SIZE: step*BATCH_SIZE+BATCH_SIZE]\n",
    "    else:\n",
    "        BATCH_X = x_train[step*BATCH_SIZE:]\n",
    "        BATCH_Y = y_train[step*BATCH_SIZE:]\n",
    "    #train\n",
    "    df = sess.run(DEEP_FEATURE_LAYER, feed_dict={X: BATCH_X})\n",
    "    df_train_x = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
