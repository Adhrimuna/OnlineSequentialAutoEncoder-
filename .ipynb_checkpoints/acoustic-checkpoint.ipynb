{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adhrimuna/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from auto_elm import AUTO_ELM \n",
    "from os_MFB1 import MFB_ELM \n",
    "# Our proposed algorithm\n",
    "import pandas as pd \n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm # Jupyter notebook should use this\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import scipy.io as scipy_io\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a, axis=-1).reshape(-1, 1)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a, axis=-1).reshape(-1, 1)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def sigmoid(x):\n",
    "    '''input x should be a 1D array!'''\n",
    "    for i in range(len(x)):\n",
    "        x[i] = 1/(1+math.e**(-x[i]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 '1:-0.962576' '2:-0.960422' ... '49:-0.939076' '50:-0.972626' nan]\n",
      " [3 '1:-0.735629' '2:-0.113086' ... '49:-0.99538' '50:-0.993334' nan]\n",
      " [3 '1:-0.981124' '2:-0.968923' ... '49:-0.996101' '50:-0.995813' nan]\n",
      " ...\n",
      " [1 '1:-0.996812' '2:-0.990494' ... '49:-0.937852' '50:-0.939699' nan]\n",
      " [1 '1:-0.995711' '2:-0.983737' ... '49:-0.999353' '50:-0.998983' nan]\n",
      " [3 '1:-0.987073' '2:-0.992241' ... '49:-0.993805' '50:-0.991061' nan]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.array(pd.read_csv(\"UCI dataset/acoustic_scale\", header = None,delimiter=' '))\n",
    "test_dataset = np.array(pd.read_csv(\"UCI dataset/acoustic_scale.t\",header = None, delimiter=' '))\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [1]\n",
      " [2]\n",
      " [2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adhrimuna/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype <U12 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00685638e-01 3.20959944e-01 2.68426627e-01 ... 4.56000000e-04\n",
      "  8.16274714e-04 4.60000000e-04]\n",
      " [2.71507465e-01 5.02411141e-01 1.87505898e-01 ... 1.25150000e-03\n",
      "  1.49056440e-03 1.24800000e-03]\n",
      " [3.15320505e-02 8.35403759e-03 3.85195956e-02 ... 1.29050000e-03\n",
      "  1.60916366e-03 1.42550000e-03]\n",
      " ...\n",
      " [3.06402995e-03 2.79746259e-02 1.80337022e-02 ... 2.16500000e-03\n",
      "  2.93992530e-03 1.52500000e-03]\n",
      " [2.12955918e-01 3.85491235e-01 3.57333981e-01 ... 5.61000000e-04\n",
      "  6.12484437e-04 6.17000000e-04]\n",
      " [3.39454118e-01 4.91604712e-01 4.40571928e-02 ... 9.46000000e-04\n",
      "  5.35088677e-04 5.36500000e-04]]\n"
     ]
    }
   ],
   "source": [
    "label = train_dataset[:,0]\n",
    "data = train_dataset[:,1:51]\n",
    "\n",
    "label = label.reshape(label.shape[0], 1)\n",
    "\n",
    "label1 = np.where(label==1, 0, label)\n",
    "label1 = np.where(label1==2, 1, label1)\n",
    "label1 = np.where(label1==3, 2, label1)\n",
    "print(label1)\n",
    "\n",
    "data1 = []\n",
    "for i in data:\n",
    "    data2 = []\n",
    "    for j in i:\n",
    "        [_, value] = j.split(\":\")\n",
    "        data2.append(value)\n",
    "    data1.append(data2)\n",
    "\n",
    "    \n",
    "data = np.array(data1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "print(data)\n",
    "data = np.concatenate((label1, data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78823, 51)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 50)\n",
      "(18823, 50)\n",
      "(60000,)\n",
      "(18823,)\n"
     ]
    }
   ],
   "source": [
    "x_train = data[0:60000,1:]\n",
    "y_train = data[0:60000,0]\n",
    "x_test = data[60000:,1:]\n",
    "y_test = data[60000:,0]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, classes):\n",
    "    I = np.eye(classes)\n",
    "    #print(I)\n",
    "    ret = []\n",
    "    l = 0\n",
    "    for y_ in y:\n",
    "        ret.append(I[y_])\n",
    "            \n",
    "    return np.array(ret)\n",
    "    \n",
    "y_train_onehot = one_hot(y_train, 3)\n",
    "y_test_onehot = one_hot(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total initial:  10000\n",
      "total sequential:  50000\n",
      "total testing:  18823\n"
     ]
    }
   ],
   "source": [
    "border = 10000\n",
    "x_train_init = x_train[:border]\n",
    "x_train_seq = x_train[border:]\n",
    "\n",
    "print('total initial: ', (border))\n",
    "print('total sequential: ', len(x_train_seq))\n",
    "print('total testing: ', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_nodes = 50\n",
    "n_hidden_nodes = 10  # used to be 6\n",
    "n_output_nodes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# ===========================================\n",
    "# Instantiate os-elm\n",
    "# ===========================================\n",
    "auto_elm = AUTO_ELM(\n",
    "    # the number of input nodes.\n",
    "    n_input_nodes=n_input_nodes,\n",
    "    # the number of hidden nodes.\n",
    "    n_hidden_nodes=n_hidden_nodes,\n",
    "    # the number of output nodes.\n",
    "    n_output_nodes=n_output_nodes,\n",
    "    # loss function.\n",
    "    # the default value is 'mean_squared_error'.\n",
    "    # for the other functions, we support\n",
    "    # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "    c_value = 2.0**(-3),\n",
    "    loss='mean_squared_error',\n",
    "    # activation function applied to the hidden nodes.\n",
    "    # the default value is 'sigmoid'.\n",
    "    # for the other functions, we support 'linear' and 'tanh'.\n",
    "    # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "    activation='sin',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.003501, train_accuracy: 0.671944\n",
      "test_loss: 0.003449, test_accuracy: 0.671944\n"
     ]
    }
   ],
   "source": [
    "auto_elm.init_train(x_train_init, x_train_init)\n",
    "\n",
    "import time\n",
    "\n",
    "'''initial training evaluation'''\n",
    "t1 = time.time()\n",
    "[train_loss, accuracy] = auto_elm.evaluate(x_train_init, x_train_init, metrics=['loss', 'accuracy'])\n",
    "[test_loss, accuracy] = auto_elm.evaluate(x_test, x_test, metrics=['loss', 'accuracy'])\n",
    "print('train_loss: %f, train_accuracy: %f' % (train_loss, accuracy))\n",
    "print('test_loss: %f, test_accuracy: %f' % (test_loss, accuracy))\n",
    "t2 = time.time()\n",
    "\n",
    "epoch_train_loss = []\n",
    "epoch_test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad61e0dfa4e0442081163db668a165c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001411, train_accuracy: 0.655422\n",
      "test_loss: 0.001373, test_accuracy: 0.655422\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4217d53f558c4c028fcc1242dcb42150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001251, train_accuracy: 0.679913\n",
      "test_loss: 0.001214, test_accuracy: 0.679913\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c75c52d677456b83abc7e6ba01c8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001177, train_accuracy: 0.696595\n",
      "test_loss: 0.001140, test_accuracy: 0.696595\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc4e78a2dde4892b6e47863caace7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001146, train_accuracy: 0.706954\n",
      "test_loss: 0.001109, test_accuracy: 0.706954\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d2ab09702b458fbe56b11be2d4636f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001131, train_accuracy: 0.710886\n",
      "test_loss: 0.001094, test_accuracy: 0.710886\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f36db560754469b5b257d87d95f462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001122, train_accuracy: 0.713436\n",
      "test_loss: 0.001085, test_accuracy: 0.713436\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453ce4f26b974213af604bba45559b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001115, train_accuracy: 0.714658\n",
      "test_loss: 0.001077, test_accuracy: 0.714658\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013a25f3c5594f5baa3c539ec5392d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001108, train_accuracy: 0.716092\n",
      "test_loss: 0.001070, test_accuracy: 0.716092\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1ef33b9c744ed78e53a78ad7ad8653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001101, train_accuracy: 0.717420\n",
      "test_loss: 0.001062, test_accuracy: 0.717420\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c09f1cdb17d4e949427e289ca59fabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequential training phase', max=50000, style=ProgressStyle(description_width='initial')), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.001092, train_accuracy: 0.718908\n",
      "test_loss: 0.001054, test_accuracy: 0.718908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    pbar = tqdm(total=len(x_train_seq), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        auto_elm.seq_train(x_batch, x_batch)\n",
    "        pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, accuracy] = auto_elm.evaluate(x_train_init, x_train_init, metrics=['loss', 'accuracy'])\n",
    "    [test_loss, accuracy] = auto_elm.evaluate(x_test, x_test, metrics=['loss', 'accuracy'])\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, accuracy))\n",
    "    epoch_train_loss.append(train_loss)\n",
    "    epoch_test_loss.append(test_loss)\n",
    "\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(18823, 10)\n",
      "(60000,)\n",
      "(18823,)\n"
     ]
    }
   ],
   "source": [
    "x_train_encoded = auto_elm.encoding(x_train)\n",
    "x_test_encoded = auto_elm.encoding(x_test)\n",
    "\n",
    "\n",
    "print(x_train_encoded.shape)\n",
    "print(x_test_encoded.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_nodes = 10\n",
    "n_hidden_nodes = 1  # used to be 256\n",
    "n_output_nodes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "border = 30000\n",
    "x_train_init = x_train_encoded[:border]\n",
    "y_train_init = y_train_onehot[:border]\n",
    "x_train_seq = x_train_encoded[border:]\n",
    "y_train_seq = y_train_onehot[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from os_MFB1 import MFB_ELM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(?, 3)\n",
      "0\n",
      "Tensor(\"Assign_10:0\", shape=(), dtype=bool_ref)\n"
     ]
    }
   ],
   "source": [
    "C = 4\n",
    "mfb_elm = MFB_ELM(\n",
    "    # the number of input nodes.\n",
    "    n_input_nodes=n_input_nodes,\n",
    "    # the number of hidden nodes.\n",
    "    n_hidden_nodes=n_hidden_nodes,\n",
    "    # the number of output nodes.\n",
    "    n_output_nodes=n_output_nodes,\n",
    "    #C = C,\n",
    "    # loss function.\n",
    "    # the default value is 'mean_squared_error'.\n",
    "    # for the other functions, we support\n",
    "    # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "    loss='mean_squared_error',\n",
    "    # activation function applied to the hidden nodes.\n",
    "    # the default value is 'sigmoid'.\n",
    "    # for the other functions, we support 'linear' and 'tanh'.\n",
    "    # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "    activation='sin',\n",
    "    C = C\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.171107, train_accuracy: 0.669394\n",
      "test_loss: 0.170507, test_accuracy: 0.671200\n"
     ]
    }
   ],
   "source": [
    "mfb_elm.init_train(x_train_init, y_train_init)\n",
    "\n",
    "'''initial training evaluation'''\n",
    "[train_loss, train_accuracy] = mfb_elm.evaluate(x_train_encoded[:len(x_test_encoded)], y_train_onehot[:len(x_test_encoded)], metrics=['loss', 'accuracy'])\n",
    "[test_loss, test_accuracy] = mfb_elm.evaluate(x_test_encoded, y_test_onehot, metrics=['loss', 'accuracy'])\n",
    "print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    \n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        mfb_elm.seq_train(x_batch, y_batch)\n",
    "       # pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = mfb_elm.evaluate(x_train_encoded, y_train_onehot, metrics=['loss', 'accuracy'])\n",
    "    [test_loss, test_accuracy] = mfb_elm.evaluate(x_test_encoded, y_test_onehot, metrics=['loss', 'accuracy'])\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03155266 -0.09847658  0.8773411 ]\n",
      " [ 0.59656423  0.153546    0.30241793]\n",
      " [ 0.533619    0.06958039  0.34604353]\n",
      " ...\n",
      " [ 0.17493562  0.02434713  0.7637784 ]\n",
      " [-0.12744384 -0.09191735  0.9056508 ]\n",
      " [-0.18651065  0.02194001  0.90021384]]\n",
      "0.6473463316155766\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(mfb_elm.predict(x_test_encoded), axis=1)\n",
    "l = mfb_elm.predict(x_test_encoded)\n",
    "print(l)\n",
    "print(np.sum(np.equal(pred, np.argmax(y_test_onehot,axis=1)))/len(y_test_onehot))\n",
    "print(y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.075071\n",
      "test_acc: 0.673697\n",
      "==========================================\n",
      "OS-ELA ===================================\n",
      "==========================================\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "from ELM import ELM \n",
    "tf.reset_default_graph()\n",
    "# ===========================================\n",
    "# Instantiate os-elm\n",
    "# ===========================================\n",
    "\n",
    "    \n",
    "def one_hot(y, classes):\n",
    "    I = np.eye(classes)\n",
    "    ret = []\n",
    "    for y_ in y:\n",
    "        ret.append(I[y_])\n",
    "    return np.array(ret)\n",
    "    \n",
    "#y_train_onehot = one_hot(y_train, 6)\n",
    "#y_test_onehot = one_hot(y_test, 6)\n",
    "    \n",
    "model = ELM(n_input_nodes=10,\n",
    "                    n_hidden_nodes=10,\n",
    "                    n_output_nodes=3,\n",
    "                    loss='mean_squared_error',\n",
    "                    activation='sigmoid',\n",
    "                    name='elm',\n",
    "                    )\n",
    "   \n",
    "feature_train = auto_elm.encoding(x_train)\n",
    "feature_test = auto_elm.encoding(x_test)\n",
    "\n",
    "model.fit(feature_train, y_train_onehot)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(feature_test, y_test_onehot, metrics=['loss', 'accuracy'])\n",
    "print('test_loss: %f' % test_loss)\n",
    "print('test_acc: %f' % test_acc)\n",
    "#accuracy_sum+=test_acc\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(\"==========================================\")\n",
    "print(\"OS-ELA ===================================\")\n",
    "print(\"==========================================\")\n",
    "#print(\"Average time: \", time_sum/10.0)\n",
    "#print(\"Average accuracy: \", accuracy_sum/10.0)\n",
    "print(\"==========================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (18823,) (18823,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8e8b79626100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (18823,) (18823,3) "
     ]
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(feature_test),axis=1)\n",
    "test_accuracy = np.sum(np.equal(pred, y_test_onehot))/len(pred)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.87)\n",
    "pca.fit(x_train)\n",
    "train_img = pca.transform(x_train)\n",
    "test_img  = pca.transform(x_test)\n",
    "train_img.shape,test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ELM import ELM \n",
    "tf.reset_default_graph()\n",
    "# ===========================================\n",
    "# Instantiate os-elm\n",
    "# ===========================================\n",
    "\n",
    "    \n",
    "def one_hot(y, classes):\n",
    "    I = np.eye(classes)\n",
    "    ret = []\n",
    "    for y_ in y:\n",
    "        ret.append(I[y_])\n",
    "    return np.array(ret)\n",
    "    \n",
    "#y_train_onehot = one_hot(y_train, 6)\n",
    "#y_test_onehot = one_hot(y_test, 6)\n",
    "    \n",
    "model = ELM(n_input_nodes=10,\n",
    "                    n_hidden_nodes=10,\n",
    "                    n_output_nodes=3,\n",
    "                    loss='mean_squared_error',\n",
    "                    activation='sigmoid',\n",
    "                    name='elm',\n",
    "                    )\n",
    "   \n",
    "feature_train = train_img\n",
    "feature_test = test_img\n",
    "\n",
    "model.fit(feature_train, y_train_onehot)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(feature_test, y_test_onehot, metrics=['loss', 'accuracy'])\n",
    "print('test_loss: %f' % test_loss)\n",
    "print('test_acc: %f' % test_acc)\n",
    "#accuracy_sum+=test_acc\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(\"==========================================\")\n",
    "print(\"OS-ELA ===================================\")\n",
    "print(\"==========================================\")\n",
    "#print(\"Average time: \", time_sum/10.0)\n",
    "#print(\"Average accuracy: \", accuracy_sum/10.0)\n",
    "print(\"==========================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border = 30000\n",
    "x_train_init = feature_train[:border]\n",
    "y_train_init = y_train_onehot[:border]\n",
    "x_train_seq = feature_train[border:]\n",
    "y_train_seq = y_train_onehot[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from os_MFB1 import MFB_ELM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(?, 3)\n",
      "0\n",
      "Tensor(\"Assign_10:0\", shape=(), dtype=bool_ref)\n"
     ]
    }
   ],
   "source": [
    "C = 4\n",
    "mfb_elm = MFB_ELM(\n",
    "    # the number of input nodes.\n",
    "    n_input_nodes=n_input_nodes,\n",
    "    # the number of hidden nodes.\n",
    "    n_hidden_nodes=n_hidden_nodes,\n",
    "    # the number of output nodes.\n",
    "    n_output_nodes=n_output_nodes,\n",
    "    #C = C,\n",
    "    # loss function.\n",
    "    # the default value is 'mean_squared_error'.\n",
    "    # for the other functions, we support\n",
    "    # 'mean_absolute_error', 'categorical_crossentropy', and 'binary_crossentropy'.\n",
    "    loss='mean_squared_error',\n",
    "    # activation function applied to the hidden nodes.\n",
    "    # the default value is 'sigmoid'.\n",
    "    # for the other functions, we support 'linear' and 'tanh'.\n",
    "    # NOTE: OS-ELM can apply an activation function only to the hidden nodes.\n",
    "    activation='sin',\n",
    "    C = C\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.171107, train_accuracy: 0.669394\n",
      "test_loss: 0.170507, test_accuracy: 0.671200\n"
     ]
    }
   ],
   "source": [
    "mfb_elm.init_train(x_train_init, y_train_init)\n",
    "\n",
    "'''initial training evaluation'''\n",
    "[train_loss, train_accuracy] = mfb_elm.evaluate(feature_train[:len(feature_test)], y_train_onehot[:len(feature_test)], metrics=['loss', 'accuracy'])\n",
    "[test_loss, test_accuracy] = mfb_elm.evaluate(feature_test, y_test_onehot, metrics=['loss', 'accuracy'])\n",
    "print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    \n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n",
      "train_loss: 0.158751, train_accuracy: 0.647683\n",
      "test_loss: 0.158645, test_accuracy: 0.647346\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        mfb_elm.seq_train(x_batch, y_batch)\n",
    "       # pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = mfb_elm.evaluate(feature_train, y_train_onehot, metrics=['loss', 'accuracy'])\n",
    "    [test_loss, test_accuracy] = mfb_elm.evaluate(feature_test, y_test_onehot, metrics=['loss', 'accuracy'])\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.105619\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.110535\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.113368\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.099772\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.087720\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.090152\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.085707\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.087215\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.080349\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.082993\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.240024\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.239577\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.243350\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.246762\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.247519\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.240296\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "#from sklearn.datasets import load_digits\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "\n",
    "from dbn.tensorflow import SupervisedDBNClassification\n",
    "\n",
    "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
    "                                         learning_rate_rbm=0.05,\n",
    "                                         learning_rate=0.01,\n",
    "                                         n_epochs_rbm=10,\n",
    "                                         n_iter_backprop=100,\n",
    "                                         batch_size=32,\n",
    "                                         activation_function='relu',\n",
    "                                         dropout_p=0.2)\n",
    "classifier.fit(x_train, y_train)\n",
    "Y_pred = classifier.predict(x_test)\n",
    "print('Done.\\nAccuracy: %f' % accuracy_score(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
