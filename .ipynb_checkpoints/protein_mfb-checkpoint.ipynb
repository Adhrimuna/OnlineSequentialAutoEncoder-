{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import mnist_handler\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"; \n",
    "INPUT_DIMENSION = 180\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "def process_data(fname, NUM_ATTR, NUM_CLASSES):\n",
    "    I = np.eye(NUM_CLASSES)\n",
    "    with open(fname) as file:\n",
    "        xx = file.readlines()\n",
    "        data = np.zeros([len(xx), NUM_ATTR])\n",
    "        label = np.zeros(len(xx), dtype=int)\n",
    "        label_onehot = []\n",
    "        for i in range(len(xx)):\n",
    "            tmp = xx[i].split(' ')\n",
    "            label[i] = int(tmp[0])-1\n",
    "            label_onehot.append(I[label[i]])\n",
    "            for j in range(1,len(tmp)-1):\n",
    "                position = int(tmp[j].split(':')[0])\n",
    "                value = 1.0*int(tmp[j].split(':')[1])\n",
    "                data[i][position-1] = value \n",
    "    return data, label, np.array(label_onehot, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_file = 'UCI dataset/DNA'\n",
    "ts_file = 'UCI dataset/DNAt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tr_label, tr_onehot = process_data(tr_file, NUM_ATTR=180, NUM_CLASSES=3)\n",
    "ts_data, ts_label, ts_onehot = process_data(ts_file, NUM_ATTR=180, NUM_CLASSES=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1186, 180)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tr_data*0.01\n",
    "y_train = tr_label\n",
    "x_test = ts_data*0.01\n",
    "y_test = ts_label\n",
    "x_train\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.savetxt(\"x_train.csv\", x_train, delimiter=\",\")\n",
    "np.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
    "np.savetxt(\"x_test.csv\", x_test, delimiter=\",\")\n",
    "np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "border = 100\n",
    "x_train_init = x_train[:border]\n",
    "y_train_init = y_train[:border]\n",
    "x_train_seq = x_train[border:]\n",
    "y_train_seq = y_train[border:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(0.55)\n",
    "time_sum = 0\n",
    "t1 = time.time()\n",
    "pca.fit(x_train)\n",
    "t2 = time.time()\n",
    "time_sum+= t2-t1\n",
    "train_img = pca.transform(x_train)\n",
    "test_img  = pca.transform(x_test)\n",
    "x_train.shape,train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1046, 180), (1046,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "border = 146\n",
    "x_train_init = train_img[:border]\n",
    "y_train_init = y_train[:border]\n",
    "x_train_seq = train_img[border:]\n",
    "y_train_seq = y_train[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # clear all the tensors\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "\"\"\"Placeholders\"\"\"\n",
    "X_ = tf.placeholder(tf.float32, [None, INPUT_DIMENSION])\n",
    "#X_ = tf.reshape(X, [-1, INPUT_DIMENSION]) # Flatten X: [N,D]\n",
    "Y = tf.placeholder(tf.int64, [None]) # labels\n",
    "Y_ = tf.one_hot(indices=Y, depth=NUM_CLASSES) # one_hot labels: [N,M]\n",
    "\n",
    "\"\"\"Some constants\"\"\"\n",
    "D = INPUT_DIMENSION\n",
    "M = NUM_CLASSES # Number of outputs\n",
    "C = tf.constant(2.0**(-3))\n",
    "\n",
    "\"\"\"Weights\"\"\"\n",
    "alpha_1 = tf.get_variable('alpha_1',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False) # 1st subnetwork\n",
    "alpha_2 = tf.get_variable('alpha_2',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False) # 2st subnetwork\n",
    "alpha_3 = tf.get_variable('alpha_3',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_1 = tf.get_variable('beta_1',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_2 = tf.get_variable('beta_2',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_3 = tf.get_variable('beta_3',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tf.get_variable('k',shape=[D, D],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "m = tf.get_variable('m',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions\"\"\"\n",
    "def mul(A, B):\n",
    "    return tf.matmul(A, B)\n",
    "\n",
    "def inv(A):\n",
    "    return tf.matrix_inverse(A)\n",
    "\n",
    "def t(A):\n",
    "    return tf.transpose(A)\n",
    "\n",
    "def sin(A):\n",
    "    return tf.math.sin(A)\n",
    "\n",
    "def asin(A):\n",
    "    return tf.math.asin(A)\n",
    "\n",
    "def sqrt(A):\n",
    "    return tf.sqrt(A)\n",
    "\n",
    "def sqr(A):\n",
    "    return tf.math.pow(A, 2)\n",
    "\n",
    "def pseudo_inv(A, I, C):\n",
    "    C_I = I/C\n",
    "    return mul(t(A), inv(C_I + mul(A, t(A))))\n",
    "\n",
    "def h(A):\n",
    "    '''activation function'''\n",
    "    return sin(A)\n",
    "\n",
    "def h_(A):\n",
    "    '''inverse activation function'''\n",
    "    return asin(A)\n",
    "\n",
    "def u(A):\n",
    "    '''normalize the input to (0,1]'''\n",
    "    return tf.math.sigmoid(A) # sigmoid\n",
    "    \n",
    "def u_(A):\n",
    "    '''the inverse of u'''\n",
    "    ONE = tf.constant(1.0)\n",
    "    return -(tf.math.log(ONE/A - ONE)) # the inverse of sigmoid\n",
    "    \n",
    "def subnet_output(alpha, beta, A):\n",
    "    return t(mul(beta, h(mul(t(alpha), t(A))))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial Training Graph\"\"\"\n",
    "# D: input dimension\n",
    "# N: number of input samples\n",
    "# M: number of classes (number of outputs)\n",
    "'''some pre-computations'''\n",
    "X_init = t(X_) # [D,N]\n",
    "Y_init = t(Y_) # [M,N]\n",
    "N_init = D # number of dimensions\n",
    "I_DxD = tf.eye(N_init, dtype=tf.float32) # [D,D]\n",
    "I_MxM = tf.eye(M, dtype=tf.float32) # [M,M]\n",
    "C_I = I_DxD/C\n",
    "H_I = I_MxM/C\n",
    "\n",
    "add = C_I + mul(X_init, t(X_init))\n",
    "k = tf.assign(k,add)\n",
    "X_inv_init = pseudo_inv(X_init, I_DxD, C) # [N,D]\n",
    "\n",
    "'''1st subnet'''\n",
    "alpha_1_init_calculated = t(mul(h_(Y_init), X_inv_init)) # ([M,N]x[N,D])T=[D,M]\n",
    "alpha_1_init = tf.assign(alpha_1, alpha_1_init_calculated) # [D,M]\n",
    "H_1_init = h(mul(t(alpha_1_init), X_init)) # [M,N]\n",
    "H_add = H_I + mul(H_1_init,t(H_1_init))\n",
    "m = tf.assign(m,H_add)\n",
    "H_pseudo_init = pseudo_inv(H_1_init,I_MxM,C) #[N,M]\n",
    "\n",
    "beta_1_init_calculated = mul(Y_init, t(H_1_init))/sqr(tf.norm(H_1_init)) # [M,M]\n",
    "beta_1_init_calculated = mul(Y_init,H_pseudo_init)\n",
    "\n",
    "beta_1_init = tf.assign(beta_1, beta_1_init_calculated) # [M,M]\n",
    "H_beta_1_init = mul(beta_1_init, t(mul(t(X_init), alpha_1_init))) # [M,N]\n",
    "E_1_init = Y_init - H_beta_1_init # [M,N]\n",
    "\n",
    "'''2nd subnet'''\n",
    "#alpha_2_init_calculated = t(mul(h_(E_1_init), X_inv_init)) # [D,M]    \n",
    "alpha_2_init_calculated = t(mul(asin(Y_init), X_inv_init)) # [D,M]\n",
    "\n",
    "alpha_2_init = tf.assign(alpha_2, alpha_2_init_calculated) # [D,M]\n",
    "H_2_init = h(mul(t(alpha_2_init), X_init)) # [M,N]\n",
    "H_2_inv_init = pseudo_inv(H_2_init, I_MxM, C) # [M,N]\n",
    "H_add = H_I + mul(H_2_init,t(H_2_init))\n",
    "#m = tf.assign(m,H_add)\n",
    "H_pseudo_init = pseudo_inv(H_2_init,I_MxM,C) #[N,M]\n",
    "\n",
    "beta_2_init_calculated = mul(E_1_init, t(H_2_init))/sqr(tf.norm(H_2_init)) # [M,M]\n",
    "beta_2_init_calculated = mul(E_1_init, H_pseudo_init)\n",
    "\n",
    "beta_2_init = tf.assign(beta_2, beta_2_init_calculated) # [M,M]\n",
    "H_beta_2_init = mul(beta_2_init, t(mul(t(X_init), alpha_2_init))) # [M,N]\n",
    "E_2_init = Y_init - (H_beta_1_init+H_beta_2_init) # [M,N]\n",
    "\n",
    "'''3rd subnetwork'''\n",
    "alpha_3_init_calculated = t(mul(h_(E_2_init), X_inv_init)) # [D,M]    \n",
    "alpha_3_init_calculated = t(mul(asin(Y_init), X_inv_init)) # [D,M]\n",
    "\n",
    "alpha_3_init = tf.assign(alpha_3, alpha_3_init_calculated) # [D,M]\n",
    "H_3_init = h(mul(t(alpha_3_init), X_init)) # [M,N]\n",
    "H_3_inv_init = pseudo_inv(H_3_init, I_MxM, C) # [M,N]\n",
    "\n",
    "beta_3_init_calculated = mul(E_2_init, t(H_3_init))/sqr(tf.norm(H_3_init)) # [M,M]\n",
    "beta_3_init_calculated = mul(E_2_init, H_3_inv_init)\n",
    "\n",
    "beta_3_init = tf.assign(beta_3, beta_3_init_calculated) # [M,M]\n",
    "H_beta_3_init = mul(beta_3_init, t(mul(t(X_init), alpha_3_init))) # [M,N]\n",
    "E_3_init = Y_init - (H_beta_3_init+H_beta_2_init+ H_beta_1_init) # [M,N]\n",
    "\n",
    "#init_train_graph = H_beta_1_init\n",
    "init_train_graph = E_3_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_3:0' shape=(3, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''With one subnetwork'''\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) \n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training done\n",
      "Initial train training loss:  0.33265358\n",
      "Initial train training accuracy:  0.53059274\n",
      "Initial train testing loss:  0.3326692\n",
      "Initial train testing accuracy:  0.50843173\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "sess.run(E_1_init, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) \n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training done\n",
      "Initial train training loss:  0.31407967\n",
      "Initial train training accuracy:  0.74474186\n",
      "Initial train testing loss:  0.31518787\n",
      "Initial train testing accuracy:  0.7166948\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "import time\n",
    "s = 0\n",
    "t1 = time.time()\n",
    "sess.run(E_2_init, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+=t2-t2\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training done\n",
      "Initial train training loss:  0.33130506\n",
      "Initial train training accuracy:  0.53059274\n",
      "Initial train testing loss:  0.33135155\n",
      "Initial train testing accuracy:  0.50843173\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "sess.run(init_train_graph, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_init = subnet_output(alpha_1, beta_1, X_)+ subnet_output(alpha_2, beta_2, X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic = sess.run(logits_init, feed_dict={X_ : [x_test[4]]})\n",
    "print(np.argmax(logic,axis =1))\n",
    "print(y_test[4])\n",
    "#plt.imshow(x_test[4200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sequential Training Graph\"\"\"\n",
    "# D: input dimension\n",
    "# N: number of input samples\n",
    "# M: number of classes (number of outputs)\n",
    "X_seq = t(X_) # [D,N]\n",
    "Y_seq = t(Y_) # [M,N]\n",
    "pseudo = mul(X_seq, X_) #DXD\n",
    "k = tf.assign(k, tf.add(k,pseudo)) #DXD\n",
    "k_inv = inv(k)\n",
    "\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_1))\n",
    "alpha1_seq = tf.assign(alpha_1,tf.add(alpha_1,new)) #DXM\n",
    "H_1_seq = h(mul(t(alpha1_seq), X_seq)) # [M,N]\n",
    "m_su = mul(H_1_seq,t(H_1_seq))\n",
    "m = tf.assign(m,tf.add(m,m_su))\n",
    "m_inv = inv(m)\n",
    "#update = tf.matmul(tf.matmul(m_inv,H_1_seq),h_(Y_seq)- tf.matmul())\n",
    "H_pseudo_init = pseudo_inv(H_1_seq,I_MxM,C) #[N,M]\n",
    "#UPDATE = tf.matmul(tf.matmul(K_inverse, HT), inverse_acti_y - tf.matmul(H, self.__outputWeight))\n",
    "beta_1_seq_calculated = mul(Y_seq, H_pseudo_init) # [M,M]\n",
    "beta_1_seq = tf.assign(beta_1, beta_1_seq_calculated) # [M,M]\n",
    "H_beta_1_seq = mul(beta_1_seq, t(mul(X_, alpha1_seq))) # [M,N]\n",
    "E_1_seq = Y_seq - H_beta_1_seq # [M,N]\n",
    "\n",
    "'''2nd subnetwork'''\n",
    "\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_2))\n",
    "alpha2_seq = tf.assign(alpha_2,tf.add(alpha_2,new)) #DXM\n",
    "H_2_seq = h(mul(t(alpha2_seq), X_seq)) # [M,N]\n",
    "H_pseudo_init = pseudo_inv(H_2_seq,I_MxM,C) #[N,M]\n",
    "beta_2_seq_calculated = mul(E_1_seq, H_pseudo_init) # [M,M]\n",
    "beta_2_seq = tf.assign(beta_2, beta_2_seq_calculated) # [M,M]\n",
    "H_beta_2_seq = mul(beta_2_seq, t(mul(t(X_seq), alpha2_seq))) # [M,N]\n",
    "E_2_seq = Y_seq - (H_beta_2_seq+ H_beta_1_seq) # [M,N]\n",
    "\n",
    "'''3rd subnetwork'''\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_3))\n",
    "alpha3_seq = tf.assign(alpha_3,tf.add(alpha_3,new)) #DXM\n",
    "H_3_seq = h(mul(t(alpha3_seq), X_seq)) # [M,N]\n",
    "H_pseudo_init = pseudo_inv(H_3_seq,I_MxM,C) #[N,M]\n",
    "beta_3_seq_calculated = mul(E_2_seq, H_pseudo_init) # [M,M]\n",
    "beta_3_seq = tf.assign(beta_3, beta_3_seq_calculated) # [M,M]\n",
    "H_beta_3_seq = mul(beta_3_seq, t(mul(t(X_seq), alpha3_seq))) # [M,N]\n",
    "E_3_seq = Y_seq - (H_beta_3_seq +H_beta_2_seq + H_beta_1_seq )# [M,N]\n",
    "seq_train_graph = E_3_seq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.245005, train_accuracy: 0.530593\n",
      "test_loss: 0.247213, test_accuracy: 0.508432\n",
      "train_loss: 0.211122, train_accuracy: 0.530593\n",
      "test_loss: 0.214470, test_accuracy: 0.508432\n",
      "train_loss: 0.204926, train_accuracy: 0.530593\n",
      "test_loss: 0.208632, test_accuracy: 0.508432\n",
      "train_loss: 0.202202, train_accuracy: 0.530593\n",
      "test_loss: 0.206102, test_accuracy: 0.508432\n",
      "train_loss: 0.199675, train_accuracy: 0.530593\n",
      "test_loss: 0.203735, test_accuracy: 0.508432\n",
      "train_loss: 0.196962, train_accuracy: 0.530593\n",
      "test_loss: 0.201177, test_accuracy: 0.508432\n",
      "train_loss: 0.194042, train_accuracy: 0.530593\n",
      "test_loss: 0.198413, test_accuracy: 0.508432\n",
      "train_loss: 0.190947, train_accuracy: 0.530593\n",
      "test_loss: 0.195476, test_accuracy: 0.508432\n",
      "train_loss: 0.187715, train_accuracy: 0.530593\n",
      "test_loss: 0.192402, test_accuracy: 0.508432\n",
      "train_loss: 0.184381, train_accuracy: 0.530593\n",
      "test_loss: 0.189224, test_accuracy: 0.508432\n",
      "train_loss: 0.180974, train_accuracy: 0.530593\n",
      "test_loss: 0.185973, test_accuracy: 0.508432\n",
      "train_loss: 0.177521, train_accuracy: 0.530593\n",
      "test_loss: 0.182673, test_accuracy: 0.508432\n",
      "train_loss: 0.174045, train_accuracy: 0.530593\n",
      "test_loss: 0.179347, test_accuracy: 0.508432\n",
      "train_loss: 0.170565, train_accuracy: 0.530593\n",
      "test_loss: 0.176014, test_accuracy: 0.508432\n",
      "train_loss: 0.167099, train_accuracy: 0.533461\n",
      "test_loss: 0.172690, test_accuracy: 0.513491\n",
      "train_loss: 0.163661, train_accuracy: 0.542065\n",
      "test_loss: 0.169389, test_accuracy: 0.520236\n",
      "train_loss: 0.160264, train_accuracy: 0.565010\n",
      "test_loss: 0.166125, test_accuracy: 0.538786\n",
      "train_loss: 0.156920, train_accuracy: 0.607075\n",
      "test_loss: 0.162908, test_accuracy: 0.563238\n",
      "train_loss: 0.153638, train_accuracy: 0.649140\n",
      "test_loss: 0.159749, test_accuracy: 0.609612\n",
      "train_loss: 0.150428, train_accuracy: 0.692161\n",
      "test_loss: 0.156655, test_accuracy: 0.650084\n",
      "train_loss: 0.147297, train_accuracy: 0.724665\n",
      "test_loss: 0.153635, test_accuracy: 0.686341\n",
      "train_loss: 0.144252, train_accuracy: 0.755258\n",
      "test_loss: 0.150694, test_accuracy: 0.718381\n",
      "train_loss: 0.141297, train_accuracy: 0.785851\n",
      "test_loss: 0.147839, test_accuracy: 0.747049\n",
      "train_loss: 0.138438, train_accuracy: 0.812620\n",
      "test_loss: 0.145072, test_accuracy: 0.763912\n",
      "train_loss: 0.135678, train_accuracy: 0.833652\n",
      "test_loss: 0.142398, test_accuracy: 0.787521\n",
      "train_loss: 0.133019, train_accuracy: 0.847036\n",
      "test_loss: 0.139820, test_accuracy: 0.811130\n",
      "train_loss: 0.130462, train_accuracy: 0.860421\n",
      "test_loss: 0.137338, test_accuracy: 0.824621\n",
      "train_loss: 0.128009, train_accuracy: 0.873805\n",
      "test_loss: 0.134954, test_accuracy: 0.832209\n",
      "train_loss: 0.125659, train_accuracy: 0.877629\n",
      "test_loss: 0.132668, test_accuracy: 0.836425\n",
      "train_loss: 0.123413, train_accuracy: 0.888145\n",
      "test_loss: 0.130479, test_accuracy: 0.845700\n",
      "train_loss: 0.121268, train_accuracy: 0.891013\n",
      "test_loss: 0.128388, test_accuracy: 0.849073\n",
      "train_loss: 0.119223, train_accuracy: 0.897706\n",
      "test_loss: 0.126392, test_accuracy: 0.852445\n",
      "train_loss: 0.117277, train_accuracy: 0.901530\n",
      "test_loss: 0.124489, test_accuracy: 0.857504\n",
      "train_loss: 0.115427, train_accuracy: 0.905354\n",
      "test_loss: 0.122679, test_accuracy: 0.865093\n",
      "train_loss: 0.113670, train_accuracy: 0.904398\n",
      "test_loss: 0.120957, test_accuracy: 0.870995\n",
      "train_loss: 0.112003, train_accuracy: 0.906310\n",
      "test_loss: 0.119321, test_accuracy: 0.873524\n",
      "train_loss: 0.110424, train_accuracy: 0.908222\n",
      "test_loss: 0.117770, test_accuracy: 0.874368\n",
      "train_loss: 0.108928, train_accuracy: 0.910134\n",
      "test_loss: 0.116299, test_accuracy: 0.877740\n",
      "train_loss: 0.107513, train_accuracy: 0.912046\n",
      "test_loss: 0.114905, test_accuracy: 0.877740\n",
      "train_loss: 0.106175, train_accuracy: 0.915870\n",
      "test_loss: 0.113586, test_accuracy: 0.878583\n",
      "train_loss: 0.104911, train_accuracy: 0.915870\n",
      "test_loss: 0.112339, test_accuracy: 0.882799\n",
      "train_loss: 0.103717, train_accuracy: 0.917782\n",
      "test_loss: 0.111159, test_accuracy: 0.888701\n",
      "train_loss: 0.102591, train_accuracy: 0.917782\n",
      "test_loss: 0.110044, test_accuracy: 0.890388\n",
      "train_loss: 0.101528, train_accuracy: 0.917782\n",
      "test_loss: 0.108992, test_accuracy: 0.892074\n",
      "train_loss: 0.100526, train_accuracy: 0.920650\n",
      "test_loss: 0.107998, test_accuracy: 0.892917\n",
      "train_loss: 0.099581, train_accuracy: 0.922562\n",
      "test_loss: 0.107060, test_accuracy: 0.898820\n",
      "train_loss: 0.098691, train_accuracy: 0.922562\n",
      "test_loss: 0.106176, test_accuracy: 0.900506\n",
      "train_loss: 0.097852, train_accuracy: 0.920650\n",
      "test_loss: 0.105341, test_accuracy: 0.899663\n",
      "train_loss: 0.097062, train_accuracy: 0.921606\n",
      "test_loss: 0.104555, test_accuracy: 0.900506\n",
      "train_loss: 0.096318, train_accuracy: 0.923518\n",
      "test_loss: 0.103813, test_accuracy: 0.897976\n",
      "train_loss: 0.095618, train_accuracy: 0.924474\n",
      "test_loss: 0.103115, test_accuracy: 0.899663\n",
      "train_loss: 0.094958, train_accuracy: 0.927342\n",
      "test_loss: 0.102456, test_accuracy: 0.899663\n",
      "train_loss: 0.094338, train_accuracy: 0.927342\n",
      "test_loss: 0.101836, test_accuracy: 0.898820\n",
      "train_loss: 0.093753, train_accuracy: 0.926386\n",
      "test_loss: 0.101252, test_accuracy: 0.898820\n",
      "train_loss: 0.093203, train_accuracy: 0.927342\n",
      "test_loss: 0.100701, test_accuracy: 0.902192\n",
      "train_loss: 0.092686, train_accuracy: 0.928298\n",
      "test_loss: 0.100183, test_accuracy: 0.903035\n",
      "train_loss: 0.092199, train_accuracy: 0.928298\n",
      "test_loss: 0.099695, test_accuracy: 0.903879\n",
      "train_loss: 0.091740, train_accuracy: 0.927342\n",
      "test_loss: 0.099236, test_accuracy: 0.904722\n",
      "train_loss: 0.091309, train_accuracy: 0.927342\n",
      "test_loss: 0.098803, test_accuracy: 0.907251\n",
      "train_loss: 0.090903, train_accuracy: 0.927342\n",
      "test_loss: 0.098396, test_accuracy: 0.906408\n",
      "train_loss: 0.090521, train_accuracy: 0.927342\n",
      "test_loss: 0.098012, test_accuracy: 0.906408\n",
      "train_loss: 0.090162, train_accuracy: 0.927342\n",
      "test_loss: 0.097651, test_accuracy: 0.906408\n",
      "train_loss: 0.089824, train_accuracy: 0.927342\n",
      "test_loss: 0.097312, test_accuracy: 0.905565\n",
      "train_loss: 0.089506, train_accuracy: 0.927342\n",
      "test_loss: 0.096992, test_accuracy: 0.906408\n",
      "train_loss: 0.089206, train_accuracy: 0.929254\n",
      "test_loss: 0.096692, test_accuracy: 0.906408\n",
      "train_loss: 0.088925, train_accuracy: 0.930210\n",
      "test_loss: 0.096409, test_accuracy: 0.906408\n",
      "train_loss: 0.088660, train_accuracy: 0.930210\n",
      "test_loss: 0.096143, test_accuracy: 0.906408\n",
      "train_loss: 0.088411, train_accuracy: 0.929254\n",
      "test_loss: 0.095892, test_accuracy: 0.906408\n",
      "train_loss: 0.088177, train_accuracy: 0.929254\n",
      "test_loss: 0.095657, test_accuracy: 0.906408\n",
      "train_loss: 0.087956, train_accuracy: 0.929254\n",
      "test_loss: 0.095436, test_accuracy: 0.906408\n",
      "train_loss: 0.087749, train_accuracy: 0.929254\n",
      "test_loss: 0.095228, test_accuracy: 0.908094\n",
      "train_loss: 0.087555, train_accuracy: 0.929254\n",
      "test_loss: 0.095033, test_accuracy: 0.908094\n",
      "train_loss: 0.087372, train_accuracy: 0.929254\n",
      "test_loss: 0.094849, test_accuracy: 0.908094\n",
      "train_loss: 0.087200, train_accuracy: 0.929254\n",
      "test_loss: 0.094677, test_accuracy: 0.908094\n",
      "train_loss: 0.087039, train_accuracy: 0.929254\n",
      "test_loss: 0.094516, test_accuracy: 0.908938\n",
      "train_loss: 0.086887, train_accuracy: 0.929254\n",
      "test_loss: 0.094364, test_accuracy: 0.908938\n",
      "train_loss: 0.086745, train_accuracy: 0.929254\n",
      "test_loss: 0.094222, test_accuracy: 0.908938\n",
      "train_loss: 0.086611, train_accuracy: 0.929254\n",
      "test_loss: 0.094089, test_accuracy: 0.908938\n",
      "train_loss: 0.086486, train_accuracy: 0.929254\n",
      "test_loss: 0.093964, test_accuracy: 0.908938\n",
      "train_loss: 0.086369, train_accuracy: 0.929254\n",
      "test_loss: 0.093847, test_accuracy: 0.908938\n",
      "train_loss: 0.086259, train_accuracy: 0.930210\n",
      "test_loss: 0.093738, test_accuracy: 0.908938\n",
      "train_loss: 0.086157, train_accuracy: 0.931166\n",
      "test_loss: 0.093636, test_accuracy: 0.908938\n",
      "train_loss: 0.086061, train_accuracy: 0.932122\n",
      "test_loss: 0.093541, test_accuracy: 0.908938\n",
      "train_loss: 0.085971, train_accuracy: 0.931166\n",
      "test_loss: 0.093452, test_accuracy: 0.908938\n",
      "train_loss: 0.085887, train_accuracy: 0.931166\n",
      "test_loss: 0.093369, test_accuracy: 0.908938\n",
      "train_loss: 0.085809, train_accuracy: 0.931166\n",
      "test_loss: 0.093292, test_accuracy: 0.908938\n",
      "train_loss: 0.085736, train_accuracy: 0.931166\n",
      "test_loss: 0.093221, test_accuracy: 0.908938\n",
      "train_loss: 0.085668, train_accuracy: 0.931166\n",
      "test_loss: 0.093155, test_accuracy: 0.909781\n",
      "train_loss: 0.085605, train_accuracy: 0.931166\n",
      "test_loss: 0.093093, test_accuracy: 0.910624\n",
      "train_loss: 0.085547, train_accuracy: 0.933078\n",
      "test_loss: 0.093036, test_accuracy: 0.910624\n",
      "train_loss: 0.085492, train_accuracy: 0.933078\n",
      "test_loss: 0.092984, test_accuracy: 0.909781\n",
      "train_loss: 0.085442, train_accuracy: 0.933078\n",
      "test_loss: 0.092936, test_accuracy: 0.909781\n",
      "train_loss: 0.085396, train_accuracy: 0.934034\n",
      "test_loss: 0.092892, test_accuracy: 0.909781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.085354, train_accuracy: 0.934034\n",
      "test_loss: 0.092851, test_accuracy: 0.909781\n",
      "train_loss: 0.085315, train_accuracy: 0.934034\n",
      "test_loss: 0.092815, test_accuracy: 0.909781\n",
      "train_loss: 0.085279, train_accuracy: 0.934034\n",
      "test_loss: 0.092781, test_accuracy: 0.910624\n",
      "train_loss: 0.085247, train_accuracy: 0.934034\n",
      "test_loss: 0.092751, test_accuracy: 0.910624\n",
      "train_loss: 0.085217, train_accuracy: 0.934034\n",
      "test_loss: 0.092724, test_accuracy: 0.910624\n",
      "train_loss: 0.085191, train_accuracy: 0.934034\n",
      "test_loss: 0.092700, test_accuracy: 0.911467\n",
      "train_loss: 0.085167, train_accuracy: 0.934034\n",
      "test_loss: 0.092678, test_accuracy: 0.911467\n",
      "train_loss: 0.085145, train_accuracy: 0.934034\n",
      "test_loss: 0.092659, test_accuracy: 0.912310\n",
      "train_loss: 0.085126, train_accuracy: 0.934034\n",
      "test_loss: 0.092643, test_accuracy: 0.912310\n",
      "train_loss: 0.085110, train_accuracy: 0.934034\n",
      "test_loss: 0.092629, test_accuracy: 0.913997\n",
      "train_loss: 0.085096, train_accuracy: 0.934034\n",
      "test_loss: 0.092618, test_accuracy: 0.913997\n",
      "train_loss: 0.085083, train_accuracy: 0.934990\n",
      "test_loss: 0.092608, test_accuracy: 0.913997\n",
      "train_loss: 0.085073, train_accuracy: 0.934990\n",
      "test_loss: 0.092601, test_accuracy: 0.913997\n",
      "train_loss: 0.085065, train_accuracy: 0.934990\n",
      "test_loss: 0.092595, test_accuracy: 0.913997\n",
      "train_loss: 0.085058, train_accuracy: 0.934990\n",
      "test_loss: 0.092591, test_accuracy: 0.913997\n",
      "train_loss: 0.085053, train_accuracy: 0.934990\n",
      "test_loss: 0.092590, test_accuracy: 0.913997\n",
      "train_loss: 0.085050, train_accuracy: 0.934990\n",
      "test_loss: 0.092589, test_accuracy: 0.914840\n",
      "train_loss: 0.085049, train_accuracy: 0.934990\n",
      "test_loss: 0.092591, test_accuracy: 0.915683\n",
      "train_loss: 0.085049, train_accuracy: 0.934990\n",
      "test_loss: 0.092594, test_accuracy: 0.915683\n",
      "train_loss: 0.085050, train_accuracy: 0.935946\n",
      "test_loss: 0.092598, test_accuracy: 0.915683\n",
      "train_loss: 0.085053, train_accuracy: 0.935946\n",
      "test_loss: 0.092604, test_accuracy: 0.915683\n",
      "train_loss: 0.085056, train_accuracy: 0.935946\n",
      "test_loss: 0.092611, test_accuracy: 0.915683\n",
      "train_loss: 0.085062, train_accuracy: 0.935946\n",
      "test_loss: 0.092619, test_accuracy: 0.915683\n",
      "train_loss: 0.085068, train_accuracy: 0.935946\n",
      "test_loss: 0.092629, test_accuracy: 0.915683\n",
      "train_loss: 0.085075, train_accuracy: 0.935946\n",
      "test_loss: 0.092639, test_accuracy: 0.915683\n",
      "train_loss: 0.085084, train_accuracy: 0.935946\n",
      "test_loss: 0.092651, test_accuracy: 0.915683\n",
      "train_loss: 0.085093, train_accuracy: 0.936902\n",
      "test_loss: 0.092664, test_accuracy: 0.915683\n",
      "train_loss: 0.085104, train_accuracy: 0.936902\n",
      "test_loss: 0.092677, test_accuracy: 0.915683\n",
      "train_loss: 0.085115, train_accuracy: 0.936902\n",
      "test_loss: 0.092692, test_accuracy: 0.915683\n",
      "train_loss: 0.085127, train_accuracy: 0.936902\n",
      "test_loss: 0.092707, test_accuracy: 0.915683\n",
      "train_loss: 0.085140, train_accuracy: 0.936902\n",
      "test_loss: 0.092724, test_accuracy: 0.915683\n",
      "train_loss: 0.085154, train_accuracy: 0.936902\n",
      "test_loss: 0.092741, test_accuracy: 0.915683\n",
      "train_loss: 0.085168, train_accuracy: 0.936902\n",
      "test_loss: 0.092759, test_accuracy: 0.915683\n",
      "train_loss: 0.085183, train_accuracy: 0.936902\n",
      "test_loss: 0.092777, test_accuracy: 0.915683\n",
      "train_loss: 0.085199, train_accuracy: 0.936902\n",
      "test_loss: 0.092796, test_accuracy: 0.915683\n",
      "train_loss: 0.085216, train_accuracy: 0.936902\n",
      "test_loss: 0.092816, test_accuracy: 0.915683\n",
      "train_loss: 0.085233, train_accuracy: 0.936902\n",
      "test_loss: 0.092837, test_accuracy: 0.915683\n",
      "train_loss: 0.085250, train_accuracy: 0.937859\n",
      "test_loss: 0.092858, test_accuracy: 0.916526\n",
      "train_loss: 0.085269, train_accuracy: 0.937859\n",
      "test_loss: 0.092880, test_accuracy: 0.916526\n",
      "train_loss: 0.085287, train_accuracy: 0.937859\n",
      "test_loss: 0.092902, test_accuracy: 0.916526\n",
      "train_loss: 0.085306, train_accuracy: 0.937859\n",
      "test_loss: 0.092924, test_accuracy: 0.916526\n",
      "train_loss: 0.085326, train_accuracy: 0.937859\n",
      "test_loss: 0.092947, test_accuracy: 0.916526\n",
      "train_loss: 0.085346, train_accuracy: 0.937859\n",
      "test_loss: 0.092971, test_accuracy: 0.916526\n",
      "train_loss: 0.085366, train_accuracy: 0.937859\n",
      "test_loss: 0.092995, test_accuracy: 0.916526\n",
      "train_loss: 0.085387, train_accuracy: 0.937859\n",
      "test_loss: 0.093019, test_accuracy: 0.916526\n",
      "train_loss: 0.085408, train_accuracy: 0.937859\n",
      "test_loss: 0.093044, test_accuracy: 0.916526\n",
      "train_loss: 0.085430, train_accuracy: 0.937859\n",
      "test_loss: 0.093069, test_accuracy: 0.916526\n",
      "train_loss: 0.085452, train_accuracy: 0.938815\n",
      "test_loss: 0.093094, test_accuracy: 0.916526\n",
      "train_loss: 0.085474, train_accuracy: 0.938815\n",
      "test_loss: 0.093120, test_accuracy: 0.915683\n",
      "train_loss: 0.085496, train_accuracy: 0.938815\n",
      "test_loss: 0.093146, test_accuracy: 0.915683\n",
      "train_loss: 0.085519, train_accuracy: 0.937859\n",
      "test_loss: 0.093172, test_accuracy: 0.914840\n",
      "train_loss: 0.085542, train_accuracy: 0.937859\n",
      "test_loss: 0.093199, test_accuracy: 0.914840\n",
      "train_loss: 0.085565, train_accuracy: 0.937859\n",
      "test_loss: 0.093226, test_accuracy: 0.914840\n",
      "train_loss: 0.085588, train_accuracy: 0.938815\n",
      "test_loss: 0.093253, test_accuracy: 0.914840\n",
      "train_loss: 0.085612, train_accuracy: 0.938815\n",
      "test_loss: 0.093280, test_accuracy: 0.914840\n",
      "train_loss: 0.085636, train_accuracy: 0.938815\n",
      "test_loss: 0.093307, test_accuracy: 0.914840\n",
      "train_loss: 0.085659, train_accuracy: 0.938815\n",
      "test_loss: 0.093335, test_accuracy: 0.914840\n",
      "train_loss: 0.085683, train_accuracy: 0.938815\n",
      "test_loss: 0.093363, test_accuracy: 0.914840\n",
      "train_loss: 0.085708, train_accuracy: 0.938815\n",
      "test_loss: 0.093391, test_accuracy: 0.914840\n",
      "train_loss: 0.085732, train_accuracy: 0.938815\n",
      "test_loss: 0.093419, test_accuracy: 0.914840\n",
      "train_loss: 0.085756, train_accuracy: 0.938815\n",
      "test_loss: 0.093447, test_accuracy: 0.915683\n",
      "train_loss: 0.085781, train_accuracy: 0.938815\n",
      "test_loss: 0.093475, test_accuracy: 0.916526\n",
      "train_loss: 0.085806, train_accuracy: 0.938815\n",
      "test_loss: 0.093504, test_accuracy: 0.916526\n",
      "train_loss: 0.085830, train_accuracy: 0.938815\n",
      "test_loss: 0.093532, test_accuracy: 0.916526\n",
      "train_loss: 0.085855, train_accuracy: 0.938815\n",
      "test_loss: 0.093561, test_accuracy: 0.917369\n",
      "train_loss: 0.085880, train_accuracy: 0.938815\n",
      "test_loss: 0.093590, test_accuracy: 0.917369\n",
      "train_loss: 0.085905, train_accuracy: 0.938815\n",
      "test_loss: 0.093618, test_accuracy: 0.917369\n",
      "train_loss: 0.085930, train_accuracy: 0.938815\n",
      "test_loss: 0.093647, test_accuracy: 0.917369\n",
      "train_loss: 0.085955, train_accuracy: 0.939771\n",
      "test_loss: 0.093676, test_accuracy: 0.917369\n",
      "train_loss: 0.085980, train_accuracy: 0.939771\n",
      "test_loss: 0.093705, test_accuracy: 0.917369\n",
      "train_loss: 0.086005, train_accuracy: 0.939771\n",
      "test_loss: 0.093734, test_accuracy: 0.917369\n",
      "train_loss: 0.086030, train_accuracy: 0.939771\n",
      "test_loss: 0.093763, test_accuracy: 0.917369\n",
      "train_loss: 0.086055, train_accuracy: 0.939771\n",
      "test_loss: 0.093792, test_accuracy: 0.917369\n",
      "train_loss: 0.086080, train_accuracy: 0.939771\n",
      "test_loss: 0.093821, test_accuracy: 0.917369\n",
      "train_loss: 0.086105, train_accuracy: 0.939771\n",
      "test_loss: 0.093850, test_accuracy: 0.918212\n",
      "train_loss: 0.086130, train_accuracy: 0.939771\n",
      "test_loss: 0.093879, test_accuracy: 0.918212\n",
      "train_loss: 0.086155, train_accuracy: 0.939771\n",
      "test_loss: 0.093908, test_accuracy: 0.918212\n",
      "train_loss: 0.086180, train_accuracy: 0.939771\n",
      "test_loss: 0.093937, test_accuracy: 0.918212\n",
      "train_loss: 0.086205, train_accuracy: 0.940727\n",
      "test_loss: 0.093966, test_accuracy: 0.919056\n",
      "train_loss: 0.086230, train_accuracy: 0.940727\n",
      "test_loss: 0.093995, test_accuracy: 0.919056\n",
      "train_loss: 0.086255, train_accuracy: 0.940727\n",
      "test_loss: 0.094024, test_accuracy: 0.919056\n",
      "train_loss: 0.086280, train_accuracy: 0.940727\n",
      "test_loss: 0.094053, test_accuracy: 0.919056\n",
      "train_loss: 0.086304, train_accuracy: 0.940727\n",
      "test_loss: 0.094082, test_accuracy: 0.919056\n",
      "train_loss: 0.086329, train_accuracy: 0.941683\n",
      "test_loss: 0.094111, test_accuracy: 0.919056\n",
      "train_loss: 0.086354, train_accuracy: 0.941683\n",
      "test_loss: 0.094139, test_accuracy: 0.919899\n",
      "train_loss: 0.086378, train_accuracy: 0.941683\n",
      "test_loss: 0.094168, test_accuracy: 0.919899\n",
      "train_loss: 0.086403, train_accuracy: 0.941683\n",
      "test_loss: 0.094197, test_accuracy: 0.919899\n",
      "train_loss: 0.086427, train_accuracy: 0.941683\n",
      "test_loss: 0.094226, test_accuracy: 0.919899\n",
      "train_loss: 0.086452, train_accuracy: 0.940727\n",
      "test_loss: 0.094254, test_accuracy: 0.919899\n",
      "train_loss: 0.086476, train_accuracy: 0.940727\n",
      "test_loss: 0.094283, test_accuracy: 0.920742\n",
      "train_loss: 0.086500, train_accuracy: 0.940727\n",
      "test_loss: 0.094311, test_accuracy: 0.920742\n",
      "train_loss: 0.086524, train_accuracy: 0.940727\n",
      "test_loss: 0.094340, test_accuracy: 0.920742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.086548, train_accuracy: 0.940727\n",
      "test_loss: 0.094368, test_accuracy: 0.921585\n",
      "train_loss: 0.086572, train_accuracy: 0.940727\n",
      "test_loss: 0.094396, test_accuracy: 0.921585\n",
      "train_loss: 0.086596, train_accuracy: 0.942639\n",
      "test_loss: 0.094424, test_accuracy: 0.921585\n",
      "train_loss: 0.086620, train_accuracy: 0.942639\n",
      "test_loss: 0.094452, test_accuracy: 0.921585\n",
      "train_loss: 0.086643, train_accuracy: 0.942639\n",
      "test_loss: 0.094480, test_accuracy: 0.921585\n",
      "train_loss: 0.086667, train_accuracy: 0.942639\n",
      "test_loss: 0.094508, test_accuracy: 0.921585\n",
      "train_loss: 0.086690, train_accuracy: 0.942639\n",
      "test_loss: 0.094536, test_accuracy: 0.921585\n",
      "train_loss: 0.086713, train_accuracy: 0.943595\n",
      "test_loss: 0.094564, test_accuracy: 0.920742\n",
      "train_loss: 0.086737, train_accuracy: 0.943595\n",
      "test_loss: 0.094591, test_accuracy: 0.920742\n",
      "train_loss: 0.086760, train_accuracy: 0.943595\n",
      "test_loss: 0.094619, test_accuracy: 0.920742\n",
      "train_loss: 0.086782, train_accuracy: 0.943595\n",
      "test_loss: 0.094646, test_accuracy: 0.920742\n",
      "train_loss: 0.086805, train_accuracy: 0.943595\n",
      "test_loss: 0.094674, test_accuracy: 0.920742\n",
      "train_loss: 0.086828, train_accuracy: 0.943595\n",
      "test_loss: 0.094701, test_accuracy: 0.920742\n",
      "train_loss: 0.086850, train_accuracy: 0.943595\n",
      "test_loss: 0.094728, test_accuracy: 0.920742\n",
      "train_loss: 0.086873, train_accuracy: 0.943595\n",
      "test_loss: 0.094755, test_accuracy: 0.919899\n",
      "train_loss: 0.086895, train_accuracy: 0.943595\n",
      "test_loss: 0.094782, test_accuracy: 0.919899\n",
      "train_loss: 0.086917, train_accuracy: 0.943595\n",
      "test_loss: 0.094809, test_accuracy: 0.919899\n",
      "train_loss: 0.086939, train_accuracy: 0.943595\n",
      "test_loss: 0.094835, test_accuracy: 0.919899\n",
      "train_loss: 0.086961, train_accuracy: 0.943595\n",
      "test_loss: 0.094862, test_accuracy: 0.919056\n",
      "train_loss: 0.086983, train_accuracy: 0.944551\n",
      "test_loss: 0.094889, test_accuracy: 0.919056\n",
      "train_loss: 0.087005, train_accuracy: 0.944551\n",
      "test_loss: 0.094915, test_accuracy: 0.919056\n",
      "train_loss: 0.087026, train_accuracy: 0.945507\n",
      "test_loss: 0.094941, test_accuracy: 0.919056\n",
      "train_loss: 0.087048, train_accuracy: 0.946463\n",
      "test_loss: 0.094967, test_accuracy: 0.919056\n",
      "train_loss: 0.087069, train_accuracy: 0.946463\n",
      "test_loss: 0.094993, test_accuracy: 0.919056\n",
      "train_loss: 0.087090, train_accuracy: 0.945507\n",
      "test_loss: 0.095019, test_accuracy: 0.919056\n",
      "train_loss: 0.087111, train_accuracy: 0.945507\n",
      "test_loss: 0.095045, test_accuracy: 0.919056\n",
      "train_loss: 0.087132, train_accuracy: 0.945507\n",
      "test_loss: 0.095071, test_accuracy: 0.919056\n",
      "train_loss: 0.087152, train_accuracy: 0.945507\n",
      "test_loss: 0.095096, test_accuracy: 0.919056\n",
      "train_loss: 0.087173, train_accuracy: 0.945507\n",
      "test_loss: 0.095122, test_accuracy: 0.919056\n",
      "train_loss: 0.087193, train_accuracy: 0.945507\n",
      "test_loss: 0.095147, test_accuracy: 0.919899\n",
      "train_loss: 0.087213, train_accuracy: 0.945507\n",
      "test_loss: 0.095172, test_accuracy: 0.920742\n",
      "train_loss: 0.087233, train_accuracy: 0.945507\n",
      "test_loss: 0.095197, test_accuracy: 0.919899\n",
      "train_loss: 0.087253, train_accuracy: 0.945507\n",
      "test_loss: 0.095222, test_accuracy: 0.919899\n",
      "train_loss: 0.087273, train_accuracy: 0.945507\n",
      "test_loss: 0.095247, test_accuracy: 0.919899\n",
      "train_loss: 0.087293, train_accuracy: 0.945507\n",
      "test_loss: 0.095272, test_accuracy: 0.919899\n",
      "train_loss: 0.087312, train_accuracy: 0.944551\n",
      "test_loss: 0.095296, test_accuracy: 0.919899\n",
      "train_loss: 0.087332, train_accuracy: 0.944551\n",
      "test_loss: 0.095321, test_accuracy: 0.919899\n",
      "train_loss: 0.087351, train_accuracy: 0.944551\n",
      "test_loss: 0.095345, test_accuracy: 0.920742\n",
      "train_loss: 0.087370, train_accuracy: 0.944551\n",
      "test_loss: 0.095369, test_accuracy: 0.920742\n",
      "train_loss: 0.087389, train_accuracy: 0.944551\n",
      "test_loss: 0.095393, test_accuracy: 0.920742\n",
      "train_loss: 0.087407, train_accuracy: 0.944551\n",
      "test_loss: 0.095417, test_accuracy: 0.920742\n",
      "train_loss: 0.087426, train_accuracy: 0.944551\n",
      "test_loss: 0.095441, test_accuracy: 0.920742\n",
      "train_loss: 0.087444, train_accuracy: 0.944551\n",
      "test_loss: 0.095464, test_accuracy: 0.920742\n",
      "train_loss: 0.087463, train_accuracy: 0.944551\n",
      "test_loss: 0.095488, test_accuracy: 0.920742\n",
      "train_loss: 0.087481, train_accuracy: 0.944551\n",
      "test_loss: 0.095511, test_accuracy: 0.920742\n",
      "train_loss: 0.087499, train_accuracy: 0.944551\n",
      "test_loss: 0.095535, test_accuracy: 0.920742\n",
      "train_loss: 0.087517, train_accuracy: 0.944551\n",
      "test_loss: 0.095558, test_accuracy: 0.920742\n",
      "train_loss: 0.087534, train_accuracy: 0.944551\n",
      "test_loss: 0.095581, test_accuracy: 0.920742\n",
      "train_loss: 0.087552, train_accuracy: 0.944551\n",
      "test_loss: 0.095604, test_accuracy: 0.920742\n",
      "train_loss: 0.087569, train_accuracy: 0.945507\n",
      "test_loss: 0.095627, test_accuracy: 0.920742\n",
      "train_loss: 0.087587, train_accuracy: 0.945507\n",
      "test_loss: 0.095649, test_accuracy: 0.920742\n",
      "train_loss: 0.087604, train_accuracy: 0.945507\n",
      "test_loss: 0.095672, test_accuracy: 0.919899\n",
      "train_loss: 0.087621, train_accuracy: 0.945507\n",
      "test_loss: 0.095694, test_accuracy: 0.919899\n",
      "train_loss: 0.087638, train_accuracy: 0.945507\n",
      "test_loss: 0.095716, test_accuracy: 0.919899\n",
      "train_loss: 0.087654, train_accuracy: 0.945507\n",
      "test_loss: 0.095739, test_accuracy: 0.919899\n",
      "train_loss: 0.087671, train_accuracy: 0.945507\n",
      "test_loss: 0.095761, test_accuracy: 0.919899\n",
      "train_loss: 0.087687, train_accuracy: 0.945507\n",
      "test_loss: 0.095783, test_accuracy: 0.919899\n",
      "train_loss: 0.087703, train_accuracy: 0.945507\n",
      "test_loss: 0.095804, test_accuracy: 0.919899\n",
      "train_loss: 0.087719, train_accuracy: 0.945507\n",
      "test_loss: 0.095826, test_accuracy: 0.919899\n",
      "train_loss: 0.087735, train_accuracy: 0.945507\n",
      "test_loss: 0.095847, test_accuracy: 0.919899\n",
      "train_loss: 0.087751, train_accuracy: 0.945507\n",
      "test_loss: 0.095869, test_accuracy: 0.919899\n",
      "train_loss: 0.087767, train_accuracy: 0.946463\n",
      "test_loss: 0.095890, test_accuracy: 0.919899\n",
      "train_loss: 0.087782, train_accuracy: 0.946463\n",
      "test_loss: 0.095911, test_accuracy: 0.919899\n",
      "train_loss: 0.087798, train_accuracy: 0.946463\n",
      "test_loss: 0.095932, test_accuracy: 0.919899\n",
      "train_loss: 0.087813, train_accuracy: 0.946463\n",
      "test_loss: 0.095953, test_accuracy: 0.919899\n",
      "train_loss: 0.087828, train_accuracy: 0.946463\n",
      "test_loss: 0.095974, test_accuracy: 0.919899\n",
      "train_loss: 0.087843, train_accuracy: 0.946463\n",
      "test_loss: 0.095995, test_accuracy: 0.919899\n",
      "train_loss: 0.087858, train_accuracy: 0.946463\n",
      "test_loss: 0.096015, test_accuracy: 0.919056\n",
      "train_loss: 0.087872, train_accuracy: 0.946463\n",
      "test_loss: 0.096035, test_accuracy: 0.919056\n",
      "train_loss: 0.087887, train_accuracy: 0.946463\n",
      "test_loss: 0.096056, test_accuracy: 0.918212\n",
      "train_loss: 0.087901, train_accuracy: 0.946463\n",
      "test_loss: 0.096076, test_accuracy: 0.918212\n",
      "train_loss: 0.087915, train_accuracy: 0.945507\n",
      "test_loss: 0.096096, test_accuracy: 0.918212\n",
      "train_loss: 0.087929, train_accuracy: 0.945507\n",
      "test_loss: 0.096116, test_accuracy: 0.918212\n",
      "train_loss: 0.087943, train_accuracy: 0.945507\n",
      "test_loss: 0.096136, test_accuracy: 0.918212\n",
      "train_loss: 0.087957, train_accuracy: 0.945507\n",
      "test_loss: 0.096155, test_accuracy: 0.918212\n",
      "train_loss: 0.087971, train_accuracy: 0.945507\n",
      "test_loss: 0.096175, test_accuracy: 0.918212\n",
      "train_loss: 0.087984, train_accuracy: 0.945507\n",
      "test_loss: 0.096194, test_accuracy: 0.918212\n",
      "train_loss: 0.087997, train_accuracy: 0.946463\n",
      "test_loss: 0.096214, test_accuracy: 0.918212\n",
      "train_loss: 0.088011, train_accuracy: 0.946463\n",
      "test_loss: 0.096233, test_accuracy: 0.918212\n",
      "train_loss: 0.088024, train_accuracy: 0.946463\n",
      "test_loss: 0.096252, test_accuracy: 0.918212\n",
      "train_loss: 0.088037, train_accuracy: 0.946463\n",
      "test_loss: 0.096271, test_accuracy: 0.918212\n",
      "train_loss: 0.088049, train_accuracy: 0.946463\n",
      "test_loss: 0.096290, test_accuracy: 0.918212\n",
      "train_loss: 0.088062, train_accuracy: 0.946463\n",
      "test_loss: 0.096308, test_accuracy: 0.918212\n",
      "train_loss: 0.088075, train_accuracy: 0.946463\n",
      "test_loss: 0.096327, test_accuracy: 0.918212\n",
      "train_loss: 0.088087, train_accuracy: 0.946463\n",
      "test_loss: 0.096345, test_accuracy: 0.918212\n",
      "train_loss: 0.088099, train_accuracy: 0.946463\n",
      "test_loss: 0.096364, test_accuracy: 0.918212\n",
      "train_loss: 0.088111, train_accuracy: 0.946463\n",
      "test_loss: 0.096382, test_accuracy: 0.918212\n",
      "train_loss: 0.088123, train_accuracy: 0.946463\n",
      "test_loss: 0.096400, test_accuracy: 0.918212\n",
      "train_loss: 0.088135, train_accuracy: 0.946463\n",
      "test_loss: 0.096418, test_accuracy: 0.919056\n",
      "train_loss: 0.088147, train_accuracy: 0.946463\n",
      "test_loss: 0.096436, test_accuracy: 0.920742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.088159, train_accuracy: 0.946463\n",
      "test_loss: 0.096454, test_accuracy: 0.920742\n",
      "train_loss: 0.088170, train_accuracy: 0.946463\n",
      "test_loss: 0.096471, test_accuracy: 0.921585\n",
      "train_loss: 0.088181, train_accuracy: 0.946463\n",
      "test_loss: 0.096489, test_accuracy: 0.921585\n",
      "train_loss: 0.088193, train_accuracy: 0.946463\n",
      "test_loss: 0.096506, test_accuracy: 0.920742\n",
      "train_loss: 0.088204, train_accuracy: 0.946463\n",
      "test_loss: 0.096524, test_accuracy: 0.920742\n",
      "train_loss: 0.088215, train_accuracy: 0.946463\n",
      "test_loss: 0.096541, test_accuracy: 0.919899\n",
      "train_loss: 0.088225, train_accuracy: 0.946463\n",
      "test_loss: 0.096558, test_accuracy: 0.919899\n",
      "train_loss: 0.088236, train_accuracy: 0.946463\n",
      "test_loss: 0.096575, test_accuracy: 0.919899\n",
      "train_loss: 0.088247, train_accuracy: 0.946463\n",
      "test_loss: 0.096592, test_accuracy: 0.919899\n",
      "train_loss: 0.088257, train_accuracy: 0.946463\n",
      "test_loss: 0.096609, test_accuracy: 0.919899\n",
      "train_loss: 0.088268, train_accuracy: 0.946463\n",
      "test_loss: 0.096625, test_accuracy: 0.919899\n",
      "train_loss: 0.088278, train_accuracy: 0.946463\n",
      "test_loss: 0.096642, test_accuracy: 0.919899\n",
      "train_loss: 0.088288, train_accuracy: 0.947419\n",
      "test_loss: 0.096658, test_accuracy: 0.919899\n",
      "train_loss: 0.088298, train_accuracy: 0.947419\n",
      "test_loss: 0.096675, test_accuracy: 0.919899\n",
      "train_loss: 0.088308, train_accuracy: 0.947419\n",
      "test_loss: 0.096691, test_accuracy: 0.919899\n",
      "train_loss: 0.088317, train_accuracy: 0.947419\n",
      "test_loss: 0.096707, test_accuracy: 0.919899\n",
      "train_loss: 0.088327, train_accuracy: 0.947419\n",
      "test_loss: 0.096723, test_accuracy: 0.919899\n",
      "train_loss: 0.088336, train_accuracy: 0.947419\n",
      "test_loss: 0.096739, test_accuracy: 0.919899\n",
      "train_loss: 0.088346, train_accuracy: 0.947419\n",
      "test_loss: 0.096755, test_accuracy: 0.919899\n",
      "train_loss: 0.088355, train_accuracy: 0.947419\n",
      "test_loss: 0.096771, test_accuracy: 0.919899\n",
      "train_loss: 0.088364, train_accuracy: 0.947419\n",
      "test_loss: 0.096786, test_accuracy: 0.919899\n",
      "train_loss: 0.088373, train_accuracy: 0.947419\n",
      "test_loss: 0.096802, test_accuracy: 0.919899\n",
      "train_loss: 0.088382, train_accuracy: 0.947419\n",
      "test_loss: 0.096817, test_accuracy: 0.919899\n",
      "train_loss: 0.088391, train_accuracy: 0.947419\n",
      "test_loss: 0.096833, test_accuracy: 0.919899\n",
      "train_loss: 0.088399, train_accuracy: 0.948375\n",
      "test_loss: 0.096848, test_accuracy: 0.920742\n",
      "train_loss: 0.088408, train_accuracy: 0.948375\n",
      "test_loss: 0.096863, test_accuracy: 0.920742\n",
      "train_loss: 0.088416, train_accuracy: 0.948375\n",
      "test_loss: 0.096878, test_accuracy: 0.920742\n",
      "train_loss: 0.088425, train_accuracy: 0.948375\n",
      "test_loss: 0.096893, test_accuracy: 0.921585\n",
      "train_loss: 0.088433, train_accuracy: 0.948375\n",
      "test_loss: 0.096908, test_accuracy: 0.921585\n",
      "train_loss: 0.088441, train_accuracy: 0.948375\n",
      "test_loss: 0.096922, test_accuracy: 0.921585\n",
      "train_loss: 0.088449, train_accuracy: 0.948375\n",
      "test_loss: 0.096937, test_accuracy: 0.921585\n",
      "train_loss: 0.088457, train_accuracy: 0.948375\n",
      "test_loss: 0.096952, test_accuracy: 0.921585\n",
      "train_loss: 0.088465, train_accuracy: 0.948375\n",
      "test_loss: 0.096966, test_accuracy: 0.921585\n",
      "train_loss: 0.088472, train_accuracy: 0.948375\n",
      "test_loss: 0.096980, test_accuracy: 0.921585\n",
      "train_loss: 0.088480, train_accuracy: 0.948375\n",
      "test_loss: 0.096995, test_accuracy: 0.921585\n",
      "train_loss: 0.088487, train_accuracy: 0.948375\n",
      "test_loss: 0.097009, test_accuracy: 0.922428\n",
      "train_loss: 0.088495, train_accuracy: 0.949331\n",
      "test_loss: 0.097023, test_accuracy: 0.923271\n",
      "train_loss: 0.088502, train_accuracy: 0.949331\n",
      "test_loss: 0.097037, test_accuracy: 0.923271\n",
      "train_loss: 0.088509, train_accuracy: 0.949331\n",
      "test_loss: 0.097051, test_accuracy: 0.923271\n",
      "train_loss: 0.088516, train_accuracy: 0.949331\n",
      "test_loss: 0.097064, test_accuracy: 0.923271\n",
      "train_loss: 0.088523, train_accuracy: 0.949331\n",
      "test_loss: 0.097078, test_accuracy: 0.923271\n",
      "train_loss: 0.088530, train_accuracy: 0.949331\n",
      "test_loss: 0.097092, test_accuracy: 0.923271\n",
      "train_loss: 0.088537, train_accuracy: 0.949331\n",
      "test_loss: 0.097105, test_accuracy: 0.924115\n",
      "train_loss: 0.088543, train_accuracy: 0.949331\n",
      "test_loss: 0.097119, test_accuracy: 0.924115\n",
      "train_loss: 0.088550, train_accuracy: 0.949331\n",
      "test_loss: 0.097132, test_accuracy: 0.924115\n",
      "train_loss: 0.088556, train_accuracy: 0.949331\n",
      "test_loss: 0.097145, test_accuracy: 0.924115\n",
      "train_loss: 0.088562, train_accuracy: 0.949331\n",
      "test_loss: 0.097158, test_accuracy: 0.924958\n",
      "train_loss: 0.088569, train_accuracy: 0.949331\n",
      "test_loss: 0.097171, test_accuracy: 0.924958\n",
      "train_loss: 0.088575, train_accuracy: 0.949331\n",
      "test_loss: 0.097184, test_accuracy: 0.924958\n",
      "train_loss: 0.088581, train_accuracy: 0.949331\n",
      "test_loss: 0.097197, test_accuracy: 0.924958\n",
      "train_loss: 0.088587, train_accuracy: 0.949331\n",
      "test_loss: 0.097210, test_accuracy: 0.924958\n",
      "train_loss: 0.088593, train_accuracy: 0.949331\n",
      "test_loss: 0.097223, test_accuracy: 0.924958\n",
      "train_loss: 0.088598, train_accuracy: 0.949331\n",
      "test_loss: 0.097235, test_accuracy: 0.924958\n",
      "train_loss: 0.088604, train_accuracy: 0.949331\n",
      "test_loss: 0.097248, test_accuracy: 0.924958\n",
      "train_loss: 0.088610, train_accuracy: 0.949331\n",
      "test_loss: 0.097260, test_accuracy: 0.924958\n",
      "train_loss: 0.088615, train_accuracy: 0.949331\n",
      "test_loss: 0.097273, test_accuracy: 0.924958\n",
      "train_loss: 0.088620, train_accuracy: 0.950287\n",
      "test_loss: 0.097285, test_accuracy: 0.924958\n",
      "train_loss: 0.088626, train_accuracy: 0.950287\n",
      "test_loss: 0.097297, test_accuracy: 0.924958\n",
      "train_loss: 0.088631, train_accuracy: 0.950287\n",
      "test_loss: 0.097309, test_accuracy: 0.924958\n",
      "train_loss: 0.088636, train_accuracy: 0.950287\n",
      "test_loss: 0.097321, test_accuracy: 0.924958\n",
      "train_loss: 0.088641, train_accuracy: 0.950287\n",
      "test_loss: 0.097333, test_accuracy: 0.924958\n",
      "train_loss: 0.088646, train_accuracy: 0.950287\n",
      "test_loss: 0.097345, test_accuracy: 0.924958\n",
      "train_loss: 0.088651, train_accuracy: 0.950287\n",
      "test_loss: 0.097357, test_accuracy: 0.925801\n",
      "train_loss: 0.088656, train_accuracy: 0.950287\n",
      "test_loss: 0.097369, test_accuracy: 0.925801\n",
      "train_loss: 0.088660, train_accuracy: 0.950287\n",
      "test_loss: 0.097380, test_accuracy: 0.925801\n",
      "train_loss: 0.088665, train_accuracy: 0.950287\n",
      "test_loss: 0.097392, test_accuracy: 0.925801\n",
      "train_loss: 0.088669, train_accuracy: 0.950287\n",
      "test_loss: 0.097403, test_accuracy: 0.925801\n",
      "train_loss: 0.088674, train_accuracy: 0.951243\n",
      "test_loss: 0.097415, test_accuracy: 0.925801\n",
      "train_loss: 0.088678, train_accuracy: 0.951243\n",
      "test_loss: 0.097426, test_accuracy: 0.925801\n",
      "train_loss: 0.088682, train_accuracy: 0.951243\n",
      "test_loss: 0.097437, test_accuracy: 0.924958\n",
      "train_loss: 0.088686, train_accuracy: 0.951243\n",
      "test_loss: 0.097449, test_accuracy: 0.924958\n",
      "train_loss: 0.088690, train_accuracy: 0.951243\n",
      "test_loss: 0.097460, test_accuracy: 0.924958\n",
      "train_loss: 0.088694, train_accuracy: 0.951243\n",
      "test_loss: 0.097471, test_accuracy: 0.924958\n",
      "train_loss: 0.088698, train_accuracy: 0.951243\n",
      "test_loss: 0.097482, test_accuracy: 0.924958\n",
      "train_loss: 0.088702, train_accuracy: 0.951243\n",
      "test_loss: 0.097493, test_accuracy: 0.924958\n",
      "train_loss: 0.088706, train_accuracy: 0.951243\n",
      "test_loss: 0.097503, test_accuracy: 0.924958\n",
      "train_loss: 0.088710, train_accuracy: 0.952199\n",
      "test_loss: 0.097514, test_accuracy: 0.924958\n",
      "train_loss: 0.088713, train_accuracy: 0.952199\n",
      "test_loss: 0.097525, test_accuracy: 0.924958\n",
      "train_loss: 0.088717, train_accuracy: 0.952199\n",
      "test_loss: 0.097535, test_accuracy: 0.924958\n",
      "train_loss: 0.088720, train_accuracy: 0.952199\n",
      "test_loss: 0.097546, test_accuracy: 0.924958\n",
      "train_loss: 0.088724, train_accuracy: 0.952199\n",
      "test_loss: 0.097556, test_accuracy: 0.924958\n",
      "train_loss: 0.088727, train_accuracy: 0.952199\n",
      "test_loss: 0.097567, test_accuracy: 0.924958\n",
      "train_loss: 0.088730, train_accuracy: 0.952199\n",
      "test_loss: 0.097577, test_accuracy: 0.924958\n",
      "train_loss: 0.088733, train_accuracy: 0.952199\n",
      "test_loss: 0.097587, test_accuracy: 0.924958\n",
      "train_loss: 0.088736, train_accuracy: 0.952199\n",
      "test_loss: 0.097598, test_accuracy: 0.924958\n",
      "train_loss: 0.088739, train_accuracy: 0.952199\n",
      "test_loss: 0.097608, test_accuracy: 0.924958\n",
      "train_loss: 0.088742, train_accuracy: 0.952199\n",
      "test_loss: 0.097618, test_accuracy: 0.924958\n",
      "train_loss: 0.088745, train_accuracy: 0.952199\n",
      "test_loss: 0.097628, test_accuracy: 0.924958\n",
      "train_loss: 0.088748, train_accuracy: 0.952199\n",
      "test_loss: 0.097638, test_accuracy: 0.924958\n",
      "train_loss: 0.088750, train_accuracy: 0.953155\n",
      "test_loss: 0.097647, test_accuracy: 0.924958\n",
      "train_loss: 0.088753, train_accuracy: 0.953155\n",
      "test_loss: 0.097657, test_accuracy: 0.924958\n",
      "train_loss: 0.088756, train_accuracy: 0.953155\n",
      "test_loss: 0.097667, test_accuracy: 0.924115\n",
      "train_loss: 0.088758, train_accuracy: 0.953155\n",
      "test_loss: 0.097677, test_accuracy: 0.924115\n",
      "train_loss: 0.088761, train_accuracy: 0.953155\n",
      "test_loss: 0.097686, test_accuracy: 0.924115\n",
      "train_loss: 0.088763, train_accuracy: 0.953155\n",
      "test_loss: 0.097696, test_accuracy: 0.924115\n",
      "train_loss: 0.088765, train_accuracy: 0.953155\n",
      "test_loss: 0.097705, test_accuracy: 0.924115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.088767, train_accuracy: 0.953155\n",
      "test_loss: 0.097714, test_accuracy: 0.924115\n",
      "train_loss: 0.088770, train_accuracy: 0.953155\n",
      "test_loss: 0.097724, test_accuracy: 0.924115\n",
      "train_loss: 0.088772, train_accuracy: 0.953155\n",
      "test_loss: 0.097733, test_accuracy: 0.924115\n",
      "train_loss: 0.088774, train_accuracy: 0.953155\n",
      "test_loss: 0.097742, test_accuracy: 0.924115\n",
      "train_loss: 0.088776, train_accuracy: 0.953155\n",
      "test_loss: 0.097751, test_accuracy: 0.924115\n",
      "train_loss: 0.088778, train_accuracy: 0.953155\n",
      "test_loss: 0.097760, test_accuracy: 0.924115\n",
      "train_loss: 0.088779, train_accuracy: 0.953155\n",
      "test_loss: 0.097769, test_accuracy: 0.924115\n",
      "train_loss: 0.088781, train_accuracy: 0.953155\n",
      "test_loss: 0.097778, test_accuracy: 0.924115\n",
      "train_loss: 0.088783, train_accuracy: 0.953155\n",
      "test_loss: 0.097787, test_accuracy: 0.924115\n",
      "train_loss: 0.088785, train_accuracy: 0.953155\n",
      "test_loss: 0.097796, test_accuracy: 0.924115\n",
      "train_loss: 0.088786, train_accuracy: 0.953155\n",
      "test_loss: 0.097805, test_accuracy: 0.924115\n",
      "train_loss: 0.088788, train_accuracy: 0.953155\n",
      "test_loss: 0.097814, test_accuracy: 0.924958\n",
      "train_loss: 0.088789, train_accuracy: 0.953155\n",
      "test_loss: 0.097822, test_accuracy: 0.924958\n",
      "train_loss: 0.088790, train_accuracy: 0.953155\n",
      "test_loss: 0.097831, test_accuracy: 0.924958\n",
      "train_loss: 0.088792, train_accuracy: 0.953155\n",
      "test_loss: 0.097839, test_accuracy: 0.924958\n",
      "train_loss: 0.088793, train_accuracy: 0.953155\n",
      "test_loss: 0.097848, test_accuracy: 0.924958\n",
      "train_loss: 0.088794, train_accuracy: 0.953155\n",
      "test_loss: 0.097856, test_accuracy: 0.924958\n",
      "train_loss: 0.088795, train_accuracy: 0.953155\n",
      "test_loss: 0.097865, test_accuracy: 0.924958\n",
      "train_loss: 0.088797, train_accuracy: 0.953155\n",
      "test_loss: 0.097873, test_accuracy: 0.924958\n",
      "train_loss: 0.088798, train_accuracy: 0.953155\n",
      "test_loss: 0.097881, test_accuracy: 0.924958\n",
      "train_loss: 0.088799, train_accuracy: 0.953155\n",
      "test_loss: 0.097890, test_accuracy: 0.924958\n",
      "train_loss: 0.088800, train_accuracy: 0.953155\n",
      "test_loss: 0.097898, test_accuracy: 0.924958\n",
      "train_loss: 0.088800, train_accuracy: 0.953155\n",
      "test_loss: 0.097906, test_accuracy: 0.924958\n",
      "train_loss: 0.088801, train_accuracy: 0.953155\n",
      "test_loss: 0.097914, test_accuracy: 0.924958\n",
      "train_loss: 0.088802, train_accuracy: 0.953155\n",
      "test_loss: 0.097922, test_accuracy: 0.924958\n",
      "train_loss: 0.088803, train_accuracy: 0.953155\n",
      "test_loss: 0.097930, test_accuracy: 0.924958\n",
      "train_loss: 0.088803, train_accuracy: 0.953155\n",
      "test_loss: 0.097938, test_accuracy: 0.924958\n",
      "train_loss: 0.088804, train_accuracy: 0.953155\n",
      "test_loss: 0.097946, test_accuracy: 0.924958\n",
      "train_loss: 0.088805, train_accuracy: 0.954111\n",
      "test_loss: 0.097953, test_accuracy: 0.924958\n",
      "train_loss: 0.088805, train_accuracy: 0.954111\n",
      "test_loss: 0.097961, test_accuracy: 0.924958\n",
      "train_loss: 0.088806, train_accuracy: 0.954111\n",
      "test_loss: 0.097969, test_accuracy: 0.924958\n",
      "train_loss: 0.088806, train_accuracy: 0.954111\n",
      "test_loss: 0.097976, test_accuracy: 0.924958\n",
      "train_loss: 0.088806, train_accuracy: 0.954111\n",
      "test_loss: 0.097984, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.097991, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.097999, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.098006, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.098014, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.098021, test_accuracy: 0.924958\n",
      "train_loss: 0.088808, train_accuracy: 0.954111\n",
      "test_loss: 0.098028, test_accuracy: 0.924958\n",
      "train_loss: 0.088808, train_accuracy: 0.954111\n",
      "test_loss: 0.098036, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.098043, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.098050, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.954111\n",
      "test_loss: 0.098057, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.955067\n",
      "test_loss: 0.098064, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.955067\n",
      "test_loss: 0.098071, test_accuracy: 0.924958\n",
      "train_loss: 0.088807, train_accuracy: 0.955067\n",
      "test_loss: 0.098078, test_accuracy: 0.924958\n",
      "train_loss: 0.088806, train_accuracy: 0.955067\n",
      "test_loss: 0.098085, test_accuracy: 0.924115\n",
      "train_loss: 0.088806, train_accuracy: 0.955067\n",
      "test_loss: 0.098092, test_accuracy: 0.923271\n",
      "train_loss: 0.088806, train_accuracy: 0.955067\n",
      "test_loss: 0.098099, test_accuracy: 0.923271\n",
      "train_loss: 0.088805, train_accuracy: 0.955067\n",
      "test_loss: 0.098105, test_accuracy: 0.923271\n",
      "train_loss: 0.088805, train_accuracy: 0.955067\n",
      "test_loss: 0.098112, test_accuracy: 0.923271\n",
      "train_loss: 0.088804, train_accuracy: 0.955067\n",
      "test_loss: 0.098119, test_accuracy: 0.923271\n",
      "train_loss: 0.088804, train_accuracy: 0.955067\n",
      "test_loss: 0.098125, test_accuracy: 0.923271\n",
      "train_loss: 0.088803, train_accuracy: 0.955067\n",
      "test_loss: 0.098132, test_accuracy: 0.923271\n",
      "train_loss: 0.088802, train_accuracy: 0.955067\n",
      "test_loss: 0.098139, test_accuracy: 0.923271\n",
      "train_loss: 0.088802, train_accuracy: 0.955067\n",
      "test_loss: 0.098145, test_accuracy: 0.922428\n",
      "train_loss: 0.088801, train_accuracy: 0.955067\n",
      "test_loss: 0.098152, test_accuracy: 0.922428\n",
      "train_loss: 0.088800, train_accuracy: 0.955067\n",
      "test_loss: 0.098158, test_accuracy: 0.922428\n",
      "train_loss: 0.088799, train_accuracy: 0.955067\n",
      "test_loss: 0.098164, test_accuracy: 0.922428\n",
      "train_loss: 0.088799, train_accuracy: 0.955067\n",
      "test_loss: 0.098171, test_accuracy: 0.922428\n",
      "train_loss: 0.088798, train_accuracy: 0.955067\n",
      "test_loss: 0.098177, test_accuracy: 0.922428\n",
      "train_loss: 0.088797, train_accuracy: 0.955067\n",
      "test_loss: 0.098183, test_accuracy: 0.922428\n",
      "train_loss: 0.088796, train_accuracy: 0.955067\n",
      "test_loss: 0.098189, test_accuracy: 0.922428\n",
      "train_loss: 0.088795, train_accuracy: 0.955067\n",
      "test_loss: 0.098196, test_accuracy: 0.922428\n",
      "train_loss: 0.088794, train_accuracy: 0.955067\n",
      "test_loss: 0.098202, test_accuracy: 0.922428\n",
      "train_loss: 0.088793, train_accuracy: 0.955067\n",
      "test_loss: 0.098208, test_accuracy: 0.922428\n",
      "train_loss: 0.088792, train_accuracy: 0.955067\n",
      "test_loss: 0.098214, test_accuracy: 0.922428\n",
      "train_loss: 0.088790, train_accuracy: 0.955067\n",
      "test_loss: 0.098220, test_accuracy: 0.922428\n",
      "train_loss: 0.088789, train_accuracy: 0.955067\n",
      "test_loss: 0.098226, test_accuracy: 0.922428\n",
      "train_loss: 0.088788, train_accuracy: 0.955067\n",
      "test_loss: 0.098232, test_accuracy: 0.922428\n",
      "train_loss: 0.088787, train_accuracy: 0.955067\n",
      "test_loss: 0.098238, test_accuracy: 0.922428\n",
      "train_loss: 0.088785, train_accuracy: 0.955067\n",
      "test_loss: 0.098244, test_accuracy: 0.922428\n",
      "train_loss: 0.088784, train_accuracy: 0.956023\n",
      "test_loss: 0.098250, test_accuracy: 0.922428\n",
      "train_loss: 0.088783, train_accuracy: 0.956023\n",
      "test_loss: 0.098255, test_accuracy: 0.923271\n",
      "train_loss: 0.088781, train_accuracy: 0.956023\n",
      "test_loss: 0.098261, test_accuracy: 0.923271\n",
      "train_loss: 0.088780, train_accuracy: 0.956023\n",
      "test_loss: 0.098267, test_accuracy: 0.923271\n",
      "train_loss: 0.088779, train_accuracy: 0.956023\n",
      "test_loss: 0.098272, test_accuracy: 0.923271\n",
      "train_loss: 0.088777, train_accuracy: 0.956023\n",
      "test_loss: 0.098278, test_accuracy: 0.923271\n",
      "train_loss: 0.088776, train_accuracy: 0.956023\n",
      "test_loss: 0.098284, test_accuracy: 0.923271\n",
      "train_loss: 0.088774, train_accuracy: 0.956023\n",
      "test_loss: 0.098289, test_accuracy: 0.923271\n",
      "train_loss: 0.088772, train_accuracy: 0.956023\n",
      "test_loss: 0.098295, test_accuracy: 0.923271\n",
      "train_loss: 0.088771, train_accuracy: 0.956023\n",
      "test_loss: 0.098300, test_accuracy: 0.923271\n",
      "train_loss: 0.088769, train_accuracy: 0.956023\n",
      "test_loss: 0.098306, test_accuracy: 0.923271\n",
      "train_loss: 0.088767, train_accuracy: 0.956023\n",
      "test_loss: 0.098311, test_accuracy: 0.923271\n",
      "train_loss: 0.088766, train_accuracy: 0.956023\n",
      "test_loss: 0.098317, test_accuracy: 0.923271\n",
      "train_loss: 0.088764, train_accuracy: 0.956023\n",
      "test_loss: 0.098322, test_accuracy: 0.923271\n",
      "train_loss: 0.088762, train_accuracy: 0.956023\n",
      "test_loss: 0.098327, test_accuracy: 0.923271\n",
      "train_loss: 0.088760, train_accuracy: 0.956023\n",
      "test_loss: 0.098333, test_accuracy: 0.923271\n",
      "train_loss: 0.088759, train_accuracy: 0.956023\n",
      "test_loss: 0.098338, test_accuracy: 0.923271\n",
      "train_loss: 0.088757, train_accuracy: 0.956023\n",
      "test_loss: 0.098343, test_accuracy: 0.923271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.088755, train_accuracy: 0.956023\n",
      "test_loss: 0.098348, test_accuracy: 0.923271\n",
      "train_loss: 0.088753, train_accuracy: 0.956023\n",
      "test_loss: 0.098354, test_accuracy: 0.923271\n",
      "train_loss: 0.088751, train_accuracy: 0.956023\n",
      "test_loss: 0.098359, test_accuracy: 0.923271\n",
      "train_loss: 0.088749, train_accuracy: 0.956023\n",
      "test_loss: 0.098364, test_accuracy: 0.923271\n",
      "train_loss: 0.088747, train_accuracy: 0.956023\n",
      "test_loss: 0.098369, test_accuracy: 0.923271\n",
      "train_loss: 0.088745, train_accuracy: 0.956023\n",
      "test_loss: 0.098374, test_accuracy: 0.923271\n",
      "train_loss: 0.088743, train_accuracy: 0.956023\n",
      "test_loss: 0.098379, test_accuracy: 0.923271\n",
      "train_loss: 0.088741, train_accuracy: 0.956023\n",
      "test_loss: 0.098384, test_accuracy: 0.923271\n",
      "train_loss: 0.088739, train_accuracy: 0.956023\n",
      "test_loss: 0.098389, test_accuracy: 0.923271\n",
      "train_loss: 0.088737, train_accuracy: 0.956023\n",
      "test_loss: 0.098394, test_accuracy: 0.923271\n",
      "train_loss: 0.088735, train_accuracy: 0.956023\n",
      "test_loss: 0.098399, test_accuracy: 0.923271\n",
      "train_loss: 0.088732, train_accuracy: 0.956023\n",
      "test_loss: 0.098403, test_accuracy: 0.923271\n",
      "train_loss: 0.088730, train_accuracy: 0.956023\n",
      "test_loss: 0.098408, test_accuracy: 0.923271\n",
      "train_loss: 0.088728, train_accuracy: 0.956023\n",
      "test_loss: 0.098413, test_accuracy: 0.923271\n",
      "train_loss: 0.088726, train_accuracy: 0.956023\n",
      "test_loss: 0.098418, test_accuracy: 0.923271\n",
      "train_loss: 0.088723, train_accuracy: 0.956023\n",
      "test_loss: 0.098422, test_accuracy: 0.923271\n",
      "train_loss: 0.088721, train_accuracy: 0.956023\n",
      "test_loss: 0.098427, test_accuracy: 0.923271\n",
      "train_loss: 0.088719, train_accuracy: 0.956023\n",
      "test_loss: 0.098432, test_accuracy: 0.923271\n",
      "train_loss: 0.088716, train_accuracy: 0.956023\n",
      "test_loss: 0.098436, test_accuracy: 0.923271\n",
      "train_loss: 0.088714, train_accuracy: 0.955067\n",
      "test_loss: 0.098441, test_accuracy: 0.923271\n",
      "train_loss: 0.088712, train_accuracy: 0.955067\n",
      "test_loss: 0.098446, test_accuracy: 0.923271\n",
      "train_loss: 0.088709, train_accuracy: 0.955067\n",
      "test_loss: 0.098450, test_accuracy: 0.923271\n",
      "train_loss: 0.088707, train_accuracy: 0.955067\n",
      "test_loss: 0.098455, test_accuracy: 0.923271\n",
      "train_loss: 0.088704, train_accuracy: 0.955067\n",
      "test_loss: 0.098459, test_accuracy: 0.923271\n",
      "train_loss: 0.088702, train_accuracy: 0.955067\n",
      "test_loss: 0.098464, test_accuracy: 0.923271\n",
      "train_loss: 0.088699, train_accuracy: 0.955067\n",
      "test_loss: 0.098468, test_accuracy: 0.923271\n",
      "train_loss: 0.088697, train_accuracy: 0.955067\n",
      "test_loss: 0.098473, test_accuracy: 0.923271\n",
      "train_loss: 0.088694, train_accuracy: 0.955067\n",
      "test_loss: 0.098477, test_accuracy: 0.923271\n",
      "train_loss: 0.088692, train_accuracy: 0.955067\n",
      "test_loss: 0.098481, test_accuracy: 0.923271\n",
      "train_loss: 0.088689, train_accuracy: 0.955067\n",
      "test_loss: 0.098486, test_accuracy: 0.923271\n",
      "train_loss: 0.088686, train_accuracy: 0.955067\n",
      "test_loss: 0.098490, test_accuracy: 0.923271\n",
      "train_loss: 0.088684, train_accuracy: 0.955067\n",
      "test_loss: 0.098494, test_accuracy: 0.923271\n",
      "train_loss: 0.088681, train_accuracy: 0.955067\n",
      "test_loss: 0.098499, test_accuracy: 0.923271\n",
      "train_loss: 0.088678, train_accuracy: 0.955067\n",
      "test_loss: 0.098503, test_accuracy: 0.923271\n",
      "train_loss: 0.088676, train_accuracy: 0.955067\n",
      "test_loss: 0.098507, test_accuracy: 0.923271\n",
      "train_loss: 0.088673, train_accuracy: 0.956023\n",
      "test_loss: 0.098511, test_accuracy: 0.923271\n",
      "train_loss: 0.088670, train_accuracy: 0.956023\n",
      "test_loss: 0.098515, test_accuracy: 0.923271\n",
      "train_loss: 0.088668, train_accuracy: 0.956023\n",
      "test_loss: 0.098519, test_accuracy: 0.923271\n",
      "train_loss: 0.088665, train_accuracy: 0.956023\n",
      "test_loss: 0.098524, test_accuracy: 0.923271\n",
      "train_loss: 0.088662, train_accuracy: 0.956979\n",
      "test_loss: 0.098528, test_accuracy: 0.923271\n",
      "train_loss: 0.088659, train_accuracy: 0.956979\n",
      "test_loss: 0.098532, test_accuracy: 0.923271\n",
      "train_loss: 0.088656, train_accuracy: 0.956979\n",
      "test_loss: 0.098536, test_accuracy: 0.923271\n",
      "train_loss: 0.088654, train_accuracy: 0.956979\n",
      "test_loss: 0.098540, test_accuracy: 0.923271\n",
      "train_loss: 0.088651, train_accuracy: 0.956979\n",
      "test_loss: 0.098544, test_accuracy: 0.923271\n",
      "train_loss: 0.088648, train_accuracy: 0.956979\n",
      "test_loss: 0.098548, test_accuracy: 0.923271\n",
      "train_loss: 0.088645, train_accuracy: 0.956979\n",
      "test_loss: 0.098552, test_accuracy: 0.923271\n",
      "train_loss: 0.088642, train_accuracy: 0.956979\n",
      "test_loss: 0.098556, test_accuracy: 0.923271\n",
      "train_loss: 0.088639, train_accuracy: 0.956979\n",
      "test_loss: 0.098559, test_accuracy: 0.923271\n",
      "train_loss: 0.088636, train_accuracy: 0.956979\n",
      "test_loss: 0.098563, test_accuracy: 0.923271\n",
      "train_loss: 0.088633, train_accuracy: 0.956979\n",
      "test_loss: 0.098567, test_accuracy: 0.923271\n",
      "train_loss: 0.088630, train_accuracy: 0.956979\n",
      "test_loss: 0.098571, test_accuracy: 0.923271\n",
      "train_loss: 0.088627, train_accuracy: 0.956979\n",
      "test_loss: 0.098575, test_accuracy: 0.923271\n",
      "train_loss: 0.088624, train_accuracy: 0.956979\n",
      "test_loss: 0.098579, test_accuracy: 0.924115\n",
      "train_loss: 0.088621, train_accuracy: 0.956979\n",
      "test_loss: 0.098582, test_accuracy: 0.924115\n",
      "train_loss: 0.088618, train_accuracy: 0.956979\n",
      "test_loss: 0.098586, test_accuracy: 0.924115\n",
      "train_loss: 0.088615, train_accuracy: 0.956979\n",
      "test_loss: 0.098590, test_accuracy: 0.924115\n",
      "train_loss: 0.088612, train_accuracy: 0.956979\n",
      "test_loss: 0.098593, test_accuracy: 0.924958\n",
      "train_loss: 0.088609, train_accuracy: 0.956979\n",
      "test_loss: 0.098597, test_accuracy: 0.924958\n",
      "train_loss: 0.088606, train_accuracy: 0.956979\n",
      "test_loss: 0.098601, test_accuracy: 0.924958\n",
      "train_loss: 0.088603, train_accuracy: 0.956979\n",
      "test_loss: 0.098604, test_accuracy: 0.924958\n",
      "train_loss: 0.088600, train_accuracy: 0.956979\n",
      "test_loss: 0.098608, test_accuracy: 0.924958\n",
      "train_loss: 0.088596, train_accuracy: 0.956979\n",
      "test_loss: 0.098611, test_accuracy: 0.924958\n",
      "train_loss: 0.088593, train_accuracy: 0.956979\n",
      "test_loss: 0.098615, test_accuracy: 0.924958\n",
      "train_loss: 0.088590, train_accuracy: 0.956979\n",
      "test_loss: 0.098619, test_accuracy: 0.924958\n",
      "train_loss: 0.088587, train_accuracy: 0.956979\n",
      "test_loss: 0.098622, test_accuracy: 0.924958\n",
      "train_loss: 0.088584, train_accuracy: 0.956979\n",
      "test_loss: 0.098626, test_accuracy: 0.924958\n",
      "train_loss: 0.088580, train_accuracy: 0.956979\n",
      "test_loss: 0.098629, test_accuracy: 0.924958\n",
      "train_loss: 0.088577, train_accuracy: 0.956979\n",
      "test_loss: 0.098633, test_accuracy: 0.924958\n",
      "train_loss: 0.088574, train_accuracy: 0.956979\n",
      "test_loss: 0.098636, test_accuracy: 0.924958\n",
      "train_loss: 0.088571, train_accuracy: 0.956979\n",
      "test_loss: 0.098639, test_accuracy: 0.924958\n",
      "train_loss: 0.088567, train_accuracy: 0.956979\n",
      "test_loss: 0.098643, test_accuracy: 0.924958\n",
      "train_loss: 0.088564, train_accuracy: 0.956979\n",
      "test_loss: 0.098646, test_accuracy: 0.926644\n",
      "train_loss: 0.088561, train_accuracy: 0.956979\n",
      "test_loss: 0.098649, test_accuracy: 0.926644\n",
      "train_loss: 0.088558, train_accuracy: 0.956979\n",
      "test_loss: 0.098653, test_accuracy: 0.926644\n",
      "train_loss: 0.088554, train_accuracy: 0.956979\n",
      "test_loss: 0.098656, test_accuracy: 0.926644\n",
      "train_loss: 0.088551, train_accuracy: 0.956979\n",
      "test_loss: 0.098659, test_accuracy: 0.926644\n",
      "train_loss: 0.088548, train_accuracy: 0.956979\n",
      "test_loss: 0.098663, test_accuracy: 0.926644\n",
      "train_loss: 0.088544, train_accuracy: 0.956979\n",
      "test_loss: 0.098666, test_accuracy: 0.926644\n",
      "train_loss: 0.088541, train_accuracy: 0.956979\n",
      "test_loss: 0.098669, test_accuracy: 0.926644\n",
      "train_loss: 0.088538, train_accuracy: 0.956979\n",
      "test_loss: 0.098672, test_accuracy: 0.926644\n",
      "train_loss: 0.088534, train_accuracy: 0.957935\n",
      "test_loss: 0.098676, test_accuracy: 0.926644\n",
      "train_loss: 0.088531, train_accuracy: 0.957935\n",
      "test_loss: 0.098679, test_accuracy: 0.926644\n",
      "train_loss: 0.088527, train_accuracy: 0.957935\n",
      "test_loss: 0.098682, test_accuracy: 0.926644\n",
      "train_loss: 0.088524, train_accuracy: 0.957935\n",
      "test_loss: 0.098685, test_accuracy: 0.926644\n",
      "train_loss: 0.088521, train_accuracy: 0.957935\n",
      "test_loss: 0.098688, test_accuracy: 0.926644\n",
      "train_loss: 0.088517, train_accuracy: 0.957935\n",
      "test_loss: 0.098691, test_accuracy: 0.926644\n",
      "train_loss: 0.088514, train_accuracy: 0.957935\n",
      "test_loss: 0.098694, test_accuracy: 0.926644\n",
      "train_loss: 0.088510, train_accuracy: 0.957935\n",
      "test_loss: 0.098698, test_accuracy: 0.926644\n",
      "train_loss: 0.088507, train_accuracy: 0.957935\n",
      "test_loss: 0.098701, test_accuracy: 0.926644\n",
      "train_loss: 0.088503, train_accuracy: 0.957935\n",
      "test_loss: 0.098704, test_accuracy: 0.926644\n",
      "train_loss: 0.088500, train_accuracy: 0.957935\n",
      "test_loss: 0.098707, test_accuracy: 0.926644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.088496, train_accuracy: 0.957935\n",
      "test_loss: 0.098710, test_accuracy: 0.926644\n",
      "train_loss: 0.088493, train_accuracy: 0.957935\n",
      "test_loss: 0.098713, test_accuracy: 0.926644\n",
      "train_loss: 0.088489, train_accuracy: 0.957935\n",
      "test_loss: 0.098716, test_accuracy: 0.926644\n",
      "train_loss: 0.088486, train_accuracy: 0.957935\n",
      "test_loss: 0.098719, test_accuracy: 0.926644\n",
      "train_loss: 0.088482, train_accuracy: 0.957935\n",
      "test_loss: 0.098722, test_accuracy: 0.926644\n",
      "train_loss: 0.088479, train_accuracy: 0.957935\n",
      "test_loss: 0.098725, test_accuracy: 0.926644\n",
      "train_loss: 0.088475, train_accuracy: 0.957935\n",
      "test_loss: 0.098727, test_accuracy: 0.926644\n",
      "train_loss: 0.088472, train_accuracy: 0.957935\n",
      "test_loss: 0.098730, test_accuracy: 0.926644\n",
      "train_loss: 0.088468, train_accuracy: 0.957935\n",
      "test_loss: 0.098733, test_accuracy: 0.926644\n",
      "train_loss: 0.088465, train_accuracy: 0.957935\n",
      "test_loss: 0.098736, test_accuracy: 0.926644\n",
      "train_loss: 0.088461, train_accuracy: 0.957935\n",
      "test_loss: 0.098739, test_accuracy: 0.926644\n",
      "train_loss: 0.088457, train_accuracy: 0.958891\n",
      "test_loss: 0.098742, test_accuracy: 0.926644\n",
      "train_loss: 0.088454, train_accuracy: 0.958891\n",
      "test_loss: 0.098745, test_accuracy: 0.926644\n",
      "train_loss: 0.088450, train_accuracy: 0.958891\n",
      "test_loss: 0.098747, test_accuracy: 0.925801\n",
      "train_loss: 0.088447, train_accuracy: 0.958891\n",
      "test_loss: 0.098750, test_accuracy: 0.925801\n",
      "train_loss: 0.088443, train_accuracy: 0.958891\n",
      "test_loss: 0.098753, test_accuracy: 0.925801\n",
      "train_loss: 0.088439, train_accuracy: 0.958891\n",
      "test_loss: 0.098756, test_accuracy: 0.925801\n",
      "train_loss: 0.088436, train_accuracy: 0.958891\n",
      "test_loss: 0.098758, test_accuracy: 0.925801\n",
      "train_loss: 0.088432, train_accuracy: 0.958891\n",
      "test_loss: 0.098761, test_accuracy: 0.925801\n",
      "train_loss: 0.088429, train_accuracy: 0.958891\n",
      "test_loss: 0.098764, test_accuracy: 0.925801\n",
      "train_loss: 0.088425, train_accuracy: 0.958891\n",
      "test_loss: 0.098767, test_accuracy: 0.925801\n",
      "train_loss: 0.088421, train_accuracy: 0.958891\n",
      "test_loss: 0.098769, test_accuracy: 0.925801\n",
      "train_loss: 0.088418, train_accuracy: 0.958891\n",
      "test_loss: 0.098772, test_accuracy: 0.925801\n",
      "train_loss: 0.088414, train_accuracy: 0.958891\n",
      "test_loss: 0.098775, test_accuracy: 0.925801\n",
      "train_loss: 0.088410, train_accuracy: 0.958891\n",
      "test_loss: 0.098777, test_accuracy: 0.925801\n",
      "train_loss: 0.088407, train_accuracy: 0.958891\n",
      "test_loss: 0.098780, test_accuracy: 0.925801\n",
      "train_loss: 0.088403, train_accuracy: 0.958891\n",
      "test_loss: 0.098782, test_accuracy: 0.925801\n",
      "train_loss: 0.088399, train_accuracy: 0.958891\n",
      "test_loss: 0.098785, test_accuracy: 0.925801\n",
      "train_loss: 0.088396, train_accuracy: 0.958891\n",
      "test_loss: 0.098788, test_accuracy: 0.925801\n",
      "train_loss: 0.088392, train_accuracy: 0.958891\n",
      "test_loss: 0.098790, test_accuracy: 0.925801\n",
      "train_loss: 0.088388, train_accuracy: 0.958891\n",
      "test_loss: 0.098793, test_accuracy: 0.925801\n",
      "train_loss: 0.088384, train_accuracy: 0.958891\n",
      "test_loss: 0.098795, test_accuracy: 0.925801\n",
      "train_loss: 0.088381, train_accuracy: 0.958891\n",
      "test_loss: 0.098798, test_accuracy: 0.925801\n",
      "train_loss: 0.088377, train_accuracy: 0.958891\n",
      "test_loss: 0.098800, test_accuracy: 0.925801\n",
      "train_loss: 0.088373, train_accuracy: 0.958891\n",
      "test_loss: 0.098803, test_accuracy: 0.925801\n",
      "train_loss: 0.088370, train_accuracy: 0.958891\n",
      "test_loss: 0.098805, test_accuracy: 0.925801\n",
      "train_loss: 0.088366, train_accuracy: 0.958891\n",
      "test_loss: 0.098808, test_accuracy: 0.926644\n",
      "train_loss: 0.088362, train_accuracy: 0.958891\n",
      "test_loss: 0.098810, test_accuracy: 0.926644\n",
      "train_loss: 0.088358, train_accuracy: 0.958891\n",
      "test_loss: 0.098813, test_accuracy: 0.926644\n",
      "train_loss: 0.088355, train_accuracy: 0.958891\n",
      "test_loss: 0.098815, test_accuracy: 0.926644\n",
      "train_loss: 0.088351, train_accuracy: 0.958891\n",
      "test_loss: 0.098817, test_accuracy: 0.926644\n",
      "train_loss: 0.088347, train_accuracy: 0.958891\n",
      "test_loss: 0.098820, test_accuracy: 0.925801\n",
      "train_loss: 0.088343, train_accuracy: 0.958891\n",
      "test_loss: 0.098822, test_accuracy: 0.925801\n",
      "train_loss: 0.088340, train_accuracy: 0.958891\n",
      "test_loss: 0.098825, test_accuracy: 0.925801\n",
      "train_loss: 0.088336, train_accuracy: 0.958891\n",
      "test_loss: 0.098827, test_accuracy: 0.926644\n",
      "train_loss: 0.088332, train_accuracy: 0.958891\n",
      "test_loss: 0.098829, test_accuracy: 0.926644\n",
      "train_loss: 0.088328, train_accuracy: 0.958891\n",
      "test_loss: 0.098832, test_accuracy: 0.926644\n",
      "train_loss: 0.088325, train_accuracy: 0.958891\n",
      "test_loss: 0.098834, test_accuracy: 0.926644\n",
      "train_loss: 0.088321, train_accuracy: 0.958891\n",
      "test_loss: 0.098836, test_accuracy: 0.926644\n",
      "train_loss: 0.088317, train_accuracy: 0.958891\n",
      "test_loss: 0.098839, test_accuracy: 0.925801\n",
      "train_loss: 0.088313, train_accuracy: 0.958891\n",
      "test_loss: 0.098841, test_accuracy: 0.925801\n",
      "train_loss: 0.088309, train_accuracy: 0.958891\n",
      "test_loss: 0.098843, test_accuracy: 0.925801\n",
      "train_loss: 0.088306, train_accuracy: 0.958891\n",
      "test_loss: 0.098846, test_accuracy: 0.925801\n",
      "train_loss: 0.088302, train_accuracy: 0.958891\n",
      "test_loss: 0.098848, test_accuracy: 0.925801\n",
      "train_loss: 0.088298, train_accuracy: 0.958891\n",
      "test_loss: 0.098850, test_accuracy: 0.925801\n",
      "train_loss: 0.088294, train_accuracy: 0.958891\n",
      "test_loss: 0.098852, test_accuracy: 0.925801\n",
      "train_loss: 0.088290, train_accuracy: 0.958891\n",
      "test_loss: 0.098855, test_accuracy: 0.925801\n",
      "train_loss: 0.088287, train_accuracy: 0.958891\n",
      "test_loss: 0.098857, test_accuracy: 0.925801\n",
      "train_loss: 0.088283, train_accuracy: 0.958891\n",
      "test_loss: 0.098859, test_accuracy: 0.925801\n",
      "train_loss: 0.088279, train_accuracy: 0.958891\n",
      "test_loss: 0.098861, test_accuracy: 0.925801\n",
      "train_loss: 0.088275, train_accuracy: 0.958891\n",
      "test_loss: 0.098863, test_accuracy: 0.925801\n",
      "train_loss: 0.088271, train_accuracy: 0.958891\n",
      "test_loss: 0.098866, test_accuracy: 0.926644\n",
      "train_loss: 0.088267, train_accuracy: 0.958891\n",
      "test_loss: 0.098868, test_accuracy: 0.926644\n",
      "train_loss: 0.088264, train_accuracy: 0.958891\n",
      "test_loss: 0.098870, test_accuracy: 0.926644\n",
      "train_loss: 0.088260, train_accuracy: 0.958891\n",
      "test_loss: 0.098872, test_accuracy: 0.926644\n",
      "train_loss: 0.088256, train_accuracy: 0.958891\n",
      "test_loss: 0.098874, test_accuracy: 0.926644\n",
      "train_loss: 0.088252, train_accuracy: 0.958891\n",
      "test_loss: 0.098876, test_accuracy: 0.926644\n",
      "train_loss: 0.088248, train_accuracy: 0.958891\n",
      "test_loss: 0.098878, test_accuracy: 0.926644\n",
      "train_loss: 0.088244, train_accuracy: 0.958891\n",
      "test_loss: 0.098880, test_accuracy: 0.926644\n",
      "train_loss: 0.088241, train_accuracy: 0.958891\n",
      "test_loss: 0.098883, test_accuracy: 0.926644\n",
      "train_loss: 0.088237, train_accuracy: 0.958891\n",
      "test_loss: 0.098885, test_accuracy: 0.926644\n",
      "train_loss: 0.088233, train_accuracy: 0.958891\n",
      "test_loss: 0.098887, test_accuracy: 0.926644\n",
      "train_loss: 0.088229, train_accuracy: 0.958891\n",
      "test_loss: 0.098889, test_accuracy: 0.926644\n",
      "train_loss: 0.088225, train_accuracy: 0.958891\n",
      "test_loss: 0.098891, test_accuracy: 0.926644\n",
      "train_loss: 0.088221, train_accuracy: 0.958891\n",
      "test_loss: 0.098893, test_accuracy: 0.926644\n",
      "train_loss: 0.088217, train_accuracy: 0.958891\n",
      "test_loss: 0.098895, test_accuracy: 0.926644\n",
      "train_loss: 0.088214, train_accuracy: 0.958891\n",
      "test_loss: 0.098897, test_accuracy: 0.926644\n",
      "train_loss: 0.088210, train_accuracy: 0.958891\n",
      "test_loss: 0.098899, test_accuracy: 0.926644\n",
      "train_loss: 0.088206, train_accuracy: 0.958891\n",
      "test_loss: 0.098901, test_accuracy: 0.926644\n",
      "train_loss: 0.088202, train_accuracy: 0.958891\n",
      "test_loss: 0.098903, test_accuracy: 0.926644\n",
      "train_loss: 0.088198, train_accuracy: 0.958891\n",
      "test_loss: 0.098905, test_accuracy: 0.925801\n",
      "train_loss: 0.088194, train_accuracy: 0.958891\n",
      "test_loss: 0.098907, test_accuracy: 0.925801\n",
      "train_loss: 0.088190, train_accuracy: 0.958891\n",
      "test_loss: 0.098909, test_accuracy: 0.925801\n",
      "train_loss: 0.088187, train_accuracy: 0.958891\n",
      "test_loss: 0.098911, test_accuracy: 0.925801\n",
      "train_loss: 0.088183, train_accuracy: 0.958891\n",
      "test_loss: 0.098913, test_accuracy: 0.925801\n",
      "train_loss: 0.088179, train_accuracy: 0.958891\n",
      "test_loss: 0.098915, test_accuracy: 0.925801\n",
      "train_loss: 0.088175, train_accuracy: 0.958891\n",
      "test_loss: 0.098916, test_accuracy: 0.925801\n",
      "train_loss: 0.088171, train_accuracy: 0.958891\n",
      "test_loss: 0.098918, test_accuracy: 0.925801\n",
      "train_loss: 0.088167, train_accuracy: 0.958891\n",
      "test_loss: 0.098920, test_accuracy: 0.925801\n",
      "train_loss: 0.088163, train_accuracy: 0.958891\n",
      "test_loss: 0.098922, test_accuracy: 0.925801\n",
      "train_loss: 0.088160, train_accuracy: 0.958891\n",
      "test_loss: 0.098924, test_accuracy: 0.925801\n",
      "train_loss: 0.088156, train_accuracy: 0.958891\n",
      "test_loss: 0.098926, test_accuracy: 0.925801\n",
      "train_loss: 0.088152, train_accuracy: 0.958891\n",
      "test_loss: 0.098928, test_accuracy: 0.925801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.088148, train_accuracy: 0.958891\n",
      "test_loss: 0.098930, test_accuracy: 0.925801\n",
      "train_loss: 0.088144, train_accuracy: 0.958891\n",
      "test_loss: 0.098931, test_accuracy: 0.925801\n",
      "train_loss: 0.088140, train_accuracy: 0.958891\n",
      "test_loss: 0.098933, test_accuracy: 0.925801\n",
      "train_loss: 0.088136, train_accuracy: 0.958891\n",
      "test_loss: 0.098935, test_accuracy: 0.925801\n",
      "train_loss: 0.088132, train_accuracy: 0.958891\n",
      "test_loss: 0.098937, test_accuracy: 0.925801\n",
      "train_loss: 0.088129, train_accuracy: 0.958891\n",
      "test_loss: 0.098939, test_accuracy: 0.925801\n",
      "train_loss: 0.088125, train_accuracy: 0.958891\n",
      "test_loss: 0.098941, test_accuracy: 0.925801\n",
      "train_loss: 0.088121, train_accuracy: 0.958891\n",
      "test_loss: 0.098942, test_accuracy: 0.925801\n",
      "train_loss: 0.088117, train_accuracy: 0.958891\n",
      "test_loss: 0.098944, test_accuracy: 0.925801\n",
      "train_loss: 0.088113, train_accuracy: 0.958891\n",
      "test_loss: 0.098946, test_accuracy: 0.925801\n",
      "train_loss: 0.088109, train_accuracy: 0.958891\n",
      "test_loss: 0.098948, test_accuracy: 0.925801\n",
      "train_loss: 0.088105, train_accuracy: 0.958891\n",
      "test_loss: 0.098949, test_accuracy: 0.925801\n",
      "train_loss: 0.088101, train_accuracy: 0.958891\n",
      "test_loss: 0.098951, test_accuracy: 0.925801\n",
      "train_loss: 0.088098, train_accuracy: 0.958891\n",
      "test_loss: 0.098953, test_accuracy: 0.925801\n",
      "train_loss: 0.088094, train_accuracy: 0.958891\n",
      "test_loss: 0.098955, test_accuracy: 0.925801\n",
      "train_loss: 0.088090, train_accuracy: 0.958891\n",
      "test_loss: 0.098956, test_accuracy: 0.925801\n",
      "train_loss: 0.088086, train_accuracy: 0.958891\n",
      "test_loss: 0.098958, test_accuracy: 0.925801\n",
      "train_loss: 0.088082, train_accuracy: 0.958891\n",
      "test_loss: 0.098960, test_accuracy: 0.925801\n",
      "train_loss: 0.088078, train_accuracy: 0.958891\n",
      "test_loss: 0.098962, test_accuracy: 0.925801\n",
      "train_loss: 0.088074, train_accuracy: 0.958891\n",
      "test_loss: 0.098963, test_accuracy: 0.925801\n",
      "train_loss: 0.088071, train_accuracy: 0.958891\n",
      "test_loss: 0.098965, test_accuracy: 0.925801\n",
      "train_loss: 0.088067, train_accuracy: 0.958891\n",
      "test_loss: 0.098967, test_accuracy: 0.925801\n",
      "train_loss: 0.088063, train_accuracy: 0.958891\n",
      "test_loss: 0.098968, test_accuracy: 0.925801\n",
      "train_loss: 0.088059, train_accuracy: 0.958891\n",
      "test_loss: 0.098970, test_accuracy: 0.925801\n",
      "train_loss: 0.088055, train_accuracy: 0.958891\n",
      "test_loss: 0.098972, test_accuracy: 0.925801\n",
      "train_loss: 0.088051, train_accuracy: 0.958891\n",
      "test_loss: 0.098973, test_accuracy: 0.925801\n",
      "train_loss: 0.088047, train_accuracy: 0.958891\n",
      "test_loss: 0.098975, test_accuracy: 0.925801\n",
      "train_loss: 0.088043, train_accuracy: 0.958891\n",
      "test_loss: 0.098977, test_accuracy: 0.925801\n",
      "train_loss: 0.088040, train_accuracy: 0.958891\n",
      "test_loss: 0.098978, test_accuracy: 0.925801\n",
      "train_loss: 0.088036, train_accuracy: 0.958891\n",
      "test_loss: 0.098980, test_accuracy: 0.925801\n",
      "train_loss: 0.088032, train_accuracy: 0.958891\n",
      "test_loss: 0.098981, test_accuracy: 0.925801\n",
      "train_loss: 0.088028, train_accuracy: 0.958891\n",
      "test_loss: 0.098983, test_accuracy: 0.925801\n",
      "train_loss: 0.088024, train_accuracy: 0.958891\n",
      "test_loss: 0.098985, test_accuracy: 0.925801\n",
      "train_loss: 0.088020, train_accuracy: 0.958891\n",
      "test_loss: 0.098986, test_accuracy: 0.925801\n",
      "train_loss: 0.088016, train_accuracy: 0.958891\n",
      "test_loss: 0.098988, test_accuracy: 0.925801\n",
      "train_loss: 0.088013, train_accuracy: 0.958891\n",
      "test_loss: 0.098989, test_accuracy: 0.925801\n",
      "train_loss: 0.088009, train_accuracy: 0.958891\n",
      "test_loss: 0.098991, test_accuracy: 0.925801\n",
      "train_loss: 0.088005, train_accuracy: 0.958891\n",
      "test_loss: 0.098993, test_accuracy: 0.925801\n",
      "train_loss: 0.088001, train_accuracy: 0.958891\n",
      "test_loss: 0.098994, test_accuracy: 0.925801\n",
      "train_loss: 0.087997, train_accuracy: 0.958891\n",
      "test_loss: 0.098996, test_accuracy: 0.925801\n",
      "train_loss: 0.087993, train_accuracy: 0.958891\n",
      "test_loss: 0.098997, test_accuracy: 0.925801\n",
      "train_loss: 0.087990, train_accuracy: 0.958891\n",
      "test_loss: 0.098999, test_accuracy: 0.925801\n",
      "train_loss: 0.087986, train_accuracy: 0.958891\n",
      "test_loss: 0.099000, test_accuracy: 0.925801\n",
      "train_loss: 0.087982, train_accuracy: 0.958891\n",
      "test_loss: 0.099002, test_accuracy: 0.925801\n",
      "train_loss: 0.087978, train_accuracy: 0.958891\n",
      "test_loss: 0.099003, test_accuracy: 0.925801\n",
      "train_loss: 0.087974, train_accuracy: 0.958891\n",
      "test_loss: 0.099005, test_accuracy: 0.925801\n",
      "train_loss: 0.087970, train_accuracy: 0.958891\n",
      "test_loss: 0.099006, test_accuracy: 0.925801\n",
      "train_loss: 0.087967, train_accuracy: 0.958891\n",
      "test_loss: 0.099008, test_accuracy: 0.925801\n",
      "train_loss: 0.087963, train_accuracy: 0.958891\n",
      "test_loss: 0.099009, test_accuracy: 0.925801\n",
      "train_loss: 0.087959, train_accuracy: 0.958891\n",
      "test_loss: 0.099011, test_accuracy: 0.925801\n",
      "train_loss: 0.087955, train_accuracy: 0.958891\n",
      "test_loss: 0.099012, test_accuracy: 0.925801\n",
      "train_loss: 0.087951, train_accuracy: 0.958891\n",
      "test_loss: 0.099014, test_accuracy: 0.925801\n",
      "train_loss: 0.087947, train_accuracy: 0.958891\n",
      "test_loss: 0.099015, test_accuracy: 0.925801\n",
      "train_loss: 0.087944, train_accuracy: 0.958891\n",
      "test_loss: 0.099017, test_accuracy: 0.925801\n",
      "train_loss: 0.087940, train_accuracy: 0.958891\n",
      "test_loss: 0.099018, test_accuracy: 0.925801\n",
      "train_loss: 0.087936, train_accuracy: 0.958891\n",
      "test_loss: 0.099020, test_accuracy: 0.925801\n",
      "train_loss: 0.087932, train_accuracy: 0.958891\n",
      "test_loss: 0.099021, test_accuracy: 0.926644\n",
      "train_loss: 0.087928, train_accuracy: 0.958891\n",
      "test_loss: 0.099022, test_accuracy: 0.926644\n",
      "train_loss: 0.087924, train_accuracy: 0.958891\n",
      "test_loss: 0.099024, test_accuracy: 0.926644\n",
      "train_loss: 0.087921, train_accuracy: 0.958891\n",
      "test_loss: 0.099025, test_accuracy: 0.926644\n",
      "Sequential training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 100\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "t1 = time.time()\n",
    "for epoch in range(705):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(seq_train_graph, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+=(t2-t1)/705\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\"\n",
    "#tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X: x_train, Y: y_train})\n",
    "#ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X: x_test, Y: y_test})\n",
    "#print(\"Sequential train training loss: \", tr_loss)\n",
    "#print(\"Sequential train training accuracy: \", tr_acc)\n",
    "#print(\"Sequential train testing loss: \", ts_loss)\n",
    "#print(\"Sequential train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03318816482598055"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) \n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.145569, train_accuracy: 0.684512\n",
      "test_loss: 0.152528, test_accuracy: 0.661046\n",
      "train_loss: 0.142330, train_accuracy: 0.719885\n",
      "test_loss: 0.149371, test_accuracy: 0.687184\n",
      "train_loss: 0.139225, train_accuracy: 0.748566\n",
      "test_loss: 0.146340, test_accuracy: 0.713322\n",
      "train_loss: 0.136255, train_accuracy: 0.778203\n",
      "test_loss: 0.143435, test_accuracy: 0.737774\n",
      "train_loss: 0.133418, train_accuracy: 0.810707\n",
      "test_loss: 0.140656, test_accuracy: 0.761383\n",
      "train_loss: 0.130713, train_accuracy: 0.828872\n",
      "test_loss: 0.138003, test_accuracy: 0.779089\n",
      "train_loss: 0.128138, train_accuracy: 0.845124\n",
      "test_loss: 0.135472, test_accuracy: 0.794266\n",
      "train_loss: 0.125690, train_accuracy: 0.855641\n",
      "test_loss: 0.133062, test_accuracy: 0.806914\n",
      "train_loss: 0.123365, train_accuracy: 0.868069\n",
      "test_loss: 0.130770, test_accuracy: 0.818718\n",
      "train_loss: 0.121160, train_accuracy: 0.879541\n",
      "test_loss: 0.128592, test_accuracy: 0.829680\n",
      "train_loss: 0.119071, train_accuracy: 0.884321\n",
      "test_loss: 0.126525, test_accuracy: 0.836425\n",
      "train_loss: 0.117093, train_accuracy: 0.890057\n",
      "test_loss: 0.124565, test_accuracy: 0.847386\n",
      "train_loss: 0.115221, train_accuracy: 0.895793\n",
      "test_loss: 0.122708, test_accuracy: 0.852445\n",
      "train_loss: 0.113453, train_accuracy: 0.900574\n",
      "test_loss: 0.120950, test_accuracy: 0.857504\n",
      "train_loss: 0.111782, train_accuracy: 0.901530\n",
      "test_loss: 0.119286, test_accuracy: 0.861720\n",
      "train_loss: 0.110205, train_accuracy: 0.904398\n",
      "test_loss: 0.117713, test_accuracy: 0.865936\n",
      "train_loss: 0.108717, train_accuracy: 0.905354\n",
      "test_loss: 0.116226, test_accuracy: 0.868465\n",
      "train_loss: 0.107313, train_accuracy: 0.906310\n",
      "test_loss: 0.114821, test_accuracy: 0.870995\n",
      "train_loss: 0.105990, train_accuracy: 0.909178\n",
      "test_loss: 0.113495, test_accuracy: 0.869309\n",
      "train_loss: 0.104743, train_accuracy: 0.909178\n",
      "test_loss: 0.112242, test_accuracy: 0.871838\n",
      "train_loss: 0.103568, train_accuracy: 0.910134\n",
      "test_loss: 0.111061, test_accuracy: 0.874368\n",
      "train_loss: 0.102462, train_accuracy: 0.909178\n",
      "test_loss: 0.109946, test_accuracy: 0.875211\n",
      "train_loss: 0.101421, train_accuracy: 0.913002\n",
      "test_loss: 0.108894, test_accuracy: 0.877740\n",
      "train_loss: 0.100440, train_accuracy: 0.913958\n",
      "test_loss: 0.107903, test_accuracy: 0.884486\n",
      "train_loss: 0.099517, train_accuracy: 0.915870\n",
      "test_loss: 0.106968, test_accuracy: 0.886172\n",
      "train_loss: 0.098649, train_accuracy: 0.915870\n",
      "test_loss: 0.106087, test_accuracy: 0.887858\n",
      "train_loss: 0.097831, train_accuracy: 0.916826\n",
      "test_loss: 0.105256, test_accuracy: 0.889545\n",
      "train_loss: 0.097063, train_accuracy: 0.915870\n",
      "test_loss: 0.104473, test_accuracy: 0.892917\n",
      "train_loss: 0.096339, train_accuracy: 0.915870\n",
      "test_loss: 0.103736, test_accuracy: 0.890388\n",
      "train_loss: 0.095659, train_accuracy: 0.916826\n",
      "test_loss: 0.103041, test_accuracy: 0.892074\n",
      "train_loss: 0.095019, train_accuracy: 0.915870\n",
      "test_loss: 0.102386, test_accuracy: 0.893761\n",
      "train_loss: 0.094417, train_accuracy: 0.916826\n",
      "test_loss: 0.101768, test_accuracy: 0.892917\n",
      "train_loss: 0.093850, train_accuracy: 0.916826\n",
      "test_loss: 0.101187, test_accuracy: 0.892917\n",
      "train_loss: 0.093318, train_accuracy: 0.919694\n",
      "test_loss: 0.100639, test_accuracy: 0.897133\n",
      "train_loss: 0.092817, train_accuracy: 0.919694\n",
      "test_loss: 0.100123, test_accuracy: 0.896290\n",
      "train_loss: 0.092346, train_accuracy: 0.920650\n",
      "test_loss: 0.099637, test_accuracy: 0.897976\n",
      "train_loss: 0.091903, train_accuracy: 0.920650\n",
      "test_loss: 0.099180, test_accuracy: 0.897976\n",
      "train_loss: 0.091487, train_accuracy: 0.921606\n",
      "test_loss: 0.098749, test_accuracy: 0.897133\n",
      "train_loss: 0.091095, train_accuracy: 0.920650\n",
      "test_loss: 0.098343, test_accuracy: 0.897133\n",
      "train_loss: 0.090727, train_accuracy: 0.920650\n",
      "test_loss: 0.097960, test_accuracy: 0.897133\n",
      "train_loss: 0.090381, train_accuracy: 0.923518\n",
      "test_loss: 0.097600, test_accuracy: 0.897976\n",
      "train_loss: 0.090056, train_accuracy: 0.923518\n",
      "test_loss: 0.097261, test_accuracy: 0.900506\n",
      "train_loss: 0.089751, train_accuracy: 0.923518\n",
      "test_loss: 0.096943, test_accuracy: 0.899663\n",
      "train_loss: 0.089464, train_accuracy: 0.923518\n",
      "test_loss: 0.096642, test_accuracy: 0.900506\n",
      "train_loss: 0.089194, train_accuracy: 0.925430\n",
      "test_loss: 0.096360, test_accuracy: 0.900506\n",
      "train_loss: 0.088941, train_accuracy: 0.926386\n",
      "test_loss: 0.096095, test_accuracy: 0.899663\n",
      "train_loss: 0.088704, train_accuracy: 0.926386\n",
      "test_loss: 0.095845, test_accuracy: 0.898820\n",
      "train_loss: 0.088481, train_accuracy: 0.926386\n",
      "test_loss: 0.095610, test_accuracy: 0.898820\n",
      "train_loss: 0.088272, train_accuracy: 0.928298\n",
      "test_loss: 0.095390, test_accuracy: 0.898820\n",
      "train_loss: 0.088076, train_accuracy: 0.930210\n",
      "test_loss: 0.095182, test_accuracy: 0.900506\n",
      "train_loss: 0.087892, train_accuracy: 0.930210\n",
      "test_loss: 0.094988, test_accuracy: 0.900506\n",
      "train_loss: 0.087720, train_accuracy: 0.930210\n",
      "test_loss: 0.094806, test_accuracy: 0.901349\n",
      "train_loss: 0.087559, train_accuracy: 0.930210\n",
      "test_loss: 0.094634, test_accuracy: 0.901349\n",
      "train_loss: 0.087408, train_accuracy: 0.931166\n",
      "test_loss: 0.094474, test_accuracy: 0.901349\n",
      "train_loss: 0.087268, train_accuracy: 0.931166\n",
      "test_loss: 0.094324, test_accuracy: 0.901349\n",
      "train_loss: 0.087136, train_accuracy: 0.931166\n",
      "test_loss: 0.094184, test_accuracy: 0.902192\n",
      "train_loss: 0.087014, train_accuracy: 0.930210\n",
      "test_loss: 0.094052, test_accuracy: 0.902192\n",
      "train_loss: 0.086900, train_accuracy: 0.930210\n",
      "test_loss: 0.093930, test_accuracy: 0.903035\n",
      "train_loss: 0.086794, train_accuracy: 0.931166\n",
      "test_loss: 0.093816, test_accuracy: 0.903035\n",
      "train_loss: 0.086695, train_accuracy: 0.931166\n",
      "test_loss: 0.093709, test_accuracy: 0.903879\n",
      "train_loss: 0.086604, train_accuracy: 0.931166\n",
      "test_loss: 0.093610, test_accuracy: 0.903879\n",
      "train_loss: 0.086519, train_accuracy: 0.932122\n",
      "test_loss: 0.093518, test_accuracy: 0.903879\n",
      "train_loss: 0.086441, train_accuracy: 0.932122\n",
      "test_loss: 0.093433, test_accuracy: 0.903879\n",
      "train_loss: 0.086369, train_accuracy: 0.932122\n",
      "test_loss: 0.093354, test_accuracy: 0.903879\n",
      "train_loss: 0.086303, train_accuracy: 0.931166\n",
      "test_loss: 0.093281, test_accuracy: 0.903879\n",
      "train_loss: 0.086242, train_accuracy: 0.931166\n",
      "test_loss: 0.093215, test_accuracy: 0.904722\n",
      "train_loss: 0.086187, train_accuracy: 0.932122\n",
      "test_loss: 0.093153, test_accuracy: 0.904722\n",
      "train_loss: 0.086137, train_accuracy: 0.931166\n",
      "test_loss: 0.093097, test_accuracy: 0.904722\n",
      "train_loss: 0.086091, train_accuracy: 0.931166\n",
      "test_loss: 0.093046, test_accuracy: 0.905565\n",
      "train_loss: 0.086050, train_accuracy: 0.931166\n",
      "test_loss: 0.092999, test_accuracy: 0.906408\n",
      "train_loss: 0.086014, train_accuracy: 0.931166\n",
      "test_loss: 0.092958, test_accuracy: 0.906408\n",
      "train_loss: 0.085981, train_accuracy: 0.931166\n",
      "test_loss: 0.092920, test_accuracy: 0.906408\n",
      "train_loss: 0.085953, train_accuracy: 0.932122\n",
      "test_loss: 0.092887, test_accuracy: 0.907251\n",
      "train_loss: 0.085928, train_accuracy: 0.932122\n",
      "test_loss: 0.092857, test_accuracy: 0.907251\n",
      "train_loss: 0.085907, train_accuracy: 0.934034\n",
      "test_loss: 0.092832, test_accuracy: 0.907251\n",
      "train_loss: 0.085889, train_accuracy: 0.934990\n",
      "test_loss: 0.092810, test_accuracy: 0.906408\n",
      "train_loss: 0.085875, train_accuracy: 0.934990\n",
      "test_loss: 0.092791, test_accuracy: 0.906408\n",
      "train_loss: 0.085863, train_accuracy: 0.934990\n",
      "test_loss: 0.092776, test_accuracy: 0.906408\n",
      "train_loss: 0.085855, train_accuracy: 0.934990\n",
      "test_loss: 0.092764, test_accuracy: 0.906408\n",
      "train_loss: 0.085850, train_accuracy: 0.934034\n",
      "test_loss: 0.092754, test_accuracy: 0.906408\n",
      "train_loss: 0.085847, train_accuracy: 0.934034\n",
      "test_loss: 0.092748, test_accuracy: 0.906408\n",
      "train_loss: 0.085847, train_accuracy: 0.934034\n",
      "test_loss: 0.092745, test_accuracy: 0.906408\n",
      "train_loss: 0.085849, train_accuracy: 0.934034\n",
      "test_loss: 0.092744, test_accuracy: 0.906408\n",
      "train_loss: 0.085854, train_accuracy: 0.934034\n",
      "test_loss: 0.092745, test_accuracy: 0.906408\n",
      "train_loss: 0.085861, train_accuracy: 0.934034\n",
      "test_loss: 0.092749, test_accuracy: 0.906408\n",
      "train_loss: 0.085871, train_accuracy: 0.935946\n",
      "test_loss: 0.092756, test_accuracy: 0.907251\n",
      "train_loss: 0.085882, train_accuracy: 0.935946\n",
      "test_loss: 0.092764, test_accuracy: 0.907251\n",
      "train_loss: 0.085896, train_accuracy: 0.935946\n",
      "test_loss: 0.092775, test_accuracy: 0.907251\n",
      "train_loss: 0.085912, train_accuracy: 0.935946\n",
      "test_loss: 0.092788, test_accuracy: 0.907251\n",
      "train_loss: 0.085929, train_accuracy: 0.935946\n",
      "test_loss: 0.092803, test_accuracy: 0.907251\n",
      "train_loss: 0.085948, train_accuracy: 0.936902\n",
      "test_loss: 0.092819, test_accuracy: 0.907251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.085969, train_accuracy: 0.936902\n",
      "test_loss: 0.092838, test_accuracy: 0.907251\n",
      "train_loss: 0.085992, train_accuracy: 0.936902\n",
      "test_loss: 0.092858, test_accuracy: 0.907251\n",
      "train_loss: 0.086016, train_accuracy: 0.936902\n",
      "test_loss: 0.092880, test_accuracy: 0.907251\n",
      "train_loss: 0.086041, train_accuracy: 0.936902\n",
      "test_loss: 0.092903, test_accuracy: 0.907251\n",
      "train_loss: 0.086069, train_accuracy: 0.936902\n",
      "test_loss: 0.092928, test_accuracy: 0.908094\n",
      "train_loss: 0.086097, train_accuracy: 0.936902\n",
      "test_loss: 0.092954, test_accuracy: 0.908094\n",
      "train_loss: 0.086127, train_accuracy: 0.936902\n",
      "test_loss: 0.092982, test_accuracy: 0.908094\n",
      "train_loss: 0.086158, train_accuracy: 0.936902\n",
      "test_loss: 0.093011, test_accuracy: 0.908094\n",
      "train_loss: 0.086191, train_accuracy: 0.936902\n",
      "test_loss: 0.093042, test_accuracy: 0.908094\n",
      "train_loss: 0.086224, train_accuracy: 0.936902\n",
      "test_loss: 0.093073, test_accuracy: 0.908094\n",
      "train_loss: 0.086259, train_accuracy: 0.936902\n",
      "test_loss: 0.093106, test_accuracy: 0.907251\n",
      "train_loss: 0.086295, train_accuracy: 0.936902\n",
      "test_loss: 0.093140, test_accuracy: 0.906408\n",
      "train_loss: 0.086332, train_accuracy: 0.936902\n",
      "test_loss: 0.093176, test_accuracy: 0.906408\n",
      "train_loss: 0.086370, train_accuracy: 0.936902\n",
      "test_loss: 0.093212, test_accuracy: 0.906408\n",
      "train_loss: 0.086409, train_accuracy: 0.936902\n",
      "test_loss: 0.093249, test_accuracy: 0.906408\n",
      "train_loss: 0.086449, train_accuracy: 0.936902\n",
      "test_loss: 0.093287, test_accuracy: 0.906408\n",
      "train_loss: 0.086490, train_accuracy: 0.936902\n",
      "test_loss: 0.093327, test_accuracy: 0.906408\n",
      "train_loss: 0.086532, train_accuracy: 0.936902\n",
      "test_loss: 0.093367, test_accuracy: 0.906408\n",
      "train_loss: 0.086574, train_accuracy: 0.936902\n",
      "test_loss: 0.093408, test_accuracy: 0.906408\n",
      "train_loss: 0.086618, train_accuracy: 0.936902\n",
      "test_loss: 0.093450, test_accuracy: 0.906408\n",
      "train_loss: 0.086662, train_accuracy: 0.936902\n",
      "test_loss: 0.093492, test_accuracy: 0.906408\n",
      "train_loss: 0.086707, train_accuracy: 0.936902\n",
      "test_loss: 0.093536, test_accuracy: 0.906408\n",
      "train_loss: 0.086753, train_accuracy: 0.936902\n",
      "test_loss: 0.093580, test_accuracy: 0.905565\n",
      "train_loss: 0.086799, train_accuracy: 0.936902\n",
      "test_loss: 0.093625, test_accuracy: 0.905565\n",
      "train_loss: 0.086846, train_accuracy: 0.936902\n",
      "test_loss: 0.093671, test_accuracy: 0.906408\n",
      "train_loss: 0.086894, train_accuracy: 0.936902\n",
      "test_loss: 0.093717, test_accuracy: 0.906408\n",
      "train_loss: 0.086942, train_accuracy: 0.936902\n",
      "test_loss: 0.093764, test_accuracy: 0.906408\n",
      "train_loss: 0.086991, train_accuracy: 0.936902\n",
      "test_loss: 0.093812, test_accuracy: 0.906408\n",
      "train_loss: 0.087041, train_accuracy: 0.937859\n",
      "test_loss: 0.093860, test_accuracy: 0.906408\n",
      "train_loss: 0.087091, train_accuracy: 0.937859\n",
      "test_loss: 0.093908, test_accuracy: 0.906408\n",
      "train_loss: 0.087141, train_accuracy: 0.937859\n",
      "test_loss: 0.093958, test_accuracy: 0.906408\n",
      "train_loss: 0.087192, train_accuracy: 0.937859\n",
      "test_loss: 0.094007, test_accuracy: 0.906408\n",
      "train_loss: 0.087244, train_accuracy: 0.937859\n",
      "test_loss: 0.094058, test_accuracy: 0.906408\n",
      "train_loss: 0.087296, train_accuracy: 0.938815\n",
      "test_loss: 0.094109, test_accuracy: 0.906408\n",
      "train_loss: 0.087349, train_accuracy: 0.938815\n",
      "test_loss: 0.094160, test_accuracy: 0.906408\n",
      "train_loss: 0.087401, train_accuracy: 0.938815\n",
      "test_loss: 0.094212, test_accuracy: 0.906408\n",
      "train_loss: 0.087455, train_accuracy: 0.938815\n",
      "test_loss: 0.094264, test_accuracy: 0.906408\n",
      "train_loss: 0.087509, train_accuracy: 0.938815\n",
      "test_loss: 0.094316, test_accuracy: 0.907251\n",
      "train_loss: 0.087563, train_accuracy: 0.938815\n",
      "test_loss: 0.094369, test_accuracy: 0.907251\n",
      "train_loss: 0.087617, train_accuracy: 0.939771\n",
      "test_loss: 0.094423, test_accuracy: 0.907251\n",
      "train_loss: 0.087672, train_accuracy: 0.939771\n",
      "test_loss: 0.094476, test_accuracy: 0.907251\n",
      "train_loss: 0.087727, train_accuracy: 0.939771\n",
      "test_loss: 0.094530, test_accuracy: 0.907251\n",
      "train_loss: 0.087783, train_accuracy: 0.939771\n",
      "test_loss: 0.094585, test_accuracy: 0.907251\n",
      "train_loss: 0.087839, train_accuracy: 0.939771\n",
      "test_loss: 0.094639, test_accuracy: 0.907251\n",
      "train_loss: 0.087895, train_accuracy: 0.938815\n",
      "test_loss: 0.094694, test_accuracy: 0.907251\n",
      "train_loss: 0.087951, train_accuracy: 0.938815\n",
      "test_loss: 0.094750, test_accuracy: 0.907251\n",
      "train_loss: 0.088008, train_accuracy: 0.938815\n",
      "test_loss: 0.094805, test_accuracy: 0.907251\n",
      "train_loss: 0.088065, train_accuracy: 0.938815\n",
      "test_loss: 0.094861, test_accuracy: 0.907251\n",
      "train_loss: 0.088122, train_accuracy: 0.938815\n",
      "test_loss: 0.094917, test_accuracy: 0.907251\n",
      "train_loss: 0.088179, train_accuracy: 0.937859\n",
      "test_loss: 0.094973, test_accuracy: 0.907251\n",
      "train_loss: 0.088237, train_accuracy: 0.937859\n",
      "test_loss: 0.095030, test_accuracy: 0.907251\n",
      "train_loss: 0.088295, train_accuracy: 0.937859\n",
      "test_loss: 0.095087, test_accuracy: 0.907251\n",
      "train_loss: 0.088353, train_accuracy: 0.937859\n",
      "test_loss: 0.095144, test_accuracy: 0.908094\n",
      "train_loss: 0.088411, train_accuracy: 0.937859\n",
      "test_loss: 0.095201, test_accuracy: 0.908094\n",
      "train_loss: 0.088469, train_accuracy: 0.938815\n",
      "test_loss: 0.095258, test_accuracy: 0.908094\n",
      "train_loss: 0.088528, train_accuracy: 0.938815\n",
      "test_loss: 0.095316, test_accuracy: 0.908094\n",
      "train_loss: 0.088586, train_accuracy: 0.938815\n",
      "test_loss: 0.095373, test_accuracy: 0.908094\n",
      "train_loss: 0.088645, train_accuracy: 0.938815\n",
      "test_loss: 0.095431, test_accuracy: 0.908094\n",
      "train_loss: 0.088704, train_accuracy: 0.938815\n",
      "test_loss: 0.095489, test_accuracy: 0.908938\n",
      "train_loss: 0.088763, train_accuracy: 0.938815\n",
      "test_loss: 0.095547, test_accuracy: 0.908938\n",
      "train_loss: 0.088822, train_accuracy: 0.938815\n",
      "test_loss: 0.095606, test_accuracy: 0.908094\n",
      "train_loss: 0.088882, train_accuracy: 0.939771\n",
      "test_loss: 0.095664, test_accuracy: 0.908094\n",
      "train_loss: 0.088941, train_accuracy: 0.939771\n",
      "test_loss: 0.095722, test_accuracy: 0.908094\n",
      "train_loss: 0.089001, train_accuracy: 0.939771\n",
      "test_loss: 0.095781, test_accuracy: 0.908094\n",
      "train_loss: 0.089060, train_accuracy: 0.939771\n",
      "test_loss: 0.095840, test_accuracy: 0.908094\n",
      "train_loss: 0.089120, train_accuracy: 0.939771\n",
      "test_loss: 0.095899, test_accuracy: 0.908938\n",
      "train_loss: 0.089180, train_accuracy: 0.939771\n",
      "test_loss: 0.095957, test_accuracy: 0.908938\n",
      "train_loss: 0.089239, train_accuracy: 0.939771\n",
      "test_loss: 0.096016, test_accuracy: 0.908938\n",
      "train_loss: 0.089299, train_accuracy: 0.939771\n",
      "test_loss: 0.096075, test_accuracy: 0.909781\n",
      "train_loss: 0.089359, train_accuracy: 0.939771\n",
      "test_loss: 0.096134, test_accuracy: 0.909781\n",
      "train_loss: 0.089419, train_accuracy: 0.939771\n",
      "test_loss: 0.096194, test_accuracy: 0.909781\n",
      "train_loss: 0.089479, train_accuracy: 0.939771\n",
      "test_loss: 0.096253, test_accuracy: 0.909781\n",
      "train_loss: 0.089539, train_accuracy: 0.939771\n",
      "test_loss: 0.096312, test_accuracy: 0.909781\n",
      "train_loss: 0.089599, train_accuracy: 0.939771\n",
      "test_loss: 0.096371, test_accuracy: 0.909781\n",
      "train_loss: 0.089659, train_accuracy: 0.939771\n",
      "test_loss: 0.096430, test_accuracy: 0.909781\n",
      "train_loss: 0.089719, train_accuracy: 0.939771\n",
      "test_loss: 0.096490, test_accuracy: 0.909781\n",
      "train_loss: 0.089779, train_accuracy: 0.939771\n",
      "test_loss: 0.096549, test_accuracy: 0.909781\n",
      "train_loss: 0.089840, train_accuracy: 0.939771\n",
      "test_loss: 0.096608, test_accuracy: 0.909781\n",
      "train_loss: 0.089900, train_accuracy: 0.940727\n",
      "test_loss: 0.096668, test_accuracy: 0.909781\n",
      "train_loss: 0.089960, train_accuracy: 0.940727\n",
      "test_loss: 0.096727, test_accuracy: 0.909781\n",
      "train_loss: 0.090020, train_accuracy: 0.941683\n",
      "test_loss: 0.096787, test_accuracy: 0.909781\n",
      "train_loss: 0.090080, train_accuracy: 0.941683\n",
      "test_loss: 0.096846, test_accuracy: 0.909781\n",
      "train_loss: 0.090140, train_accuracy: 0.941683\n",
      "test_loss: 0.096905, test_accuracy: 0.909781\n",
      "train_loss: 0.090200, train_accuracy: 0.941683\n",
      "test_loss: 0.096965, test_accuracy: 0.909781\n",
      "train_loss: 0.090260, train_accuracy: 0.942639\n",
      "test_loss: 0.097024, test_accuracy: 0.909781\n",
      "train_loss: 0.090320, train_accuracy: 0.942639\n",
      "test_loss: 0.097083, test_accuracy: 0.909781\n",
      "train_loss: 0.090379, train_accuracy: 0.942639\n",
      "test_loss: 0.097142, test_accuracy: 0.909781\n",
      "train_loss: 0.090439, train_accuracy: 0.943595\n",
      "test_loss: 0.097202, test_accuracy: 0.908938\n",
      "train_loss: 0.090499, train_accuracy: 0.943595\n",
      "test_loss: 0.097261, test_accuracy: 0.908938\n",
      "train_loss: 0.090559, train_accuracy: 0.943595\n",
      "test_loss: 0.097320, test_accuracy: 0.908938\n",
      "train_loss: 0.090618, train_accuracy: 0.943595\n",
      "test_loss: 0.097379, test_accuracy: 0.908938\n",
      "train_loss: 0.090678, train_accuracy: 0.943595\n",
      "test_loss: 0.097438, test_accuracy: 0.908094\n",
      "train_loss: 0.090737, train_accuracy: 0.943595\n",
      "test_loss: 0.097497, test_accuracy: 0.908094\n",
      "train_loss: 0.090797, train_accuracy: 0.943595\n",
      "test_loss: 0.097556, test_accuracy: 0.908094\n",
      "train_loss: 0.090856, train_accuracy: 0.943595\n",
      "test_loss: 0.097615, test_accuracy: 0.908094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.090915, train_accuracy: 0.943595\n",
      "test_loss: 0.097673, test_accuracy: 0.908094\n",
      "train_loss: 0.090975, train_accuracy: 0.943595\n",
      "test_loss: 0.097732, test_accuracy: 0.908094\n",
      "train_loss: 0.091034, train_accuracy: 0.944551\n",
      "test_loss: 0.097791, test_accuracy: 0.908094\n",
      "train_loss: 0.091093, train_accuracy: 0.944551\n",
      "test_loss: 0.097849, test_accuracy: 0.908938\n",
      "train_loss: 0.091151, train_accuracy: 0.944551\n",
      "test_loss: 0.097908, test_accuracy: 0.908938\n",
      "train_loss: 0.091210, train_accuracy: 0.944551\n",
      "test_loss: 0.097966, test_accuracy: 0.908094\n",
      "train_loss: 0.091269, train_accuracy: 0.944551\n",
      "test_loss: 0.098025, test_accuracy: 0.908094\n",
      "train_loss: 0.091328, train_accuracy: 0.946463\n",
      "test_loss: 0.098083, test_accuracy: 0.908094\n",
      "train_loss: 0.091386, train_accuracy: 0.946463\n",
      "test_loss: 0.098141, test_accuracy: 0.908094\n",
      "train_loss: 0.091444, train_accuracy: 0.946463\n",
      "test_loss: 0.098199, test_accuracy: 0.908094\n",
      "train_loss: 0.091503, train_accuracy: 0.946463\n",
      "test_loss: 0.098257, test_accuracy: 0.908094\n",
      "train_loss: 0.091561, train_accuracy: 0.946463\n",
      "test_loss: 0.098315, test_accuracy: 0.907251\n",
      "train_loss: 0.091619, train_accuracy: 0.946463\n",
      "test_loss: 0.098373, test_accuracy: 0.907251\n",
      "train_loss: 0.091677, train_accuracy: 0.947419\n",
      "test_loss: 0.098431, test_accuracy: 0.907251\n",
      "train_loss: 0.091735, train_accuracy: 0.947419\n",
      "test_loss: 0.098488, test_accuracy: 0.907251\n",
      "train_loss: 0.091792, train_accuracy: 0.947419\n",
      "test_loss: 0.098546, test_accuracy: 0.907251\n",
      "train_loss: 0.091850, train_accuracy: 0.947419\n",
      "test_loss: 0.098603, test_accuracy: 0.907251\n",
      "train_loss: 0.091907, train_accuracy: 0.947419\n",
      "test_loss: 0.098660, test_accuracy: 0.907251\n",
      "train_loss: 0.091964, train_accuracy: 0.947419\n",
      "test_loss: 0.098717, test_accuracy: 0.907251\n",
      "train_loss: 0.092022, train_accuracy: 0.947419\n",
      "test_loss: 0.098774, test_accuracy: 0.907251\n",
      "train_loss: 0.092079, train_accuracy: 0.947419\n",
      "test_loss: 0.098831, test_accuracy: 0.907251\n",
      "train_loss: 0.092135, train_accuracy: 0.947419\n",
      "test_loss: 0.098888, test_accuracy: 0.907251\n",
      "train_loss: 0.092192, train_accuracy: 0.947419\n",
      "test_loss: 0.098945, test_accuracy: 0.907251\n",
      "train_loss: 0.092249, train_accuracy: 0.947419\n",
      "test_loss: 0.099001, test_accuracy: 0.907251\n",
      "train_loss: 0.092305, train_accuracy: 0.947419\n",
      "test_loss: 0.099058, test_accuracy: 0.907251\n",
      "train_loss: 0.092361, train_accuracy: 0.947419\n",
      "test_loss: 0.099114, test_accuracy: 0.907251\n",
      "train_loss: 0.092418, train_accuracy: 0.947419\n",
      "test_loss: 0.099170, test_accuracy: 0.907251\n",
      "train_loss: 0.092474, train_accuracy: 0.947419\n",
      "test_loss: 0.099226, test_accuracy: 0.907251\n",
      "train_loss: 0.092529, train_accuracy: 0.947419\n",
      "test_loss: 0.099282, test_accuracy: 0.906408\n",
      "train_loss: 0.092585, train_accuracy: 0.947419\n",
      "test_loss: 0.099338, test_accuracy: 0.906408\n",
      "train_loss: 0.092641, train_accuracy: 0.948375\n",
      "test_loss: 0.099394, test_accuracy: 0.907251\n",
      "train_loss: 0.092696, train_accuracy: 0.948375\n",
      "test_loss: 0.099449, test_accuracy: 0.907251\n",
      "train_loss: 0.092751, train_accuracy: 0.947419\n",
      "test_loss: 0.099505, test_accuracy: 0.908094\n",
      "train_loss: 0.092806, train_accuracy: 0.947419\n",
      "test_loss: 0.099560, test_accuracy: 0.908094\n",
      "train_loss: 0.092861, train_accuracy: 0.947419\n",
      "test_loss: 0.099615, test_accuracy: 0.908938\n",
      "train_loss: 0.092916, train_accuracy: 0.947419\n",
      "test_loss: 0.099670, test_accuracy: 0.908938\n",
      "train_loss: 0.092970, train_accuracy: 0.947419\n",
      "test_loss: 0.099725, test_accuracy: 0.908938\n",
      "train_loss: 0.093025, train_accuracy: 0.947419\n",
      "test_loss: 0.099779, test_accuracy: 0.908938\n",
      "train_loss: 0.093079, train_accuracy: 0.947419\n",
      "test_loss: 0.099834, test_accuracy: 0.908938\n",
      "train_loss: 0.093133, train_accuracy: 0.947419\n",
      "test_loss: 0.099888, test_accuracy: 0.908938\n",
      "train_loss: 0.093187, train_accuracy: 0.947419\n",
      "test_loss: 0.099943, test_accuracy: 0.908938\n",
      "train_loss: 0.093241, train_accuracy: 0.947419\n",
      "test_loss: 0.099997, test_accuracy: 0.908938\n",
      "train_loss: 0.093294, train_accuracy: 0.948375\n",
      "test_loss: 0.100051, test_accuracy: 0.908938\n",
      "train_loss: 0.093347, train_accuracy: 0.948375\n",
      "test_loss: 0.100104, test_accuracy: 0.908938\n",
      "train_loss: 0.093401, train_accuracy: 0.948375\n",
      "test_loss: 0.100158, test_accuracy: 0.908938\n",
      "train_loss: 0.093454, train_accuracy: 0.948375\n",
      "test_loss: 0.100212, test_accuracy: 0.908938\n",
      "train_loss: 0.093506, train_accuracy: 0.948375\n",
      "test_loss: 0.100265, test_accuracy: 0.908938\n",
      "train_loss: 0.093559, train_accuracy: 0.948375\n",
      "test_loss: 0.100318, test_accuracy: 0.908938\n",
      "train_loss: 0.093612, train_accuracy: 0.948375\n",
      "test_loss: 0.100371, test_accuracy: 0.908938\n",
      "train_loss: 0.093664, train_accuracy: 0.948375\n",
      "test_loss: 0.100424, test_accuracy: 0.908938\n",
      "train_loss: 0.093716, train_accuracy: 0.948375\n",
      "test_loss: 0.100477, test_accuracy: 0.908938\n",
      "train_loss: 0.093768, train_accuracy: 0.948375\n",
      "test_loss: 0.100529, test_accuracy: 0.908938\n",
      "train_loss: 0.093820, train_accuracy: 0.948375\n",
      "test_loss: 0.100582, test_accuracy: 0.908938\n",
      "train_loss: 0.093871, train_accuracy: 0.948375\n",
      "test_loss: 0.100634, test_accuracy: 0.908938\n",
      "train_loss: 0.093923, train_accuracy: 0.949331\n",
      "test_loss: 0.100686, test_accuracy: 0.908938\n",
      "train_loss: 0.093974, train_accuracy: 0.949331\n",
      "test_loss: 0.100738, test_accuracy: 0.908938\n",
      "train_loss: 0.094025, train_accuracy: 0.949331\n",
      "test_loss: 0.100790, test_accuracy: 0.908938\n",
      "train_loss: 0.094076, train_accuracy: 0.949331\n",
      "test_loss: 0.100841, test_accuracy: 0.908938\n",
      "train_loss: 0.094126, train_accuracy: 0.949331\n",
      "test_loss: 0.100893, test_accuracy: 0.908938\n",
      "train_loss: 0.094177, train_accuracy: 0.949331\n",
      "test_loss: 0.100944, test_accuracy: 0.908938\n",
      "train_loss: 0.094227, train_accuracy: 0.949331\n",
      "test_loss: 0.100995, test_accuracy: 0.909781\n",
      "train_loss: 0.094277, train_accuracy: 0.949331\n",
      "test_loss: 0.101046, test_accuracy: 0.909781\n",
      "train_loss: 0.094327, train_accuracy: 0.949331\n",
      "test_loss: 0.101097, test_accuracy: 0.909781\n",
      "train_loss: 0.094377, train_accuracy: 0.949331\n",
      "test_loss: 0.101147, test_accuracy: 0.909781\n",
      "train_loss: 0.094426, train_accuracy: 0.949331\n",
      "test_loss: 0.101198, test_accuracy: 0.909781\n",
      "train_loss: 0.094476, train_accuracy: 0.950287\n",
      "test_loss: 0.101248, test_accuracy: 0.911467\n",
      "train_loss: 0.094525, train_accuracy: 0.950287\n",
      "test_loss: 0.101298, test_accuracy: 0.911467\n",
      "train_loss: 0.094574, train_accuracy: 0.950287\n",
      "test_loss: 0.101348, test_accuracy: 0.911467\n",
      "train_loss: 0.094622, train_accuracy: 0.950287\n",
      "test_loss: 0.101398, test_accuracy: 0.911467\n",
      "train_loss: 0.094671, train_accuracy: 0.950287\n",
      "test_loss: 0.101447, test_accuracy: 0.911467\n",
      "train_loss: 0.094719, train_accuracy: 0.950287\n",
      "test_loss: 0.101497, test_accuracy: 0.911467\n",
      "train_loss: 0.094768, train_accuracy: 0.950287\n",
      "test_loss: 0.101546, test_accuracy: 0.911467\n",
      "train_loss: 0.094816, train_accuracy: 0.950287\n",
      "test_loss: 0.101595, test_accuracy: 0.911467\n",
      "train_loss: 0.094863, train_accuracy: 0.950287\n",
      "test_loss: 0.101644, test_accuracy: 0.911467\n",
      "train_loss: 0.094911, train_accuracy: 0.950287\n",
      "test_loss: 0.101693, test_accuracy: 0.911467\n",
      "train_loss: 0.094958, train_accuracy: 0.950287\n",
      "test_loss: 0.101742, test_accuracy: 0.911467\n",
      "train_loss: 0.095006, train_accuracy: 0.950287\n",
      "test_loss: 0.101790, test_accuracy: 0.911467\n",
      "train_loss: 0.095053, train_accuracy: 0.950287\n",
      "test_loss: 0.101838, test_accuracy: 0.912310\n",
      "train_loss: 0.095099, train_accuracy: 0.950287\n",
      "test_loss: 0.101886, test_accuracy: 0.912310\n",
      "train_loss: 0.095146, train_accuracy: 0.950287\n",
      "test_loss: 0.101934, test_accuracy: 0.912310\n",
      "train_loss: 0.095193, train_accuracy: 0.950287\n",
      "test_loss: 0.101982, test_accuracy: 0.912310\n",
      "train_loss: 0.095239, train_accuracy: 0.950287\n",
      "test_loss: 0.102030, test_accuracy: 0.912310\n",
      "train_loss: 0.095285, train_accuracy: 0.950287\n",
      "test_loss: 0.102077, test_accuracy: 0.912310\n",
      "train_loss: 0.095331, train_accuracy: 0.950287\n",
      "test_loss: 0.102124, test_accuracy: 0.913153\n",
      "train_loss: 0.095376, train_accuracy: 0.950287\n",
      "test_loss: 0.102171, test_accuracy: 0.913153\n",
      "train_loss: 0.095422, train_accuracy: 0.950287\n",
      "test_loss: 0.102218, test_accuracy: 0.913153\n",
      "train_loss: 0.095467, train_accuracy: 0.950287\n",
      "test_loss: 0.102265, test_accuracy: 0.913153\n",
      "train_loss: 0.095512, train_accuracy: 0.950287\n",
      "test_loss: 0.102312, test_accuracy: 0.913153\n",
      "train_loss: 0.095557, train_accuracy: 0.950287\n",
      "test_loss: 0.102358, test_accuracy: 0.913153\n",
      "train_loss: 0.095602, train_accuracy: 0.950287\n",
      "test_loss: 0.102404, test_accuracy: 0.913153\n",
      "train_loss: 0.095646, train_accuracy: 0.950287\n",
      "test_loss: 0.102450, test_accuracy: 0.913153\n",
      "train_loss: 0.095691, train_accuracy: 0.950287\n",
      "test_loss: 0.102496, test_accuracy: 0.913153\n",
      "train_loss: 0.095735, train_accuracy: 0.950287\n",
      "test_loss: 0.102542, test_accuracy: 0.913153\n",
      "train_loss: 0.095779, train_accuracy: 0.950287\n",
      "test_loss: 0.102587, test_accuracy: 0.912310\n",
      "train_loss: 0.095822, train_accuracy: 0.950287\n",
      "test_loss: 0.102633, test_accuracy: 0.912310\n",
      "train_loss: 0.095866, train_accuracy: 0.950287\n",
      "test_loss: 0.102678, test_accuracy: 0.912310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.095909, train_accuracy: 0.950287\n",
      "test_loss: 0.102723, test_accuracy: 0.912310\n",
      "train_loss: 0.095953, train_accuracy: 0.950287\n",
      "test_loss: 0.102768, test_accuracy: 0.912310\n",
      "train_loss: 0.095996, train_accuracy: 0.950287\n",
      "test_loss: 0.102813, test_accuracy: 0.911467\n",
      "train_loss: 0.096038, train_accuracy: 0.950287\n",
      "test_loss: 0.102857, test_accuracy: 0.911467\n",
      "train_loss: 0.096081, train_accuracy: 0.950287\n",
      "test_loss: 0.102902, test_accuracy: 0.911467\n",
      "train_loss: 0.096123, train_accuracy: 0.950287\n",
      "test_loss: 0.102946, test_accuracy: 0.911467\n",
      "train_loss: 0.096165, train_accuracy: 0.950287\n",
      "test_loss: 0.102990, test_accuracy: 0.911467\n",
      "train_loss: 0.096207, train_accuracy: 0.950287\n",
      "test_loss: 0.103034, test_accuracy: 0.911467\n",
      "train_loss: 0.096249, train_accuracy: 0.950287\n",
      "test_loss: 0.103077, test_accuracy: 0.912310\n",
      "train_loss: 0.096291, train_accuracy: 0.950287\n",
      "test_loss: 0.103121, test_accuracy: 0.912310\n",
      "train_loss: 0.096332, train_accuracy: 0.950287\n",
      "test_loss: 0.103164, test_accuracy: 0.912310\n",
      "train_loss: 0.096374, train_accuracy: 0.950287\n",
      "test_loss: 0.103207, test_accuracy: 0.912310\n",
      "train_loss: 0.096415, train_accuracy: 0.950287\n",
      "test_loss: 0.103250, test_accuracy: 0.912310\n",
      "train_loss: 0.096456, train_accuracy: 0.950287\n",
      "test_loss: 0.103293, test_accuracy: 0.912310\n",
      "train_loss: 0.096496, train_accuracy: 0.950287\n",
      "test_loss: 0.103336, test_accuracy: 0.912310\n",
      "train_loss: 0.096537, train_accuracy: 0.950287\n",
      "test_loss: 0.103378, test_accuracy: 0.912310\n",
      "train_loss: 0.096577, train_accuracy: 0.950287\n",
      "test_loss: 0.103421, test_accuracy: 0.912310\n",
      "train_loss: 0.096617, train_accuracy: 0.950287\n",
      "test_loss: 0.103463, test_accuracy: 0.912310\n",
      "train_loss: 0.096657, train_accuracy: 0.950287\n",
      "test_loss: 0.103505, test_accuracy: 0.912310\n",
      "train_loss: 0.096697, train_accuracy: 0.950287\n",
      "test_loss: 0.103547, test_accuracy: 0.912310\n",
      "train_loss: 0.096736, train_accuracy: 0.950287\n",
      "test_loss: 0.103589, test_accuracy: 0.912310\n",
      "train_loss: 0.096776, train_accuracy: 0.950287\n",
      "test_loss: 0.103630, test_accuracy: 0.912310\n",
      "train_loss: 0.096815, train_accuracy: 0.950287\n",
      "test_loss: 0.103671, test_accuracy: 0.912310\n",
      "train_loss: 0.096854, train_accuracy: 0.950287\n",
      "test_loss: 0.103713, test_accuracy: 0.912310\n",
      "train_loss: 0.096893, train_accuracy: 0.950287\n",
      "test_loss: 0.103754, test_accuracy: 0.912310\n",
      "train_loss: 0.096931, train_accuracy: 0.950287\n",
      "test_loss: 0.103794, test_accuracy: 0.912310\n",
      "train_loss: 0.096970, train_accuracy: 0.951243\n",
      "test_loss: 0.103835, test_accuracy: 0.912310\n",
      "train_loss: 0.097008, train_accuracy: 0.951243\n",
      "test_loss: 0.103876, test_accuracy: 0.912310\n",
      "train_loss: 0.097046, train_accuracy: 0.951243\n",
      "test_loss: 0.103916, test_accuracy: 0.912310\n",
      "train_loss: 0.097084, train_accuracy: 0.951243\n",
      "test_loss: 0.103956, test_accuracy: 0.912310\n",
      "train_loss: 0.097121, train_accuracy: 0.951243\n",
      "test_loss: 0.103996, test_accuracy: 0.912310\n",
      "train_loss: 0.097159, train_accuracy: 0.951243\n",
      "test_loss: 0.104036, test_accuracy: 0.912310\n",
      "train_loss: 0.097196, train_accuracy: 0.951243\n",
      "test_loss: 0.104076, test_accuracy: 0.912310\n",
      "train_loss: 0.097233, train_accuracy: 0.951243\n",
      "test_loss: 0.104115, test_accuracy: 0.912310\n",
      "train_loss: 0.097270, train_accuracy: 0.951243\n",
      "test_loss: 0.104155, test_accuracy: 0.913153\n",
      "train_loss: 0.097307, train_accuracy: 0.951243\n",
      "test_loss: 0.104194, test_accuracy: 0.913153\n",
      "train_loss: 0.097344, train_accuracy: 0.952199\n",
      "test_loss: 0.104233, test_accuracy: 0.913153\n",
      "train_loss: 0.097380, train_accuracy: 0.952199\n",
      "test_loss: 0.104272, test_accuracy: 0.913153\n",
      "train_loss: 0.097416, train_accuracy: 0.952199\n",
      "test_loss: 0.104311, test_accuracy: 0.913153\n",
      "train_loss: 0.097452, train_accuracy: 0.952199\n",
      "test_loss: 0.104349, test_accuracy: 0.913153\n",
      "train_loss: 0.097488, train_accuracy: 0.952199\n",
      "test_loss: 0.104388, test_accuracy: 0.913153\n",
      "train_loss: 0.097524, train_accuracy: 0.952199\n",
      "test_loss: 0.104426, test_accuracy: 0.913153\n",
      "train_loss: 0.097560, train_accuracy: 0.953155\n",
      "test_loss: 0.104464, test_accuracy: 0.912310\n",
      "train_loss: 0.097595, train_accuracy: 0.953155\n",
      "test_loss: 0.104502, test_accuracy: 0.912310\n",
      "train_loss: 0.097630, train_accuracy: 0.953155\n",
      "test_loss: 0.104540, test_accuracy: 0.912310\n",
      "train_loss: 0.097665, train_accuracy: 0.953155\n",
      "test_loss: 0.104578, test_accuracy: 0.912310\n",
      "train_loss: 0.097700, train_accuracy: 0.953155\n",
      "test_loss: 0.104615, test_accuracy: 0.913153\n",
      "train_loss: 0.097735, train_accuracy: 0.953155\n",
      "test_loss: 0.104652, test_accuracy: 0.913153\n",
      "train_loss: 0.097769, train_accuracy: 0.953155\n",
      "test_loss: 0.104690, test_accuracy: 0.913153\n",
      "train_loss: 0.097803, train_accuracy: 0.953155\n",
      "test_loss: 0.104727, test_accuracy: 0.913153\n",
      "train_loss: 0.097837, train_accuracy: 0.953155\n",
      "test_loss: 0.104764, test_accuracy: 0.913153\n",
      "train_loss: 0.097871, train_accuracy: 0.953155\n",
      "test_loss: 0.104800, test_accuracy: 0.912310\n",
      "train_loss: 0.097905, train_accuracy: 0.953155\n",
      "test_loss: 0.104837, test_accuracy: 0.912310\n",
      "train_loss: 0.097939, train_accuracy: 0.953155\n",
      "test_loss: 0.104873, test_accuracy: 0.912310\n",
      "train_loss: 0.097972, train_accuracy: 0.953155\n",
      "test_loss: 0.104910, test_accuracy: 0.912310\n",
      "train_loss: 0.098005, train_accuracy: 0.953155\n",
      "test_loss: 0.104946, test_accuracy: 0.912310\n",
      "train_loss: 0.098038, train_accuracy: 0.953155\n",
      "test_loss: 0.104982, test_accuracy: 0.912310\n",
      "train_loss: 0.098071, train_accuracy: 0.953155\n",
      "test_loss: 0.105017, test_accuracy: 0.912310\n",
      "train_loss: 0.098104, train_accuracy: 0.953155\n",
      "test_loss: 0.105053, test_accuracy: 0.912310\n",
      "train_loss: 0.098137, train_accuracy: 0.953155\n",
      "test_loss: 0.105089, test_accuracy: 0.912310\n",
      "train_loss: 0.098169, train_accuracy: 0.954111\n",
      "test_loss: 0.105124, test_accuracy: 0.912310\n",
      "train_loss: 0.098201, train_accuracy: 0.954111\n",
      "test_loss: 0.105159, test_accuracy: 0.912310\n",
      "train_loss: 0.098233, train_accuracy: 0.954111\n",
      "test_loss: 0.105194, test_accuracy: 0.912310\n",
      "train_loss: 0.098265, train_accuracy: 0.954111\n",
      "test_loss: 0.105229, test_accuracy: 0.912310\n",
      "train_loss: 0.098297, train_accuracy: 0.954111\n",
      "test_loss: 0.105264, test_accuracy: 0.912310\n",
      "train_loss: 0.098329, train_accuracy: 0.954111\n",
      "test_loss: 0.105298, test_accuracy: 0.912310\n",
      "train_loss: 0.098360, train_accuracy: 0.954111\n",
      "test_loss: 0.105333, test_accuracy: 0.912310\n",
      "train_loss: 0.098391, train_accuracy: 0.954111\n",
      "test_loss: 0.105367, test_accuracy: 0.912310\n",
      "train_loss: 0.098422, train_accuracy: 0.954111\n",
      "test_loss: 0.105401, test_accuracy: 0.912310\n",
      "train_loss: 0.098453, train_accuracy: 0.954111\n",
      "test_loss: 0.105435, test_accuracy: 0.912310\n",
      "train_loss: 0.098484, train_accuracy: 0.954111\n",
      "test_loss: 0.105469, test_accuracy: 0.912310\n",
      "train_loss: 0.098515, train_accuracy: 0.954111\n",
      "test_loss: 0.105503, test_accuracy: 0.912310\n",
      "train_loss: 0.098545, train_accuracy: 0.954111\n",
      "test_loss: 0.105537, test_accuracy: 0.912310\n",
      "train_loss: 0.098575, train_accuracy: 0.954111\n",
      "test_loss: 0.105570, test_accuracy: 0.912310\n",
      "train_loss: 0.098606, train_accuracy: 0.954111\n",
      "test_loss: 0.105603, test_accuracy: 0.912310\n",
      "train_loss: 0.098636, train_accuracy: 0.954111\n",
      "test_loss: 0.105637, test_accuracy: 0.912310\n",
      "train_loss: 0.098665, train_accuracy: 0.954111\n",
      "test_loss: 0.105670, test_accuracy: 0.912310\n",
      "train_loss: 0.098695, train_accuracy: 0.954111\n",
      "test_loss: 0.105702, test_accuracy: 0.912310\n",
      "train_loss: 0.098724, train_accuracy: 0.954111\n",
      "test_loss: 0.105735, test_accuracy: 0.912310\n",
      "train_loss: 0.098754, train_accuracy: 0.954111\n",
      "test_loss: 0.105768, test_accuracy: 0.912310\n",
      "train_loss: 0.098783, train_accuracy: 0.954111\n",
      "test_loss: 0.105800, test_accuracy: 0.912310\n",
      "train_loss: 0.098812, train_accuracy: 0.954111\n",
      "test_loss: 0.105833, test_accuracy: 0.912310\n",
      "train_loss: 0.098841, train_accuracy: 0.954111\n",
      "test_loss: 0.105865, test_accuracy: 0.912310\n",
      "train_loss: 0.098870, train_accuracy: 0.954111\n",
      "test_loss: 0.105897, test_accuracy: 0.912310\n",
      "train_loss: 0.098898, train_accuracy: 0.954111\n",
      "test_loss: 0.105929, test_accuracy: 0.912310\n",
      "train_loss: 0.098927, train_accuracy: 0.955067\n",
      "test_loss: 0.105960, test_accuracy: 0.912310\n",
      "train_loss: 0.098955, train_accuracy: 0.955067\n",
      "test_loss: 0.105992, test_accuracy: 0.912310\n",
      "train_loss: 0.098983, train_accuracy: 0.955067\n",
      "test_loss: 0.106024, test_accuracy: 0.912310\n",
      "train_loss: 0.099011, train_accuracy: 0.955067\n",
      "test_loss: 0.106055, test_accuracy: 0.912310\n",
      "train_loss: 0.099039, train_accuracy: 0.955067\n",
      "test_loss: 0.106086, test_accuracy: 0.913997\n",
      "train_loss: 0.099066, train_accuracy: 0.955067\n",
      "test_loss: 0.106117, test_accuracy: 0.913997\n",
      "train_loss: 0.099094, train_accuracy: 0.955067\n",
      "test_loss: 0.106148, test_accuracy: 0.913997\n",
      "train_loss: 0.099121, train_accuracy: 0.955067\n",
      "test_loss: 0.106179, test_accuracy: 0.913997\n",
      "train_loss: 0.099148, train_accuracy: 0.955067\n",
      "test_loss: 0.106210, test_accuracy: 0.913997\n",
      "train_loss: 0.099175, train_accuracy: 0.955067\n",
      "test_loss: 0.106240, test_accuracy: 0.913997\n",
      "train_loss: 0.099202, train_accuracy: 0.955067\n",
      "test_loss: 0.106271, test_accuracy: 0.913997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.099229, train_accuracy: 0.955067\n",
      "test_loss: 0.106301, test_accuracy: 0.913997\n",
      "train_loss: 0.099256, train_accuracy: 0.954111\n",
      "test_loss: 0.106331, test_accuracy: 0.913997\n",
      "train_loss: 0.099282, train_accuracy: 0.954111\n",
      "test_loss: 0.106361, test_accuracy: 0.913997\n",
      "train_loss: 0.099308, train_accuracy: 0.954111\n",
      "test_loss: 0.106391, test_accuracy: 0.913997\n",
      "train_loss: 0.099335, train_accuracy: 0.954111\n",
      "test_loss: 0.106421, test_accuracy: 0.913997\n",
      "train_loss: 0.099361, train_accuracy: 0.954111\n",
      "test_loss: 0.106451, test_accuracy: 0.914840\n",
      "train_loss: 0.099387, train_accuracy: 0.954111\n",
      "test_loss: 0.106480, test_accuracy: 0.914840\n",
      "train_loss: 0.099412, train_accuracy: 0.954111\n",
      "test_loss: 0.106509, test_accuracy: 0.914840\n",
      "train_loss: 0.099438, train_accuracy: 0.954111\n",
      "test_loss: 0.106539, test_accuracy: 0.914840\n",
      "train_loss: 0.099463, train_accuracy: 0.954111\n",
      "test_loss: 0.106568, test_accuracy: 0.914840\n",
      "train_loss: 0.099489, train_accuracy: 0.954111\n",
      "test_loss: 0.106597, test_accuracy: 0.914840\n",
      "train_loss: 0.099514, train_accuracy: 0.955067\n",
      "test_loss: 0.106626, test_accuracy: 0.914840\n",
      "train_loss: 0.099539, train_accuracy: 0.955067\n",
      "test_loss: 0.106654, test_accuracy: 0.914840\n",
      "train_loss: 0.099564, train_accuracy: 0.955067\n",
      "test_loss: 0.106683, test_accuracy: 0.916526\n",
      "train_loss: 0.099589, train_accuracy: 0.955067\n",
      "test_loss: 0.106712, test_accuracy: 0.916526\n",
      "train_loss: 0.099613, train_accuracy: 0.954111\n",
      "test_loss: 0.106740, test_accuracy: 0.916526\n",
      "train_loss: 0.099638, train_accuracy: 0.954111\n",
      "test_loss: 0.106768, test_accuracy: 0.916526\n",
      "train_loss: 0.099662, train_accuracy: 0.954111\n",
      "test_loss: 0.106796, test_accuracy: 0.916526\n",
      "train_loss: 0.099687, train_accuracy: 0.954111\n",
      "test_loss: 0.106824, test_accuracy: 0.916526\n",
      "train_loss: 0.099711, train_accuracy: 0.954111\n",
      "test_loss: 0.106852, test_accuracy: 0.916526\n",
      "train_loss: 0.099735, train_accuracy: 0.954111\n",
      "test_loss: 0.106880, test_accuracy: 0.916526\n",
      "train_loss: 0.099758, train_accuracy: 0.954111\n",
      "test_loss: 0.106908, test_accuracy: 0.916526\n",
      "train_loss: 0.099782, train_accuracy: 0.954111\n",
      "test_loss: 0.106935, test_accuracy: 0.916526\n",
      "train_loss: 0.099806, train_accuracy: 0.954111\n",
      "test_loss: 0.106963, test_accuracy: 0.916526\n",
      "train_loss: 0.099829, train_accuracy: 0.954111\n",
      "test_loss: 0.106990, test_accuracy: 0.916526\n",
      "train_loss: 0.099853, train_accuracy: 0.954111\n",
      "test_loss: 0.107017, test_accuracy: 0.915683\n",
      "train_loss: 0.099876, train_accuracy: 0.954111\n",
      "test_loss: 0.107044, test_accuracy: 0.915683\n",
      "train_loss: 0.099899, train_accuracy: 0.954111\n",
      "test_loss: 0.107071, test_accuracy: 0.915683\n",
      "train_loss: 0.099922, train_accuracy: 0.954111\n",
      "test_loss: 0.107098, test_accuracy: 0.915683\n",
      "train_loss: 0.099945, train_accuracy: 0.954111\n",
      "test_loss: 0.107125, test_accuracy: 0.915683\n",
      "train_loss: 0.099967, train_accuracy: 0.954111\n",
      "test_loss: 0.107151, test_accuracy: 0.913997\n",
      "train_loss: 0.099990, train_accuracy: 0.954111\n",
      "test_loss: 0.107178, test_accuracy: 0.913997\n",
      "train_loss: 0.100012, train_accuracy: 0.954111\n",
      "test_loss: 0.107204, test_accuracy: 0.913997\n",
      "train_loss: 0.100034, train_accuracy: 0.954111\n",
      "test_loss: 0.107230, test_accuracy: 0.913997\n",
      "train_loss: 0.100057, train_accuracy: 0.954111\n",
      "test_loss: 0.107257, test_accuracy: 0.913997\n",
      "train_loss: 0.100079, train_accuracy: 0.954111\n",
      "test_loss: 0.107282, test_accuracy: 0.913997\n",
      "train_loss: 0.100101, train_accuracy: 0.954111\n",
      "test_loss: 0.107308, test_accuracy: 0.913997\n",
      "train_loss: 0.100122, train_accuracy: 0.954111\n",
      "test_loss: 0.107334, test_accuracy: 0.913997\n",
      "train_loss: 0.100144, train_accuracy: 0.954111\n",
      "test_loss: 0.107360, test_accuracy: 0.913153\n",
      "train_loss: 0.100166, train_accuracy: 0.954111\n",
      "test_loss: 0.107385, test_accuracy: 0.913153\n",
      "train_loss: 0.100187, train_accuracy: 0.954111\n",
      "test_loss: 0.107411, test_accuracy: 0.913153\n",
      "train_loss: 0.100208, train_accuracy: 0.954111\n",
      "test_loss: 0.107436, test_accuracy: 0.913153\n",
      "train_loss: 0.100229, train_accuracy: 0.954111\n",
      "test_loss: 0.107461, test_accuracy: 0.913153\n",
      "train_loss: 0.100251, train_accuracy: 0.954111\n",
      "test_loss: 0.107487, test_accuracy: 0.913153\n",
      "train_loss: 0.100272, train_accuracy: 0.954111\n",
      "test_loss: 0.107512, test_accuracy: 0.913153\n",
      "train_loss: 0.100292, train_accuracy: 0.954111\n",
      "test_loss: 0.107537, test_accuracy: 0.913153\n",
      "train_loss: 0.100313, train_accuracy: 0.954111\n",
      "test_loss: 0.107561, test_accuracy: 0.913153\n",
      "train_loss: 0.100334, train_accuracy: 0.954111\n",
      "test_loss: 0.107586, test_accuracy: 0.913153\n",
      "train_loss: 0.100354, train_accuracy: 0.954111\n",
      "test_loss: 0.107611, test_accuracy: 0.913153\n",
      "train_loss: 0.100375, train_accuracy: 0.954111\n",
      "test_loss: 0.107635, test_accuracy: 0.913153\n",
      "train_loss: 0.100395, train_accuracy: 0.954111\n",
      "test_loss: 0.107660, test_accuracy: 0.913153\n",
      "train_loss: 0.100415, train_accuracy: 0.954111\n",
      "test_loss: 0.107684, test_accuracy: 0.912310\n",
      "train_loss: 0.100435, train_accuracy: 0.954111\n",
      "test_loss: 0.107708, test_accuracy: 0.912310\n",
      "train_loss: 0.100455, train_accuracy: 0.954111\n",
      "test_loss: 0.107732, test_accuracy: 0.912310\n",
      "train_loss: 0.100475, train_accuracy: 0.954111\n",
      "test_loss: 0.107756, test_accuracy: 0.912310\n",
      "train_loss: 0.100494, train_accuracy: 0.954111\n",
      "test_loss: 0.107780, test_accuracy: 0.912310\n",
      "train_loss: 0.100514, train_accuracy: 0.954111\n",
      "test_loss: 0.107804, test_accuracy: 0.912310\n",
      "train_loss: 0.100533, train_accuracy: 0.954111\n",
      "test_loss: 0.107827, test_accuracy: 0.912310\n",
      "train_loss: 0.100553, train_accuracy: 0.954111\n",
      "test_loss: 0.107851, test_accuracy: 0.912310\n",
      "train_loss: 0.100572, train_accuracy: 0.954111\n",
      "test_loss: 0.107874, test_accuracy: 0.911467\n",
      "train_loss: 0.100591, train_accuracy: 0.954111\n",
      "test_loss: 0.107898, test_accuracy: 0.911467\n",
      "train_loss: 0.100610, train_accuracy: 0.954111\n",
      "test_loss: 0.107921, test_accuracy: 0.911467\n",
      "train_loss: 0.100629, train_accuracy: 0.954111\n",
      "test_loss: 0.107944, test_accuracy: 0.911467\n",
      "train_loss: 0.100648, train_accuracy: 0.954111\n",
      "test_loss: 0.107967, test_accuracy: 0.911467\n",
      "train_loss: 0.100666, train_accuracy: 0.954111\n",
      "test_loss: 0.107990, test_accuracy: 0.911467\n",
      "train_loss: 0.100685, train_accuracy: 0.954111\n",
      "test_loss: 0.108013, test_accuracy: 0.911467\n",
      "train_loss: 0.100704, train_accuracy: 0.954111\n",
      "test_loss: 0.108036, test_accuracy: 0.911467\n",
      "train_loss: 0.100722, train_accuracy: 0.954111\n",
      "test_loss: 0.108058, test_accuracy: 0.911467\n",
      "train_loss: 0.100740, train_accuracy: 0.955067\n",
      "test_loss: 0.108081, test_accuracy: 0.911467\n",
      "train_loss: 0.100758, train_accuracy: 0.955067\n",
      "test_loss: 0.108103, test_accuracy: 0.911467\n",
      "train_loss: 0.100776, train_accuracy: 0.955067\n",
      "test_loss: 0.108126, test_accuracy: 0.911467\n",
      "train_loss: 0.100794, train_accuracy: 0.955067\n",
      "test_loss: 0.108148, test_accuracy: 0.912310\n",
      "train_loss: 0.100812, train_accuracy: 0.955067\n",
      "test_loss: 0.108170, test_accuracy: 0.912310\n",
      "train_loss: 0.100830, train_accuracy: 0.955067\n",
      "test_loss: 0.108192, test_accuracy: 0.912310\n",
      "train_loss: 0.100848, train_accuracy: 0.955067\n",
      "test_loss: 0.108214, test_accuracy: 0.912310\n",
      "train_loss: 0.100865, train_accuracy: 0.955067\n",
      "test_loss: 0.108236, test_accuracy: 0.912310\n",
      "train_loss: 0.100883, train_accuracy: 0.955067\n",
      "test_loss: 0.108258, test_accuracy: 0.912310\n",
      "train_loss: 0.100900, train_accuracy: 0.955067\n",
      "test_loss: 0.108279, test_accuracy: 0.912310\n",
      "train_loss: 0.100917, train_accuracy: 0.955067\n",
      "test_loss: 0.108301, test_accuracy: 0.912310\n",
      "train_loss: 0.100934, train_accuracy: 0.955067\n",
      "test_loss: 0.108323, test_accuracy: 0.912310\n",
      "train_loss: 0.100951, train_accuracy: 0.955067\n",
      "test_loss: 0.108344, test_accuracy: 0.912310\n",
      "train_loss: 0.100968, train_accuracy: 0.955067\n",
      "test_loss: 0.108365, test_accuracy: 0.912310\n",
      "train_loss: 0.100985, train_accuracy: 0.955067\n",
      "test_loss: 0.108387, test_accuracy: 0.912310\n",
      "train_loss: 0.101002, train_accuracy: 0.955067\n",
      "test_loss: 0.108408, test_accuracy: 0.912310\n",
      "train_loss: 0.101019, train_accuracy: 0.955067\n",
      "test_loss: 0.108429, test_accuracy: 0.912310\n",
      "train_loss: 0.101035, train_accuracy: 0.955067\n",
      "test_loss: 0.108450, test_accuracy: 0.912310\n",
      "train_loss: 0.101052, train_accuracy: 0.955067\n",
      "test_loss: 0.108471, test_accuracy: 0.912310\n",
      "train_loss: 0.101068, train_accuracy: 0.955067\n",
      "test_loss: 0.108491, test_accuracy: 0.912310\n",
      "train_loss: 0.101084, train_accuracy: 0.955067\n",
      "test_loss: 0.108512, test_accuracy: 0.912310\n",
      "train_loss: 0.101100, train_accuracy: 0.955067\n",
      "test_loss: 0.108533, test_accuracy: 0.912310\n",
      "train_loss: 0.101116, train_accuracy: 0.955067\n",
      "test_loss: 0.108553, test_accuracy: 0.912310\n",
      "train_loss: 0.101132, train_accuracy: 0.955067\n",
      "test_loss: 0.108574, test_accuracy: 0.912310\n",
      "train_loss: 0.101148, train_accuracy: 0.955067\n",
      "test_loss: 0.108594, test_accuracy: 0.912310\n",
      "train_loss: 0.101164, train_accuracy: 0.955067\n",
      "test_loss: 0.108614, test_accuracy: 0.912310\n",
      "train_loss: 0.101180, train_accuracy: 0.955067\n",
      "test_loss: 0.108634, test_accuracy: 0.912310\n",
      "train_loss: 0.101195, train_accuracy: 0.955067\n",
      "test_loss: 0.108654, test_accuracy: 0.912310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.101211, train_accuracy: 0.955067\n",
      "test_loss: 0.108675, test_accuracy: 0.912310\n",
      "train_loss: 0.101226, train_accuracy: 0.955067\n",
      "test_loss: 0.108694, test_accuracy: 0.912310\n",
      "train_loss: 0.101242, train_accuracy: 0.955067\n",
      "test_loss: 0.108714, test_accuracy: 0.912310\n",
      "train_loss: 0.101257, train_accuracy: 0.955067\n",
      "test_loss: 0.108734, test_accuracy: 0.912310\n",
      "train_loss: 0.101272, train_accuracy: 0.955067\n",
      "test_loss: 0.108754, test_accuracy: 0.912310\n",
      "train_loss: 0.101287, train_accuracy: 0.955067\n",
      "test_loss: 0.108773, test_accuracy: 0.912310\n",
      "train_loss: 0.101302, train_accuracy: 0.955067\n",
      "test_loss: 0.108793, test_accuracy: 0.912310\n",
      "train_loss: 0.101317, train_accuracy: 0.955067\n",
      "test_loss: 0.108812, test_accuracy: 0.912310\n",
      "train_loss: 0.101332, train_accuracy: 0.955067\n",
      "test_loss: 0.108832, test_accuracy: 0.912310\n",
      "train_loss: 0.101347, train_accuracy: 0.955067\n",
      "test_loss: 0.108851, test_accuracy: 0.912310\n",
      "train_loss: 0.101361, train_accuracy: 0.955067\n",
      "test_loss: 0.108870, test_accuracy: 0.912310\n",
      "train_loss: 0.101376, train_accuracy: 0.955067\n",
      "test_loss: 0.108889, test_accuracy: 0.912310\n",
      "train_loss: 0.101390, train_accuracy: 0.955067\n",
      "test_loss: 0.108908, test_accuracy: 0.912310\n",
      "train_loss: 0.101405, train_accuracy: 0.955067\n",
      "test_loss: 0.108927, test_accuracy: 0.912310\n",
      "train_loss: 0.101419, train_accuracy: 0.955067\n",
      "test_loss: 0.108946, test_accuracy: 0.912310\n",
      "train_loss: 0.101433, train_accuracy: 0.955067\n",
      "test_loss: 0.108965, test_accuracy: 0.912310\n",
      "train_loss: 0.101448, train_accuracy: 0.955067\n",
      "test_loss: 0.108983, test_accuracy: 0.912310\n",
      "train_loss: 0.101462, train_accuracy: 0.955067\n",
      "test_loss: 0.109002, test_accuracy: 0.912310\n",
      "train_loss: 0.101476, train_accuracy: 0.955067\n",
      "test_loss: 0.109021, test_accuracy: 0.912310\n",
      "train_loss: 0.101489, train_accuracy: 0.955067\n",
      "test_loss: 0.109039, test_accuracy: 0.912310\n",
      "train_loss: 0.101503, train_accuracy: 0.955067\n",
      "test_loss: 0.109058, test_accuracy: 0.912310\n",
      "train_loss: 0.101517, train_accuracy: 0.955067\n",
      "test_loss: 0.109076, test_accuracy: 0.912310\n",
      "train_loss: 0.101531, train_accuracy: 0.955067\n",
      "test_loss: 0.109094, test_accuracy: 0.912310\n",
      "train_loss: 0.101544, train_accuracy: 0.956023\n",
      "test_loss: 0.109112, test_accuracy: 0.912310\n",
      "train_loss: 0.101558, train_accuracy: 0.956023\n",
      "test_loss: 0.109130, test_accuracy: 0.912310\n",
      "train_loss: 0.101571, train_accuracy: 0.956023\n",
      "test_loss: 0.109148, test_accuracy: 0.912310\n",
      "train_loss: 0.101584, train_accuracy: 0.956023\n",
      "test_loss: 0.109166, test_accuracy: 0.912310\n",
      "train_loss: 0.101598, train_accuracy: 0.956023\n",
      "test_loss: 0.109184, test_accuracy: 0.912310\n",
      "train_loss: 0.101611, train_accuracy: 0.956023\n",
      "test_loss: 0.109202, test_accuracy: 0.912310\n",
      "train_loss: 0.101624, train_accuracy: 0.956023\n",
      "test_loss: 0.109220, test_accuracy: 0.912310\n",
      "train_loss: 0.101637, train_accuracy: 0.956023\n",
      "test_loss: 0.109237, test_accuracy: 0.912310\n",
      "train_loss: 0.101650, train_accuracy: 0.956023\n",
      "test_loss: 0.109255, test_accuracy: 0.912310\n",
      "train_loss: 0.101663, train_accuracy: 0.956023\n",
      "test_loss: 0.109272, test_accuracy: 0.912310\n",
      "train_loss: 0.101676, train_accuracy: 0.956023\n",
      "test_loss: 0.109290, test_accuracy: 0.912310\n",
      "train_loss: 0.101688, train_accuracy: 0.956023\n",
      "test_loss: 0.109307, test_accuracy: 0.912310\n",
      "train_loss: 0.101701, train_accuracy: 0.956023\n",
      "test_loss: 0.109324, test_accuracy: 0.912310\n",
      "train_loss: 0.101714, train_accuracy: 0.956023\n",
      "test_loss: 0.109342, test_accuracy: 0.911467\n",
      "train_loss: 0.101726, train_accuracy: 0.956023\n",
      "test_loss: 0.109359, test_accuracy: 0.911467\n",
      "train_loss: 0.101739, train_accuracy: 0.956023\n",
      "test_loss: 0.109376, test_accuracy: 0.911467\n",
      "train_loss: 0.101751, train_accuracy: 0.956023\n",
      "test_loss: 0.109393, test_accuracy: 0.911467\n",
      "train_loss: 0.101763, train_accuracy: 0.956023\n",
      "test_loss: 0.109410, test_accuracy: 0.910624\n",
      "train_loss: 0.101775, train_accuracy: 0.956023\n",
      "test_loss: 0.109427, test_accuracy: 0.910624\n",
      "train_loss: 0.101788, train_accuracy: 0.956023\n",
      "test_loss: 0.109444, test_accuracy: 0.910624\n",
      "train_loss: 0.101800, train_accuracy: 0.956023\n",
      "test_loss: 0.109460, test_accuracy: 0.910624\n",
      "train_loss: 0.101812, train_accuracy: 0.956023\n",
      "test_loss: 0.109477, test_accuracy: 0.910624\n",
      "train_loss: 0.101824, train_accuracy: 0.956023\n",
      "test_loss: 0.109494, test_accuracy: 0.910624\n",
      "train_loss: 0.101835, train_accuracy: 0.956023\n",
      "test_loss: 0.109510, test_accuracy: 0.911467\n",
      "train_loss: 0.101847, train_accuracy: 0.956023\n",
      "test_loss: 0.109526, test_accuracy: 0.911467\n",
      "train_loss: 0.101859, train_accuracy: 0.956023\n",
      "test_loss: 0.109543, test_accuracy: 0.911467\n",
      "train_loss: 0.101871, train_accuracy: 0.956023\n",
      "test_loss: 0.109559, test_accuracy: 0.911467\n",
      "train_loss: 0.101882, train_accuracy: 0.956023\n",
      "test_loss: 0.109575, test_accuracy: 0.911467\n",
      "train_loss: 0.101894, train_accuracy: 0.956023\n",
      "test_loss: 0.109592, test_accuracy: 0.911467\n",
      "train_loss: 0.101905, train_accuracy: 0.956023\n",
      "test_loss: 0.109608, test_accuracy: 0.911467\n",
      "train_loss: 0.101916, train_accuracy: 0.956023\n",
      "test_loss: 0.109624, test_accuracy: 0.911467\n",
      "train_loss: 0.101928, train_accuracy: 0.956023\n",
      "test_loss: 0.109640, test_accuracy: 0.911467\n",
      "train_loss: 0.101939, train_accuracy: 0.956023\n",
      "test_loss: 0.109656, test_accuracy: 0.910624\n",
      "train_loss: 0.101950, train_accuracy: 0.956023\n",
      "test_loss: 0.109672, test_accuracy: 0.910624\n",
      "train_loss: 0.101961, train_accuracy: 0.956023\n",
      "test_loss: 0.109687, test_accuracy: 0.910624\n",
      "train_loss: 0.101972, train_accuracy: 0.956023\n",
      "test_loss: 0.109703, test_accuracy: 0.910624\n",
      "train_loss: 0.101983, train_accuracy: 0.956023\n",
      "test_loss: 0.109719, test_accuracy: 0.910624\n",
      "train_loss: 0.101994, train_accuracy: 0.956023\n",
      "test_loss: 0.109734, test_accuracy: 0.910624\n",
      "train_loss: 0.102005, train_accuracy: 0.956023\n",
      "test_loss: 0.109750, test_accuracy: 0.910624\n",
      "train_loss: 0.102016, train_accuracy: 0.956023\n",
      "test_loss: 0.109766, test_accuracy: 0.910624\n",
      "train_loss: 0.102027, train_accuracy: 0.956023\n",
      "test_loss: 0.109781, test_accuracy: 0.910624\n",
      "train_loss: 0.102037, train_accuracy: 0.956023\n",
      "test_loss: 0.109796, test_accuracy: 0.910624\n",
      "train_loss: 0.102048, train_accuracy: 0.956023\n",
      "test_loss: 0.109812, test_accuracy: 0.910624\n",
      "train_loss: 0.102058, train_accuracy: 0.956023\n",
      "test_loss: 0.109827, test_accuracy: 0.910624\n",
      "train_loss: 0.102069, train_accuracy: 0.956023\n",
      "test_loss: 0.109842, test_accuracy: 0.910624\n",
      "train_loss: 0.102079, train_accuracy: 0.956023\n",
      "test_loss: 0.109857, test_accuracy: 0.910624\n",
      "train_loss: 0.102090, train_accuracy: 0.956979\n",
      "test_loss: 0.109872, test_accuracy: 0.910624\n",
      "train_loss: 0.102100, train_accuracy: 0.956979\n",
      "test_loss: 0.109887, test_accuracy: 0.910624\n",
      "train_loss: 0.102110, train_accuracy: 0.956979\n",
      "test_loss: 0.109902, test_accuracy: 0.910624\n",
      "train_loss: 0.102120, train_accuracy: 0.956979\n",
      "test_loss: 0.109917, test_accuracy: 0.910624\n",
      "train_loss: 0.102130, train_accuracy: 0.956979\n",
      "test_loss: 0.109932, test_accuracy: 0.909781\n",
      "train_loss: 0.102140, train_accuracy: 0.956979\n",
      "test_loss: 0.109947, test_accuracy: 0.909781\n",
      "train_loss: 0.102150, train_accuracy: 0.956979\n",
      "test_loss: 0.109961, test_accuracy: 0.909781\n",
      "train_loss: 0.102160, train_accuracy: 0.956979\n",
      "test_loss: 0.109976, test_accuracy: 0.909781\n",
      "train_loss: 0.102170, train_accuracy: 0.956979\n",
      "test_loss: 0.109991, test_accuracy: 0.909781\n",
      "train_loss: 0.102180, train_accuracy: 0.956979\n",
      "test_loss: 0.110005, test_accuracy: 0.909781\n",
      "train_loss: 0.102190, train_accuracy: 0.956979\n",
      "test_loss: 0.110020, test_accuracy: 0.909781\n",
      "train_loss: 0.102199, train_accuracy: 0.956979\n",
      "test_loss: 0.110034, test_accuracy: 0.909781\n",
      "train_loss: 0.102209, train_accuracy: 0.956979\n",
      "test_loss: 0.110048, test_accuracy: 0.909781\n",
      "train_loss: 0.102219, train_accuracy: 0.956979\n",
      "test_loss: 0.110063, test_accuracy: 0.909781\n",
      "train_loss: 0.102228, train_accuracy: 0.956979\n",
      "test_loss: 0.110077, test_accuracy: 0.909781\n",
      "train_loss: 0.102238, train_accuracy: 0.956979\n",
      "test_loss: 0.110091, test_accuracy: 0.909781\n",
      "train_loss: 0.102247, train_accuracy: 0.956979\n",
      "test_loss: 0.110105, test_accuracy: 0.909781\n",
      "train_loss: 0.102256, train_accuracy: 0.956979\n",
      "test_loss: 0.110120, test_accuracy: 0.909781\n",
      "train_loss: 0.102266, train_accuracy: 0.956979\n",
      "test_loss: 0.110134, test_accuracy: 0.909781\n",
      "train_loss: 0.102275, train_accuracy: 0.956979\n",
      "test_loss: 0.110148, test_accuracy: 0.909781\n",
      "train_loss: 0.102284, train_accuracy: 0.956979\n",
      "test_loss: 0.110161, test_accuracy: 0.909781\n",
      "train_loss: 0.102293, train_accuracy: 0.956979\n",
      "test_loss: 0.110175, test_accuracy: 0.909781\n",
      "train_loss: 0.102302, train_accuracy: 0.956979\n",
      "test_loss: 0.110189, test_accuracy: 0.909781\n",
      "train_loss: 0.102311, train_accuracy: 0.956979\n",
      "test_loss: 0.110203, test_accuracy: 0.909781\n",
      "train_loss: 0.102320, train_accuracy: 0.956979\n",
      "test_loss: 0.110217, test_accuracy: 0.909781\n",
      "train_loss: 0.102329, train_accuracy: 0.956979\n",
      "test_loss: 0.110230, test_accuracy: 0.909781\n",
      "train_loss: 0.102338, train_accuracy: 0.956979\n",
      "test_loss: 0.110244, test_accuracy: 0.909781\n",
      "train_loss: 0.102347, train_accuracy: 0.956979\n",
      "test_loss: 0.110257, test_accuracy: 0.909781\n",
      "train_loss: 0.102356, train_accuracy: 0.956979\n",
      "test_loss: 0.110271, test_accuracy: 0.909781\n",
      "train_loss: 0.102364, train_accuracy: 0.956979\n",
      "test_loss: 0.110284, test_accuracy: 0.909781\n",
      "train_loss: 0.102373, train_accuracy: 0.956979\n",
      "test_loss: 0.110298, test_accuracy: 0.909781\n",
      "train_loss: 0.102382, train_accuracy: 0.956979\n",
      "test_loss: 0.110311, test_accuracy: 0.909781\n",
      "train_loss: 0.102390, train_accuracy: 0.956979\n",
      "test_loss: 0.110324, test_accuracy: 0.909781\n",
      "train_loss: 0.102399, train_accuracy: 0.956979\n",
      "test_loss: 0.110338, test_accuracy: 0.909781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.102407, train_accuracy: 0.956979\n",
      "test_loss: 0.110351, test_accuracy: 0.909781\n",
      "train_loss: 0.102416, train_accuracy: 0.956979\n",
      "test_loss: 0.110364, test_accuracy: 0.909781\n",
      "train_loss: 0.102424, train_accuracy: 0.956023\n",
      "test_loss: 0.110377, test_accuracy: 0.909781\n",
      "train_loss: 0.102432, train_accuracy: 0.956023\n",
      "test_loss: 0.110390, test_accuracy: 0.909781\n",
      "train_loss: 0.102440, train_accuracy: 0.956023\n",
      "test_loss: 0.110403, test_accuracy: 0.909781\n",
      "train_loss: 0.102449, train_accuracy: 0.956023\n",
      "test_loss: 0.110416, test_accuracy: 0.909781\n",
      "train_loss: 0.102457, train_accuracy: 0.956023\n",
      "test_loss: 0.110429, test_accuracy: 0.909781\n",
      "train_loss: 0.102465, train_accuracy: 0.956979\n",
      "test_loss: 0.110442, test_accuracy: 0.909781\n",
      "train_loss: 0.102473, train_accuracy: 0.956979\n",
      "test_loss: 0.110455, test_accuracy: 0.909781\n",
      "train_loss: 0.102481, train_accuracy: 0.956979\n",
      "test_loss: 0.110468, test_accuracy: 0.909781\n",
      "train_loss: 0.102489, train_accuracy: 0.956979\n",
      "test_loss: 0.110480, test_accuracy: 0.909781\n",
      "train_loss: 0.102497, train_accuracy: 0.957935\n",
      "test_loss: 0.110493, test_accuracy: 0.909781\n",
      "train_loss: 0.102505, train_accuracy: 0.957935\n",
      "test_loss: 0.110506, test_accuracy: 0.910624\n",
      "train_loss: 0.102513, train_accuracy: 0.957935\n",
      "test_loss: 0.110518, test_accuracy: 0.910624\n",
      "train_loss: 0.102520, train_accuracy: 0.957935\n",
      "test_loss: 0.110531, test_accuracy: 0.910624\n",
      "train_loss: 0.102528, train_accuracy: 0.957935\n",
      "test_loss: 0.110543, test_accuracy: 0.910624\n",
      "train_loss: 0.102536, train_accuracy: 0.957935\n",
      "test_loss: 0.110556, test_accuracy: 0.910624\n",
      "train_loss: 0.102543, train_accuracy: 0.957935\n",
      "test_loss: 0.110568, test_accuracy: 0.910624\n",
      "train_loss: 0.102551, train_accuracy: 0.957935\n",
      "test_loss: 0.110580, test_accuracy: 0.910624\n",
      "train_loss: 0.102559, train_accuracy: 0.957935\n",
      "test_loss: 0.110593, test_accuracy: 0.910624\n",
      "train_loss: 0.102566, train_accuracy: 0.957935\n",
      "test_loss: 0.110605, test_accuracy: 0.910624\n",
      "train_loss: 0.102574, train_accuracy: 0.957935\n",
      "test_loss: 0.110617, test_accuracy: 0.910624\n",
      "train_loss: 0.102581, train_accuracy: 0.957935\n",
      "test_loss: 0.110629, test_accuracy: 0.910624\n",
      "train_loss: 0.102588, train_accuracy: 0.957935\n",
      "test_loss: 0.110641, test_accuracy: 0.910624\n",
      "train_loss: 0.102596, train_accuracy: 0.958891\n",
      "test_loss: 0.110653, test_accuracy: 0.910624\n",
      "train_loss: 0.102603, train_accuracy: 0.958891\n",
      "test_loss: 0.110665, test_accuracy: 0.910624\n",
      "train_loss: 0.102610, train_accuracy: 0.958891\n",
      "test_loss: 0.110677, test_accuracy: 0.910624\n",
      "train_loss: 0.102617, train_accuracy: 0.958891\n",
      "test_loss: 0.110689, test_accuracy: 0.911467\n",
      "train_loss: 0.102625, train_accuracy: 0.958891\n",
      "test_loss: 0.110701, test_accuracy: 0.911467\n",
      "train_loss: 0.102632, train_accuracy: 0.958891\n",
      "test_loss: 0.110713, test_accuracy: 0.911467\n",
      "train_loss: 0.102639, train_accuracy: 0.958891\n",
      "test_loss: 0.110725, test_accuracy: 0.911467\n",
      "train_loss: 0.102646, train_accuracy: 0.958891\n",
      "test_loss: 0.110737, test_accuracy: 0.911467\n",
      "train_loss: 0.102653, train_accuracy: 0.958891\n",
      "test_loss: 0.110748, test_accuracy: 0.912310\n",
      "train_loss: 0.102660, train_accuracy: 0.958891\n",
      "test_loss: 0.110760, test_accuracy: 0.912310\n",
      "train_loss: 0.102667, train_accuracy: 0.958891\n",
      "test_loss: 0.110772, test_accuracy: 0.912310\n",
      "train_loss: 0.102674, train_accuracy: 0.958891\n",
      "test_loss: 0.110783, test_accuracy: 0.912310\n",
      "train_loss: 0.102680, train_accuracy: 0.958891\n",
      "test_loss: 0.110795, test_accuracy: 0.912310\n",
      "train_loss: 0.102687, train_accuracy: 0.958891\n",
      "test_loss: 0.110806, test_accuracy: 0.912310\n",
      "train_loss: 0.102694, train_accuracy: 0.958891\n",
      "test_loss: 0.110818, test_accuracy: 0.912310\n",
      "train_loss: 0.102701, train_accuracy: 0.958891\n",
      "test_loss: 0.110829, test_accuracy: 0.912310\n",
      "train_loss: 0.102707, train_accuracy: 0.958891\n",
      "test_loss: 0.110841, test_accuracy: 0.912310\n",
      "train_loss: 0.102714, train_accuracy: 0.959847\n",
      "test_loss: 0.110852, test_accuracy: 0.912310\n",
      "train_loss: 0.102720, train_accuracy: 0.959847\n",
      "test_loss: 0.110863, test_accuracy: 0.912310\n",
      "train_loss: 0.102727, train_accuracy: 0.959847\n",
      "test_loss: 0.110875, test_accuracy: 0.912310\n",
      "train_loss: 0.102734, train_accuracy: 0.960803\n",
      "test_loss: 0.110886, test_accuracy: 0.912310\n",
      "train_loss: 0.102740, train_accuracy: 0.961759\n",
      "test_loss: 0.110897, test_accuracy: 0.912310\n",
      "train_loss: 0.102746, train_accuracy: 0.961759\n",
      "test_loss: 0.110908, test_accuracy: 0.912310\n",
      "train_loss: 0.102753, train_accuracy: 0.961759\n",
      "test_loss: 0.110919, test_accuracy: 0.913153\n",
      "train_loss: 0.102759, train_accuracy: 0.961759\n",
      "test_loss: 0.110930, test_accuracy: 0.913153\n",
      "train_loss: 0.102766, train_accuracy: 0.961759\n",
      "test_loss: 0.110941, test_accuracy: 0.913997\n",
      "train_loss: 0.102772, train_accuracy: 0.961759\n",
      "test_loss: 0.110952, test_accuracy: 0.913997\n",
      "train_loss: 0.102778, train_accuracy: 0.961759\n",
      "test_loss: 0.110963, test_accuracy: 0.913997\n",
      "train_loss: 0.102784, train_accuracy: 0.961759\n",
      "test_loss: 0.110974, test_accuracy: 0.913997\n",
      "train_loss: 0.102790, train_accuracy: 0.961759\n",
      "test_loss: 0.110985, test_accuracy: 0.913997\n",
      "train_loss: 0.102797, train_accuracy: 0.961759\n",
      "test_loss: 0.110996, test_accuracy: 0.913997\n",
      "train_loss: 0.102803, train_accuracy: 0.961759\n",
      "test_loss: 0.111007, test_accuracy: 0.913997\n",
      "train_loss: 0.102809, train_accuracy: 0.961759\n",
      "test_loss: 0.111017, test_accuracy: 0.913997\n",
      "train_loss: 0.102815, train_accuracy: 0.961759\n",
      "test_loss: 0.111028, test_accuracy: 0.913997\n",
      "train_loss: 0.102821, train_accuracy: 0.961759\n",
      "test_loss: 0.111039, test_accuracy: 0.913997\n",
      "train_loss: 0.102827, train_accuracy: 0.961759\n",
      "test_loss: 0.111049, test_accuracy: 0.913997\n",
      "train_loss: 0.102833, train_accuracy: 0.961759\n",
      "test_loss: 0.111060, test_accuracy: 0.913997\n",
      "train_loss: 0.102839, train_accuracy: 0.961759\n",
      "test_loss: 0.111071, test_accuracy: 0.913997\n",
      "train_loss: 0.102844, train_accuracy: 0.961759\n",
      "test_loss: 0.111081, test_accuracy: 0.913997\n",
      "train_loss: 0.102850, train_accuracy: 0.961759\n",
      "test_loss: 0.111092, test_accuracy: 0.913997\n",
      "train_loss: 0.102856, train_accuracy: 0.961759\n",
      "test_loss: 0.111102, test_accuracy: 0.913997\n",
      "train_loss: 0.102862, train_accuracy: 0.961759\n",
      "test_loss: 0.111113, test_accuracy: 0.913997\n",
      "train_loss: 0.102867, train_accuracy: 0.961759\n",
      "test_loss: 0.111123, test_accuracy: 0.913997\n",
      "train_loss: 0.102873, train_accuracy: 0.961759\n",
      "test_loss: 0.111133, test_accuracy: 0.913997\n",
      "train_loss: 0.102879, train_accuracy: 0.961759\n",
      "test_loss: 0.111144, test_accuracy: 0.913997\n",
      "train_loss: 0.102884, train_accuracy: 0.961759\n",
      "test_loss: 0.111154, test_accuracy: 0.913997\n",
      "train_loss: 0.102890, train_accuracy: 0.961759\n",
      "test_loss: 0.111164, test_accuracy: 0.913997\n",
      "train_loss: 0.102896, train_accuracy: 0.961759\n",
      "test_loss: 0.111174, test_accuracy: 0.913997\n",
      "train_loss: 0.102901, train_accuracy: 0.961759\n",
      "test_loss: 0.111185, test_accuracy: 0.913997\n",
      "train_loss: 0.102907, train_accuracy: 0.961759\n",
      "test_loss: 0.111195, test_accuracy: 0.913997\n",
      "train_loss: 0.102912, train_accuracy: 0.961759\n",
      "test_loss: 0.111205, test_accuracy: 0.913997\n",
      "train_loss: 0.102917, train_accuracy: 0.961759\n",
      "test_loss: 0.111215, test_accuracy: 0.913997\n",
      "train_loss: 0.102923, train_accuracy: 0.961759\n",
      "test_loss: 0.111225, test_accuracy: 0.914840\n",
      "train_loss: 0.102928, train_accuracy: 0.961759\n",
      "test_loss: 0.111235, test_accuracy: 0.914840\n",
      "train_loss: 0.102934, train_accuracy: 0.961759\n",
      "test_loss: 0.111245, test_accuracy: 0.914840\n",
      "train_loss: 0.102939, train_accuracy: 0.961759\n",
      "test_loss: 0.111255, test_accuracy: 0.914840\n",
      "train_loss: 0.102944, train_accuracy: 0.961759\n",
      "test_loss: 0.111265, test_accuracy: 0.913997\n",
      "train_loss: 0.102949, train_accuracy: 0.961759\n",
      "test_loss: 0.111275, test_accuracy: 0.913997\n",
      "train_loss: 0.102955, train_accuracy: 0.961759\n",
      "test_loss: 0.111285, test_accuracy: 0.913997\n",
      "train_loss: 0.102960, train_accuracy: 0.960803\n",
      "test_loss: 0.111294, test_accuracy: 0.913997\n",
      "train_loss: 0.102965, train_accuracy: 0.960803\n",
      "test_loss: 0.111304, test_accuracy: 0.913997\n",
      "train_loss: 0.102970, train_accuracy: 0.960803\n",
      "test_loss: 0.111314, test_accuracy: 0.913997\n",
      "train_loss: 0.102975, train_accuracy: 0.960803\n",
      "test_loss: 0.111324, test_accuracy: 0.913997\n",
      "train_loss: 0.102980, train_accuracy: 0.960803\n",
      "test_loss: 0.111333, test_accuracy: 0.913997\n",
      "train_loss: 0.102985, train_accuracy: 0.960803\n",
      "test_loss: 0.111343, test_accuracy: 0.913997\n",
      "train_loss: 0.102990, train_accuracy: 0.960803\n",
      "test_loss: 0.111352, test_accuracy: 0.914840\n",
      "train_loss: 0.102995, train_accuracy: 0.960803\n",
      "test_loss: 0.111362, test_accuracy: 0.914840\n",
      "train_loss: 0.103000, train_accuracy: 0.960803\n",
      "test_loss: 0.111372, test_accuracy: 0.914840\n",
      "train_loss: 0.103005, train_accuracy: 0.960803\n",
      "test_loss: 0.111381, test_accuracy: 0.914840\n",
      "train_loss: 0.103010, train_accuracy: 0.960803\n",
      "test_loss: 0.111391, test_accuracy: 0.914840\n",
      "train_loss: 0.103015, train_accuracy: 0.960803\n",
      "test_loss: 0.111400, test_accuracy: 0.914840\n",
      "train_loss: 0.103020, train_accuracy: 0.960803\n",
      "test_loss: 0.111410, test_accuracy: 0.914840\n",
      "train_loss: 0.103024, train_accuracy: 0.960803\n",
      "test_loss: 0.111419, test_accuracy: 0.914840\n",
      "train_loss: 0.103029, train_accuracy: 0.960803\n",
      "test_loss: 0.111428, test_accuracy: 0.914840\n",
      "train_loss: 0.103034, train_accuracy: 0.960803\n",
      "test_loss: 0.111438, test_accuracy: 0.914840\n",
      "train_loss: 0.103039, train_accuracy: 0.960803\n",
      "test_loss: 0.111447, test_accuracy: 0.914840\n",
      "train_loss: 0.103043, train_accuracy: 0.960803\n",
      "test_loss: 0.111456, test_accuracy: 0.914840\n",
      "train_loss: 0.103048, train_accuracy: 0.960803\n",
      "test_loss: 0.111465, test_accuracy: 0.914840\n",
      "train_loss: 0.103052, train_accuracy: 0.960803\n",
      "test_loss: 0.111475, test_accuracy: 0.915683\n",
      "train_loss: 0.103057, train_accuracy: 0.960803\n",
      "test_loss: 0.111484, test_accuracy: 0.915683\n",
      "train_loss: 0.103062, train_accuracy: 0.960803\n",
      "test_loss: 0.111493, test_accuracy: 0.915683\n",
      "train_loss: 0.103066, train_accuracy: 0.960803\n",
      "test_loss: 0.111502, test_accuracy: 0.915683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.103071, train_accuracy: 0.960803\n",
      "test_loss: 0.111511, test_accuracy: 0.915683\n",
      "train_loss: 0.103075, train_accuracy: 0.960803\n",
      "test_loss: 0.111520, test_accuracy: 0.915683\n",
      "train_loss: 0.103080, train_accuracy: 0.960803\n",
      "test_loss: 0.111529, test_accuracy: 0.915683\n",
      "train_loss: 0.103084, train_accuracy: 0.960803\n",
      "test_loss: 0.111538, test_accuracy: 0.915683\n",
      "train_loss: 0.103089, train_accuracy: 0.960803\n",
      "test_loss: 0.111547, test_accuracy: 0.915683\n",
      "train_loss: 0.103093, train_accuracy: 0.959847\n",
      "test_loss: 0.111556, test_accuracy: 0.915683\n",
      "train_loss: 0.103097, train_accuracy: 0.959847\n",
      "test_loss: 0.111565, test_accuracy: 0.915683\n",
      "train_loss: 0.103102, train_accuracy: 0.959847\n",
      "test_loss: 0.111574, test_accuracy: 0.915683\n",
      "train_loss: 0.103106, train_accuracy: 0.959847\n",
      "test_loss: 0.111583, test_accuracy: 0.915683\n",
      "train_loss: 0.103110, train_accuracy: 0.959847\n",
      "test_loss: 0.111592, test_accuracy: 0.915683\n",
      "train_loss: 0.103115, train_accuracy: 0.959847\n",
      "test_loss: 0.111601, test_accuracy: 0.915683\n",
      "train_loss: 0.103119, train_accuracy: 0.959847\n",
      "test_loss: 0.111609, test_accuracy: 0.915683\n",
      "train_loss: 0.103123, train_accuracy: 0.959847\n",
      "test_loss: 0.111618, test_accuracy: 0.915683\n",
      "train_loss: 0.103127, train_accuracy: 0.959847\n",
      "test_loss: 0.111627, test_accuracy: 0.915683\n",
      "train_loss: 0.103131, train_accuracy: 0.959847\n",
      "test_loss: 0.111636, test_accuracy: 0.915683\n",
      "train_loss: 0.103136, train_accuracy: 0.959847\n",
      "test_loss: 0.111644, test_accuracy: 0.915683\n",
      "train_loss: 0.103140, train_accuracy: 0.959847\n",
      "test_loss: 0.111653, test_accuracy: 0.915683\n",
      "Sequential training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 250\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "for epoch in range(700):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(E_2_seq, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) \n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 250\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "for epoch in range(40):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(E_1_seq, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_ = subnet_output(alpha_1, beta_1, X_) \n",
    "logits__ = sess.run(logits_, feed_dict={X: [x_test[4000]]})\n",
    "print(logits__)\n",
    "print(np.argmax(logits__))\n",
    "print(y_test[4000])\n",
    "plt.imshow(x_test[4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_alpha(alpha, size):\n",
    "    tmp = sess.run(alpha)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            plt.subplot(2,5,i*5+j+1)\n",
    "            plt.imshow(np.reshape(tmp[:,i*5+j], [size,size]))\n",
    "\n",
    "def visualize_beta(beta):\n",
    "    tmp = sess.run(beta)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(tmp)\n",
    "    \n",
    "            \n",
    "\"\"\"visualize subnet nodes\"\"\"            \n",
    "visualize_alpha(alpha_1, 10)\n",
    "visualize_beta(beta_1)\n",
    "visualize_alpha(alpha_2, 10)\n",
    "visualize_beta(beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_elm import ML_ELM\n",
    "\n",
    "mlelm1 = ML_ELM(input_size=input_size, output_size=output_size, name='mlelm1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.math.sin(tf.constant([0.9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
