{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 7131)\n",
      "[['-0.362772' '-0.314085' '-0.177185' ... '0.343084' '-1.243480'\n",
      "  '1.804020']\n",
      " ['-0.459580' '-0.719855' '-1.005840' ... '-0.729734' '-0.639368'\n",
      "  '0.344724']\n",
      " ['0.103909' '-0.296076' '-0.165474' ... '0.181200' '-0.626812'\n",
      "  '0.237308']\n",
      " ...\n",
      " ['-0.512385' '-0.326583' '-0.091035' ... '0.180162' '0.701266'\n",
      "  '-0.305400']\n",
      " ['-0.213418' '0.415821' '-0.361252' ... '1.001600' '-0.390027'\n",
      "  '-0.624770']\n",
      " ['-0.724510' '-0.359479' '-0.847507' ... '0.222557' '-0.733495'\n",
      "  '-0.821411']]\n",
      "[[0.12875974 0.25393584 0.24650594 ... 0.53694991 0.17216095 0.88753505]\n",
      " [0.11473679 0.18010967 0.0178938  ... 0.31134664 0.30510462 0.54421007]\n",
      " [0.19635998 0.25721241 0.24973681 ... 0.50290726 0.30786775 0.51893857]\n",
      " ...\n",
      " [0.10708781 0.25166194 0.27027329 ... 0.50268898 0.60013072 0.39125699]\n",
      " [0.15039415 0.3867356  0.19572491 ... 0.67542947 0.35997575 0.31611959]\n",
      " [0.07636082 0.24567681 0.06157524 ... 0.51160424 0.2843906  0.26985635]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype <U9 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 7129)\n",
      "(15, 7129)\n",
      "(29,)\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import mnist_handler\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"; \n",
    "INPUT_DIMENSION = 7129\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "train_dataset = np.array(pd.read_csv(\"UCI dataset/duke\", header = None,delimiter=' '))\n",
    "print(train_dataset.shape)\n",
    "label = train_dataset[:,0]\n",
    "data = train_dataset[:,2:]\n",
    "label = label.reshape(label.shape[0], 1)\n",
    "\n",
    "data1 = []\n",
    "for i in data:\n",
    "    data2 = []\n",
    "    for j in i:\n",
    "        [_, value] = j.split(\":\")\n",
    "        data2.append(value)\n",
    "    data1.append(data2)\n",
    "    \n",
    "data = np.array(data1)\n",
    "data = np.array(data1)\n",
    "print(data)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "print(data)\n",
    "\n",
    "label1 = np.where(label==-1, 0, label)\n",
    "label1 = np.where(label1==1.0, 1, label1)\n",
    "#print(label1)\n",
    "data2 = np.concatenate((label1, data), axis = 1)\n",
    "\n",
    "p = np.random.permutation(len(data2))\n",
    "data2 = data2[p]\n",
    "x_train = data2[0:29,1:]\n",
    "y_train = data2[0:29,0]\n",
    "x_test = data2[29:,1:]\n",
    "y_test = data2[29:,0]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "border = 11\n",
    "x_train_init = x_train[:border]\n",
    "y_train_init = y_train[:border]\n",
    "x_train_seq = x_train[border:]\n",
    "y_train_seq = y_train[border:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 7129), (18, 7129))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_init.shape,x_train_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # clear all the tensors\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "\"\"\"Placeholders\"\"\"\n",
    "X_ = tf.placeholder(tf.float32, [None, INPUT_DIMENSION])\n",
    "#X_ = tf.reshape(X, [-1, INPUT_DIMENSION]) # Flatten X: [N,D]\n",
    "Y = tf.placeholder(tf.int64, [None]) # labels\n",
    "Y_ = tf.one_hot(indices=Y, depth=NUM_CLASSES) # one_hot labels: [N,M]\n",
    "\n",
    "\"\"\"Some constants\"\"\"\n",
    "D = INPUT_DIMENSION\n",
    "M = NUM_CLASSES # Number of outputs\n",
    "C = tf.constant(2.0**(-1))\n",
    "\n",
    "\"\"\"Weights\"\"\"\n",
    "alpha_1 = tf.get_variable('alpha_1',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False) # 1st subnetwork\n",
    "alpha_2 = tf.get_variable('alpha_2',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False) # 2st subnetwork\n",
    "alpha_3 = tf.get_variable('alpha_3',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_1 = tf.get_variable('beta_1',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_2 = tf.get_variable('beta_2',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_3 = tf.get_variable('beta_3',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tf.get_variable('k',shape=[D, D],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "m = tf.get_variable('m',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions\"\"\"\n",
    "def mul(A, B):\n",
    "    return tf.matmul(A, B)\n",
    "\n",
    "def inv(A):\n",
    "    return tf.matrix_inverse(A)\n",
    "\n",
    "def t(A):\n",
    "    return tf.transpose(A)\n",
    "\n",
    "def sin(A):\n",
    "    return tf.math.sin(A)\n",
    "\n",
    "def asin(A):\n",
    "    return tf.math.asin(A)\n",
    "\n",
    "def sqrt(A):\n",
    "    return tf.sqrt(A)\n",
    "\n",
    "def sqr(A):\n",
    "    return tf.math.pow(A, 2)\n",
    "\n",
    "def pseudo_inv(A, I, C):\n",
    "    C_I = I/C\n",
    "    return mul(t(A), inv(C_I + mul(A, t(A))))\n",
    "\n",
    "def h(A):\n",
    "    '''activation function'''\n",
    "    return sin(A)\n",
    "\n",
    "def h_(A):\n",
    "    '''inverse activation function'''\n",
    "    return asin(A)\n",
    "\n",
    "def u(A):\n",
    "    '''normalize the input to (0,1]'''\n",
    "    return tf.math.sigmoid(A) # sigmoid\n",
    "    \n",
    "def u_(A):\n",
    "    '''the inverse of u'''\n",
    "    ONE = tf.constant(1.0)\n",
    "    return -(tf.math.log(ONE/A - ONE)) # the inverse of sigmoid\n",
    "    \n",
    "def subnet_output(alpha, beta, A):\n",
    "    return t(mul(beta, h(mul(t(alpha), t(A))))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial Training Graph\"\"\"\n",
    "# D: input dimension\n",
    "# N: number of input samples\n",
    "# M: number of classes (number of outputs)\n",
    "'''some pre-computations'''\n",
    "X_init = t(X_) # [D,N]\n",
    "Y_init = t(Y_) # [M,N]\n",
    "N_init = D # number of dimensions\n",
    "I_DxD = tf.eye(N_init, dtype=tf.float32) # [D,D]\n",
    "I_MxM = tf.eye(M, dtype=tf.float32) # [M,M]\n",
    "C_I = I_DxD/C\n",
    "H_I = I_MxM/C\n",
    "\n",
    "add = C_I + mul(X_init, t(X_init))\n",
    "k = tf.assign(k,add)\n",
    "X_inv_init = pseudo_inv(X_init, I_DxD, C) # [N,D]\n",
    "\n",
    "'''1st subnet'''\n",
    "alpha_1_init_calculated = t(mul(h_(Y_init), X_inv_init)) # ([M,N]x[N,D])T=[D,M]\n",
    "alpha_1_init = tf.assign(alpha_1, alpha_1_init_calculated) # [D,M]\n",
    "H_1_init = h(mul(t(alpha_1_init), X_init)) # [M,N]\n",
    "H_add = H_I + mul(H_1_init,t(H_1_init))\n",
    "m = tf.assign(m,H_add)\n",
    "H_pseudo_init = pseudo_inv(H_1_init,I_MxM,C) #[N,M]\n",
    "\n",
    "beta_1_init_calculated = mul(Y_init, t(H_1_init))/sqr(tf.norm(H_1_init)) # [M,M]\n",
    "beta_1_init_calculated = mul(Y_init,H_pseudo_init)\n",
    "\n",
    "beta_1_init = tf.assign(beta_1, beta_1_init_calculated) # [M,M]\n",
    "H_beta_1_init = mul(beta_1_init, t(mul(t(X_init), alpha_1_init))) # [M,N]\n",
    "E_1_init = Y_init - H_beta_1_init # [M,N]\n",
    "\n",
    "'''2nd subnet'''\n",
    "#alpha_2_init_calculated = t(mul(h_(E_1_init), X_inv_init)) # [D,M]    \n",
    "alpha_2_init_calculated = t(mul(asin(Y_init), X_inv_init)) # [D,M]\n",
    "\n",
    "alpha_2_init = tf.assign(alpha_2, alpha_2_init_calculated) # [D,M]\n",
    "H_2_init = h(mul(t(alpha_2_init), X_init)) # [M,N]\n",
    "H_2_inv_init = pseudo_inv(H_2_init, I_MxM, C) # [M,N]\n",
    "H_add = H_I + mul(H_2_init,t(H_2_init))\n",
    "#m = tf.assign(m,H_add)\n",
    "H_pseudo_init = pseudo_inv(H_2_init,I_MxM,C) #[N,M]\n",
    "\n",
    "beta_2_init_calculated = mul(E_1_init, t(H_2_init))/sqr(tf.norm(H_2_init)) # [M,M]\n",
    "beta_2_init_calculated = mul(E_1_init, H_pseudo_init)\n",
    "\n",
    "beta_2_init = tf.assign(beta_2, beta_2_init_calculated) # [M,M]\n",
    "H_beta_2_init = mul(beta_2_init, t(mul(t(X_init), alpha_2_init))) # [M,N]\n",
    "E_2_init = Y_init - (H_beta_1_init+H_beta_2_init) # [M,N]\n",
    "\n",
    "'''3rd subnetwork'''\n",
    "alpha_3_init_calculated = t(mul(h_(E_2_init), X_inv_init)) # [D,M]    \n",
    "alpha_3_init_calculated = t(mul(asin(Y_init), X_inv_init)) # [D,M]\n",
    "\n",
    "alpha_3_init = tf.assign(alpha_3, alpha_3_init_calculated) # [D,M]\n",
    "H_3_init = h(mul(t(alpha_3_init), X_init)) # [M,N]\n",
    "H_3_inv_init = pseudo_inv(H_3_init, I_MxM, C) # [M,N]\n",
    "\n",
    "beta_3_init_calculated = mul(E_2_init, t(H_3_init))/sqr(tf.norm(H_3_init)) # [M,M]\n",
    "beta_3_init_calculated = mul(E_2_init, H_3_inv_init)\n",
    "\n",
    "beta_3_init = tf.assign(beta_3, beta_3_init_calculated) # [M,M]\n",
    "H_beta_3_init = mul(beta_3_init, t(mul(t(X_init), alpha_3_init))) # [M,N]\n",
    "E_3_init = Y_init - (H_beta_3_init+H_beta_2_init+ H_beta_1_init) # [M,N]\n",
    "\n",
    "#init_train_graph = H_beta_1_init\n",
    "init_train_graph = E_3_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_3:0' shape=(6, 6) dtype=float32_ref>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''With one subnetwork'''\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) \n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[7129,7129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node k/Initializer/random_uniform/RandomUniform (defined at <ipython-input-16-c1d777e3ab1f>:1)  = RandomUniform[T=DT_INT32, _class=[\"loc:@k/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](k/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'k/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-c1d777e3ab1f>\", line 1, in <module>\n    k = tf.get_variable('k',shape=[D, D],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/init_ops.py\", line 255, in __call__\n    shape, self.minval, self.maxval, dtype, seed=self.seed)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/random_ops.py\", line 243, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 733, in random_uniform\n    name=name)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7129,7129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node k/Initializer/random_uniform/RandomUniform (defined at <ipython-input-16-c1d777e3ab1f>:1)  = RandomUniform[T=DT_INT32, _class=[\"loc:@k/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](k/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7129,7129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node k/Initializer/random_uniform/RandomUniform}} = RandomUniform[T=DT_INT32, _class=[\"loc:@k/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](k/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2213bab7d8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Initialize variables\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7129,7129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node k/Initializer/random_uniform/RandomUniform (defined at <ipython-input-16-c1d777e3ab1f>:1)  = RandomUniform[T=DT_INT32, _class=[\"loc:@k/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](k/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'k/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-c1d777e3ab1f>\", line 1, in <module>\n    k = tf.get_variable('k',shape=[D, D],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1487, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1237, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 540, in get_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 922, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 183, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 146, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 125, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2444, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 1329, in __init__\n    constraint=constraint)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variables.py\", line 1437, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/variable_scope.py\", line 896, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/init_ops.py\", line 255, in __call__\n    shape, self.minval, self.maxval, dtype, seed=self.seed)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/random_ops.py\", line 243, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 733, in random_uniform\n    name=name)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7129,7129] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node k/Initializer/random_uniform/RandomUniform (defined at <ipython-input-16-c1d777e3ab1f>:1)  = RandomUniform[T=DT_INT32, _class=[\"loc:@k/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](k/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "\n",
    "sess.run(E_1_init, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) \n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "s  =0\n",
    "t1 = time.time()\n",
    "sess.run(E_2_init, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+=(t2-t1)\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "import time\n",
    "t1 = time.time()\n",
    "s = 0\n",
    "sess.run(init_train_graph, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+= t2 -t1\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sequential Training Graph\"\"\"\n",
    "# D: input dimension\n",
    "# N: number of input samples\n",
    "# M: number of classes (number of outputs)\n",
    "X_seq = t(X_) # [D,N]\n",
    "Y_seq = t(Y_) # [M,N]\n",
    "pseudo = mul(X_seq, X_) #DXD\n",
    "k = tf.assign(k, tf.add(k,pseudo)) #DXD\n",
    "k_inv = inv(k)\n",
    "\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_1))\n",
    "alpha1_seq = tf.assign(alpha_1,tf.add(alpha_1,new)) #DXM\n",
    "H_1_seq = h(mul(t(alpha1_seq), X_seq)) # [M,N]\n",
    "m_su = mul(H_1_seq,t(H_1_seq))\n",
    "m = tf.assign(m,tf.add(m,m_su))\n",
    "m_inv = inv(m)\n",
    "#update = tf.matmul(tf.matmul(m_inv,H_1_seq),h_(Y_seq)- tf.matmul())\n",
    "H_pseudo_init = pseudo_inv(H_1_seq,I_MxM,C) #[N,M]\n",
    "#UPDATE = tf.matmul(tf.matmul(K_inverse, HT), inverse_acti_y - tf.matmul(H, self.__outputWeight))\n",
    "beta_1_seq_calculated = mul(Y_seq, H_pseudo_init) # [M,M]\n",
    "beta_1_seq = tf.assign(beta_1, beta_1_seq_calculated) # [M,M]\n",
    "H_beta_1_seq = mul(beta_1_seq, t(mul(X_, alpha1_seq))) # [M,N]\n",
    "E_1_seq = Y_seq - H_beta_1_seq # [M,N]\n",
    "\n",
    "'''2nd subnetwork'''\n",
    "\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_2))\n",
    "alpha2_seq = tf.assign(alpha_2,tf.add(alpha_2,new)) #DXM\n",
    "H_2_seq = h(mul(t(alpha2_seq), X_seq)) # [M,N]\n",
    "H_pseudo_init = pseudo_inv(H_2_seq,I_MxM,C) #[N,M]\n",
    "beta_2_seq_calculated = mul(E_1_seq, H_pseudo_init) # [M,M]\n",
    "beta_2_seq = tf.assign(beta_2, beta_2_seq_calculated) # [M,M]\n",
    "H_beta_2_seq = mul(beta_2_seq, t(mul(t(X_seq), alpha2_seq))) # [M,N]\n",
    "E_2_seq = Y_seq - (H_beta_2_seq+ H_beta_1_seq) # [M,N]\n",
    "\n",
    "'''3rd subnetwork'''\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_3))\n",
    "alpha3_seq = tf.assign(alpha_3,tf.add(alpha_3,new)) #DXM\n",
    "H_3_seq = h(mul(t(alpha3_seq), X_seq)) # [M,N]\n",
    "H_pseudo_init = pseudo_inv(H_3_seq,I_MxM,C) #[N,M]\n",
    "beta_3_seq_calculated = mul(E_2_seq, H_pseudo_init) # [M,M]\n",
    "beta_3_seq = tf.assign(beta_3, beta_3_seq_calculated) # [M,M]\n",
    "H_beta_3_seq = mul(beta_3_seq, t(mul(t(X_seq), alpha3_seq))) # [M,N]\n",
    "E_3_seq = Y_seq - (H_beta_3_seq +H_beta_2_seq + H_beta_1_seq )# [M,N]\n",
    "seq_train_graph = E_3_seq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.025626, train_accuracy: 1.000000\n",
      "test_loss: 0.095337, test_accuracy: 0.600000\n",
      "train_loss: 0.027915, train_accuracy: 1.000000\n",
      "test_loss: 0.097253, test_accuracy: 0.600000\n",
      "train_loss: 0.029965, train_accuracy: 1.000000\n",
      "test_loss: 0.098664, test_accuracy: 0.600000\n",
      "train_loss: 0.031021, train_accuracy: 1.000000\n",
      "test_loss: 0.099488, test_accuracy: 0.600000\n",
      "train_loss: 0.031532, train_accuracy: 1.000000\n",
      "test_loss: 0.099952, test_accuracy: 0.666667\n",
      "train_loss: 0.031766, train_accuracy: 1.000000\n",
      "test_loss: 0.100194, test_accuracy: 0.666667\n",
      "train_loss: 0.031861, train_accuracy: 1.000000\n",
      "test_loss: 0.100297, test_accuracy: 0.666667\n",
      "train_loss: 0.031883, train_accuracy: 1.000000\n",
      "test_loss: 0.100312, test_accuracy: 0.666667\n",
      "train_loss: 0.031868, train_accuracy: 1.000000\n",
      "test_loss: 0.100271, test_accuracy: 0.666667\n",
      "train_loss: 0.031834, train_accuracy: 1.000000\n",
      "test_loss: 0.100193, test_accuracy: 0.666667\n",
      "train_loss: 0.031790, train_accuracy: 1.000000\n",
      "test_loss: 0.100093, test_accuracy: 0.666667\n",
      "train_loss: 0.031742, train_accuracy: 1.000000\n",
      "test_loss: 0.099979, test_accuracy: 0.666667\n",
      "train_loss: 0.031692, train_accuracy: 1.000000\n",
      "test_loss: 0.099857, test_accuracy: 0.666667\n",
      "train_loss: 0.031642, train_accuracy: 1.000000\n",
      "test_loss: 0.099730, test_accuracy: 0.666667\n",
      "train_loss: 0.031592, train_accuracy: 1.000000\n",
      "test_loss: 0.099601, test_accuracy: 0.666667\n",
      "train_loss: 0.031543, train_accuracy: 1.000000\n",
      "test_loss: 0.099472, test_accuracy: 0.666667\n",
      "train_loss: 0.031496, train_accuracy: 1.000000\n",
      "test_loss: 0.099342, test_accuracy: 0.666667\n",
      "train_loss: 0.031450, train_accuracy: 1.000000\n",
      "test_loss: 0.099214, test_accuracy: 0.666667\n",
      "train_loss: 0.031405, train_accuracy: 1.000000\n",
      "test_loss: 0.099087, test_accuracy: 0.666667\n",
      "train_loss: 0.031361, train_accuracy: 1.000000\n",
      "test_loss: 0.098962, test_accuracy: 0.666667\n",
      "train_loss: 0.031318, train_accuracy: 1.000000\n",
      "test_loss: 0.098838, test_accuracy: 0.666667\n",
      "train_loss: 0.031277, train_accuracy: 1.000000\n",
      "test_loss: 0.098716, test_accuracy: 0.666667\n",
      "train_loss: 0.031236, train_accuracy: 1.000000\n",
      "test_loss: 0.098595, test_accuracy: 0.666667\n",
      "train_loss: 0.031197, train_accuracy: 1.000000\n",
      "test_loss: 0.098476, test_accuracy: 0.666667\n",
      "train_loss: 0.031158, train_accuracy: 1.000000\n",
      "test_loss: 0.098359, test_accuracy: 0.666667\n",
      "train_loss: 0.031121, train_accuracy: 1.000000\n",
      "test_loss: 0.098243, test_accuracy: 0.666667\n",
      "train_loss: 0.031084, train_accuracy: 1.000000\n",
      "test_loss: 0.098129, test_accuracy: 0.666667\n",
      "train_loss: 0.031048, train_accuracy: 1.000000\n",
      "test_loss: 0.098017, test_accuracy: 0.666667\n",
      "train_loss: 0.031013, train_accuracy: 1.000000\n",
      "test_loss: 0.097906, test_accuracy: 0.666667\n",
      "train_loss: 0.030979, train_accuracy: 1.000000\n",
      "test_loss: 0.097796, test_accuracy: 0.600000\n",
      "train_loss: 0.030945, train_accuracy: 1.000000\n",
      "test_loss: 0.097688, test_accuracy: 0.600000\n",
      "train_loss: 0.030913, train_accuracy: 1.000000\n",
      "test_loss: 0.097581, test_accuracy: 0.600000\n",
      "train_loss: 0.030881, train_accuracy: 1.000000\n",
      "test_loss: 0.097475, test_accuracy: 0.600000\n",
      "train_loss: 0.030849, train_accuracy: 1.000000\n",
      "test_loss: 0.097370, test_accuracy: 0.600000\n",
      "train_loss: 0.030819, train_accuracy: 1.000000\n",
      "test_loss: 0.097267, test_accuracy: 0.600000\n",
      "train_loss: 0.030789, train_accuracy: 1.000000\n",
      "test_loss: 0.097165, test_accuracy: 0.600000\n",
      "train_loss: 0.030759, train_accuracy: 1.000000\n",
      "test_loss: 0.097065, test_accuracy: 0.600000\n",
      "train_loss: 0.030731, train_accuracy: 1.000000\n",
      "test_loss: 0.096965, test_accuracy: 0.600000\n",
      "train_loss: 0.030703, train_accuracy: 1.000000\n",
      "test_loss: 0.096867, test_accuracy: 0.600000\n",
      "train_loss: 0.030675, train_accuracy: 1.000000\n",
      "test_loss: 0.096769, test_accuracy: 0.600000\n",
      "train_loss: 0.030648, train_accuracy: 1.000000\n",
      "test_loss: 0.096673, test_accuracy: 0.600000\n",
      "train_loss: 0.030622, train_accuracy: 1.000000\n",
      "test_loss: 0.096578, test_accuracy: 0.600000\n",
      "train_loss: 0.030596, train_accuracy: 1.000000\n",
      "test_loss: 0.096484, test_accuracy: 0.600000\n",
      "train_loss: 0.030571, train_accuracy: 1.000000\n",
      "test_loss: 0.096391, test_accuracy: 0.600000\n",
      "train_loss: 0.030547, train_accuracy: 1.000000\n",
      "test_loss: 0.096300, test_accuracy: 0.600000\n",
      "train_loss: 0.030523, train_accuracy: 1.000000\n",
      "test_loss: 0.096209, test_accuracy: 0.600000\n",
      "train_loss: 0.030499, train_accuracy: 1.000000\n",
      "test_loss: 0.096119, test_accuracy: 0.600000\n",
      "train_loss: 0.030476, train_accuracy: 1.000000\n",
      "test_loss: 0.096030, test_accuracy: 0.600000\n",
      "train_loss: 0.030454, train_accuracy: 1.000000\n",
      "test_loss: 0.095943, test_accuracy: 0.600000\n",
      "train_loss: 0.030432, train_accuracy: 1.000000\n",
      "test_loss: 0.095856, test_accuracy: 0.600000\n",
      "train_loss: 0.030410, train_accuracy: 1.000000\n",
      "test_loss: 0.095770, test_accuracy: 0.600000\n",
      "train_loss: 0.030389, train_accuracy: 1.000000\n",
      "test_loss: 0.095685, test_accuracy: 0.600000\n",
      "train_loss: 0.030368, train_accuracy: 1.000000\n",
      "test_loss: 0.095602, test_accuracy: 0.600000\n",
      "train_loss: 0.030348, train_accuracy: 1.000000\n",
      "test_loss: 0.095519, test_accuracy: 0.600000\n",
      "train_loss: 0.030328, train_accuracy: 1.000000\n",
      "test_loss: 0.095437, test_accuracy: 0.600000\n",
      "train_loss: 0.030309, train_accuracy: 1.000000\n",
      "test_loss: 0.095356, test_accuracy: 0.600000\n",
      "train_loss: 0.030290, train_accuracy: 1.000000\n",
      "test_loss: 0.095276, test_accuracy: 0.600000\n",
      "train_loss: 0.030272, train_accuracy: 1.000000\n",
      "test_loss: 0.095196, test_accuracy: 0.600000\n",
      "train_loss: 0.030254, train_accuracy: 1.000000\n",
      "test_loss: 0.095118, test_accuracy: 0.600000\n",
      "train_loss: 0.030236, train_accuracy: 1.000000\n",
      "test_loss: 0.095040, test_accuracy: 0.600000\n",
      "train_loss: 0.030219, train_accuracy: 1.000000\n",
      "test_loss: 0.094964, test_accuracy: 0.600000\n",
      "train_loss: 0.030202, train_accuracy: 1.000000\n",
      "test_loss: 0.094888, test_accuracy: 0.600000\n",
      "train_loss: 0.030186, train_accuracy: 1.000000\n",
      "test_loss: 0.094813, test_accuracy: 0.600000\n",
      "train_loss: 0.030170, train_accuracy: 1.000000\n",
      "test_loss: 0.094739, test_accuracy: 0.600000\n",
      "train_loss: 0.030154, train_accuracy: 1.000000\n",
      "test_loss: 0.094665, test_accuracy: 0.600000\n",
      "train_loss: 0.030139, train_accuracy: 1.000000\n",
      "test_loss: 0.094593, test_accuracy: 0.600000\n",
      "train_loss: 0.030124, train_accuracy: 1.000000\n",
      "test_loss: 0.094521, test_accuracy: 0.600000\n",
      "train_loss: 0.030109, train_accuracy: 1.000000\n",
      "test_loss: 0.094450, test_accuracy: 0.600000\n",
      "train_loss: 0.030095, train_accuracy: 1.000000\n",
      "test_loss: 0.094380, test_accuracy: 0.600000\n",
      "train_loss: 0.030081, train_accuracy: 1.000000\n",
      "test_loss: 0.094311, test_accuracy: 0.600000\n",
      "train_loss: 0.030067, train_accuracy: 1.000000\n",
      "test_loss: 0.094242, test_accuracy: 0.600000\n",
      "train_loss: 0.030054, train_accuracy: 1.000000\n",
      "test_loss: 0.094174, test_accuracy: 0.600000\n",
      "train_loss: 0.030041, train_accuracy: 1.000000\n",
      "test_loss: 0.094107, test_accuracy: 0.600000\n",
      "train_loss: 0.030028, train_accuracy: 1.000000\n",
      "test_loss: 0.094041, test_accuracy: 0.600000\n",
      "train_loss: 0.030015, train_accuracy: 1.000000\n",
      "test_loss: 0.093975, test_accuracy: 0.600000\n",
      "train_loss: 0.030003, train_accuracy: 1.000000\n",
      "test_loss: 0.093910, test_accuracy: 0.600000\n",
      "train_loss: 0.029991, train_accuracy: 1.000000\n",
      "test_loss: 0.093846, test_accuracy: 0.600000\n",
      "train_loss: 0.029980, train_accuracy: 1.000000\n",
      "test_loss: 0.093783, test_accuracy: 0.600000\n",
      "train_loss: 0.029968, train_accuracy: 1.000000\n",
      "test_loss: 0.093720, test_accuracy: 0.600000\n",
      "train_loss: 0.029957, train_accuracy: 1.000000\n",
      "test_loss: 0.093658, test_accuracy: 0.600000\n",
      "train_loss: 0.029947, train_accuracy: 1.000000\n",
      "test_loss: 0.093596, test_accuracy: 0.600000\n",
      "train_loss: 0.029936, train_accuracy: 1.000000\n",
      "test_loss: 0.093535, test_accuracy: 0.600000\n",
      "train_loss: 0.029926, train_accuracy: 1.000000\n",
      "test_loss: 0.093475, test_accuracy: 0.600000\n",
      "train_loss: 0.029916, train_accuracy: 1.000000\n",
      "test_loss: 0.093416, test_accuracy: 0.600000\n",
      "train_loss: 0.029906, train_accuracy: 1.000000\n",
      "test_loss: 0.093357, test_accuracy: 0.600000\n",
      "train_loss: 0.029897, train_accuracy: 1.000000\n",
      "test_loss: 0.093299, test_accuracy: 0.600000\n",
      "train_loss: 0.029887, train_accuracy: 1.000000\n",
      "test_loss: 0.093241, test_accuracy: 0.600000\n",
      "train_loss: 0.029878, train_accuracy: 1.000000\n",
      "test_loss: 0.093184, test_accuracy: 0.600000\n",
      "train_loss: 0.029869, train_accuracy: 1.000000\n",
      "test_loss: 0.093128, test_accuracy: 0.600000\n",
      "train_loss: 0.029861, train_accuracy: 1.000000\n",
      "test_loss: 0.093072, test_accuracy: 0.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.029852, train_accuracy: 1.000000\n",
      "test_loss: 0.093017, test_accuracy: 0.600000\n",
      "train_loss: 0.029844, train_accuracy: 1.000000\n",
      "test_loss: 0.092963, test_accuracy: 0.600000\n",
      "train_loss: 0.029836, train_accuracy: 1.000000\n",
      "test_loss: 0.092909, test_accuracy: 0.600000\n",
      "train_loss: 0.029828, train_accuracy: 1.000000\n",
      "test_loss: 0.092855, test_accuracy: 0.600000\n",
      "train_loss: 0.029821, train_accuracy: 1.000000\n",
      "test_loss: 0.092803, test_accuracy: 0.600000\n",
      "train_loss: 0.029813, train_accuracy: 1.000000\n",
      "test_loss: 0.092750, test_accuracy: 0.600000\n",
      "train_loss: 0.029806, train_accuracy: 1.000000\n",
      "test_loss: 0.092699, test_accuracy: 0.600000\n",
      "train_loss: 0.029799, train_accuracy: 1.000000\n",
      "test_loss: 0.092648, test_accuracy: 0.600000\n",
      "train_loss: 0.029792, train_accuracy: 1.000000\n",
      "test_loss: 0.092597, test_accuracy: 0.600000\n",
      "train_loss: 0.029786, train_accuracy: 1.000000\n",
      "test_loss: 0.092547, test_accuracy: 0.600000\n",
      "Sequential training done\n",
      "70.9501256942749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 9\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "t1 = time.time()\n",
    "for epoch in range(100):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(seq_train_graph, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+=t2-t1\n",
    "print(\"Sequential training done\")\n",
    "print(s)\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\"\n",
    "#tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X: x_train, Y: y_train})\n",
    "#ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X: x_test, Y: y_test})\n",
    "#print(\"Sequential train training loss: \", tr_loss)\n",
    "#print(\"Sequential train training accuracy: \", tr_acc)\n",
    "#print(\"Sequential train testing loss: \", ts_loss)\n",
    "#print(\"Sequential train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) \n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.037375, train_accuracy: 0.931035\n",
      "test_loss: 0.104861, test_accuracy: 0.400000\n",
      "train_loss: 0.031794, train_accuracy: 1.000000\n",
      "test_loss: 0.101827, test_accuracy: 0.533333\n",
      "train_loss: 0.031925, train_accuracy: 1.000000\n",
      "test_loss: 0.102039, test_accuracy: 0.533333\n",
      "train_loss: 0.032740, train_accuracy: 1.000000\n",
      "test_loss: 0.102562, test_accuracy: 0.533333\n",
      "train_loss: 0.033442, train_accuracy: 1.000000\n",
      "test_loss: 0.103038, test_accuracy: 0.533333\n",
      "train_loss: 0.033945, train_accuracy: 1.000000\n",
      "test_loss: 0.103417, test_accuracy: 0.533333\n",
      "train_loss: 0.034284, train_accuracy: 1.000000\n",
      "test_loss: 0.103705, test_accuracy: 0.533333\n",
      "train_loss: 0.034504, train_accuracy: 1.000000\n",
      "test_loss: 0.103917, test_accuracy: 0.533333\n",
      "train_loss: 0.034643, train_accuracy: 1.000000\n",
      "test_loss: 0.104066, test_accuracy: 0.533333\n",
      "train_loss: 0.034727, train_accuracy: 1.000000\n",
      "test_loss: 0.104166, test_accuracy: 0.533333\n",
      "train_loss: 0.034775, train_accuracy: 1.000000\n",
      "test_loss: 0.104226, test_accuracy: 0.533333\n",
      "train_loss: 0.034799, train_accuracy: 1.000000\n",
      "test_loss: 0.104255, test_accuracy: 0.533333\n",
      "train_loss: 0.034806, train_accuracy: 1.000000\n",
      "test_loss: 0.104259, test_accuracy: 0.533333\n",
      "train_loss: 0.034802, train_accuracy: 1.000000\n",
      "test_loss: 0.104244, test_accuracy: 0.533333\n",
      "train_loss: 0.034791, train_accuracy: 1.000000\n",
      "test_loss: 0.104214, test_accuracy: 0.533333\n",
      "train_loss: 0.034776, train_accuracy: 1.000000\n",
      "test_loss: 0.104171, test_accuracy: 0.533333\n",
      "train_loss: 0.034757, train_accuracy: 1.000000\n",
      "test_loss: 0.104120, test_accuracy: 0.533333\n",
      "train_loss: 0.034735, train_accuracy: 1.000000\n",
      "test_loss: 0.104061, test_accuracy: 0.533333\n",
      "train_loss: 0.034713, train_accuracy: 1.000000\n",
      "test_loss: 0.103997, test_accuracy: 0.533333\n",
      "train_loss: 0.034690, train_accuracy: 1.000000\n",
      "test_loss: 0.103929, test_accuracy: 0.533333\n",
      "train_loss: 0.034667, train_accuracy: 1.000000\n",
      "test_loss: 0.103858, test_accuracy: 0.533333\n",
      "train_loss: 0.034644, train_accuracy: 1.000000\n",
      "test_loss: 0.103785, test_accuracy: 0.533333\n",
      "train_loss: 0.034621, train_accuracy: 1.000000\n",
      "test_loss: 0.103710, test_accuracy: 0.533333\n",
      "train_loss: 0.034598, train_accuracy: 1.000000\n",
      "test_loss: 0.103635, test_accuracy: 0.533333\n",
      "train_loss: 0.034576, train_accuracy: 1.000000\n",
      "test_loss: 0.103558, test_accuracy: 0.533333\n",
      "train_loss: 0.034554, train_accuracy: 1.000000\n",
      "test_loss: 0.103482, test_accuracy: 0.533333\n",
      "train_loss: 0.034532, train_accuracy: 1.000000\n",
      "test_loss: 0.103405, test_accuracy: 0.533333\n",
      "train_loss: 0.034511, train_accuracy: 1.000000\n",
      "test_loss: 0.103328, test_accuracy: 0.533333\n",
      "train_loss: 0.034490, train_accuracy: 1.000000\n",
      "test_loss: 0.103251, test_accuracy: 0.533333\n",
      "train_loss: 0.034470, train_accuracy: 1.000000\n",
      "test_loss: 0.103175, test_accuracy: 0.533333\n",
      "train_loss: 0.034450, train_accuracy: 1.000000\n",
      "test_loss: 0.103099, test_accuracy: 0.533333\n",
      "train_loss: 0.034431, train_accuracy: 1.000000\n",
      "test_loss: 0.103024, test_accuracy: 0.533333\n",
      "train_loss: 0.034412, train_accuracy: 1.000000\n",
      "test_loss: 0.102949, test_accuracy: 0.533333\n",
      "train_loss: 0.034393, train_accuracy: 1.000000\n",
      "test_loss: 0.102875, test_accuracy: 0.533333\n",
      "train_loss: 0.034375, train_accuracy: 1.000000\n",
      "test_loss: 0.102801, test_accuracy: 0.533333\n",
      "train_loss: 0.034357, train_accuracy: 1.000000\n",
      "test_loss: 0.102728, test_accuracy: 0.533333\n",
      "train_loss: 0.034340, train_accuracy: 1.000000\n",
      "test_loss: 0.102655, test_accuracy: 0.533333\n",
      "train_loss: 0.034323, train_accuracy: 1.000000\n",
      "test_loss: 0.102583, test_accuracy: 0.533333\n",
      "train_loss: 0.034306, train_accuracy: 1.000000\n",
      "test_loss: 0.102511, test_accuracy: 0.533333\n",
      "train_loss: 0.034290, train_accuracy: 1.000000\n",
      "test_loss: 0.102440, test_accuracy: 0.533333\n",
      "train_loss: 0.034274, train_accuracy: 1.000000\n",
      "test_loss: 0.102370, test_accuracy: 0.533333\n",
      "train_loss: 0.034258, train_accuracy: 1.000000\n",
      "test_loss: 0.102300, test_accuracy: 0.533333\n",
      "train_loss: 0.034243, train_accuracy: 1.000000\n",
      "test_loss: 0.102231, test_accuracy: 0.533333\n",
      "train_loss: 0.034227, train_accuracy: 1.000000\n",
      "test_loss: 0.102162, test_accuracy: 0.533333\n",
      "train_loss: 0.034213, train_accuracy: 1.000000\n",
      "test_loss: 0.102094, test_accuracy: 0.533333\n",
      "train_loss: 0.034198, train_accuracy: 1.000000\n",
      "test_loss: 0.102026, test_accuracy: 0.533333\n",
      "train_loss: 0.034184, train_accuracy: 1.000000\n",
      "test_loss: 0.101959, test_accuracy: 0.533333\n",
      "train_loss: 0.034170, train_accuracy: 1.000000\n",
      "test_loss: 0.101893, test_accuracy: 0.533333\n",
      "train_loss: 0.034156, train_accuracy: 1.000000\n",
      "test_loss: 0.101827, test_accuracy: 0.533333\n",
      "train_loss: 0.034143, train_accuracy: 1.000000\n",
      "test_loss: 0.101761, test_accuracy: 0.533333\n",
      "Sequential training done\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-83aefc370142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sequential training done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtime_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\"\"\"Sequential training evaluation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_sum' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 6\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "for epoch in range(50):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    t1 = time.time()\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(E_2_seq, feed_dict={X_: x_batch, Y: y_batch})\n",
    "    t2 = time.time()\n",
    "    s+=(t2-t1)\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "print(\"Sequential training done\")\n",
    "time_sum = time_sum\n",
    "\"\"\"Sequential training evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) \n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7987442111968994"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.20870840549469"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.158726, train_accuracy: 0.448276\n",
      "test_loss: 0.227396, test_accuracy: 0.266667\n",
      "train_loss: 0.124700, train_accuracy: 0.655172\n",
      "test_loss: 0.291086, test_accuracy: 0.200000\n",
      "train_loss: 0.113931, train_accuracy: 0.655172\n",
      "test_loss: 0.286599, test_accuracy: 0.266667\n",
      "train_loss: 0.110388, train_accuracy: 0.793103\n",
      "test_loss: 0.280894, test_accuracy: 0.266667\n",
      "train_loss: 0.108524, train_accuracy: 0.793103\n",
      "test_loss: 0.276200, test_accuracy: 0.333333\n",
      "train_loss: 0.107338, train_accuracy: 0.793103\n",
      "test_loss: 0.271405, test_accuracy: 0.333333\n",
      "train_loss: 0.106554, train_accuracy: 0.793103\n",
      "test_loss: 0.266130, test_accuracy: 0.333333\n",
      "train_loss: 0.106049, train_accuracy: 0.758621\n",
      "test_loss: 0.260597, test_accuracy: 0.333333\n",
      "train_loss: 0.105737, train_accuracy: 0.758621\n",
      "test_loss: 0.255146, test_accuracy: 0.333333\n",
      "train_loss: 0.105549, train_accuracy: 0.758621\n",
      "test_loss: 0.250038, test_accuracy: 0.400000\n",
      "Sequential training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 6\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "for epoch in range(10):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(E_1_seq, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train_encoded, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test_encoded, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7953381f8c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogits_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubnet_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "logits_ = subnet_output(alpha_1, beta_1, X_) \n",
    "logits__ = sess.run(logits_, feed_dict={X: [x_test[4000]]})\n",
    "print(logits__)\n",
    "print(np.argmax(logits__))\n",
    "print(y_test[4000])\n",
    "plt.imshow(x_test[4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_alpha(alpha, size):\n",
    "    tmp = sess.run(alpha)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            plt.subplot(2,5,i*5+j+1)\n",
    "            plt.imshow(np.reshape(tmp[:,i*5+j], [size,size]))\n",
    "\n",
    "def visualize_beta(beta):\n",
    "    tmp = sess.run(beta)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(tmp)\n",
    "    \n",
    "            \n",
    "\"\"\"visualize subnet nodes\"\"\"            \n",
    "visualize_alpha(alpha_1, 28)\n",
    "visualize_beta(beta_1)\n",
    "visualize_alpha(alpha_2, 28)\n",
    "visualize_beta(beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc6b1e5e860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzsnXd4lFX2xz8nk16BkNBCFxAIGDDYqIrKIlhQFrAjrrp27OjuTxHXtSwrupZdXQtYFlBEXZVVFEVEsAAihiYtIMWQBAKppMz9/XFnUkiblMmknM/zvM/M28875X7vPfeec8UYg6IoitJy8fO1AYqiKIpvUSFQFEVp4agQKIqitHBUCBRFUVo4KgSKoigtHBUCRVGUFo4KgaIoSgtHhUBRFKWFo0KgKIrSwvH3tQGe0LZtW9OtWzdfm6EoitKkWLt2bZoxJqa645qEEHTr1o01a9b42gxFUZQmhYjs9uQ4dQ0piqK0cFQIFEVRWjgqBIqiKC0cFQJFUZQWjgqBoihKC0eFQFEUpYWjQqAoitLCUSFoBCQlwbx5cOyYry1RFKUlokLgY/Lz4YILYOpUFQJFUXyDCoGPeeYZ2LULXnoJIiOhqAjOPx9ef92+VxRF8TYqBD7kwAGYNQvGj4frrrPbfvsN9u6Fq6+G/v1h4UJwOn1rp6IozRsVAh/ypz9Zd9BTT5Vs69QJ1q6FRYvA3x+mTIGEBNizx3d2KorSvFEh8CH33GNdQr16ld3u5weXXAI//QRvvQVdukDHjnbfnj1gTMPbqihK80VMEyhVEhMTTXPKPmoMiNT8vKws6N4deveGRx6Bs86qf9sURWk+iMhaY0xidcdpi8AHzJsHv/89ZGbW7LzAQPjLX2D3bhg9Gs48E1au9I6NiqK0HFQIGpijR2HGDNshHBZWs3MDA+GGG2D7djvaaPNmGD4cfvzRO7YqitIyUCFoYB55BA4ehH/8w/YF1IbgYLjtNtixA958EwYNsttfew02bKg/WxVFaRmoEDQgW7fC00/DtGkwZEjdrxcWBpdfbt/n5cH998NJJ8Hkyba1oCiK4gkqBA3Igw9CaCj89a/1f+3gYFv4//nPsGQJxMfDlVfqsFNFUapHhaABef55WLwYYmO9c/3Wra3radcuuOsueP99yM21+5rA4DBFUXyEDh9tAAoKwOGofZ9AbcnMhIgI+37KFGjbFh54oCQmQVGU5o0OH21EPPUUnHpqzYeL1hW3CBQV2dbCiy9Cz562tXDwYMPaoihK40WFwMvs32/H/nfsWFIwNzQOB/zzn7azesoU22Hdowd88olv7FEUpXHhVSEQkVYiskhEtojIZhE5XURmisg+EVnvWs7zpg2+ZsYMm2q6dD4hX9Gjhx1iummTDWhzj1zauhWOHPGtbYqi+A5vtwieAT4xxpwInAS4BzXOMcYkuJYlXrbBZ6xeDW+8YV0xPXv62poS+vSxghAdbTuRr7jCpq54/HGbxkJRlJaF14RARCKBEcArAMaYfGNMhrfu1xh5+mnrEnrgAV9bUjkitu/gjDNsHEKPHjBnTsloI0VRmj/ebBH0AFKB10TkRxF5WUTcSRVuEZENIvKqiLSu6GQRuV5E1ojImtTUVC+a6T1efx2WLoXwcF9bUjWDB8NHH8GqVTYg7c47bUtGUZSWgdeGj4pIIvAtMNQY852IPAMcBZ4D0gADPAJ0MMZMq+paTW34aGamHSpa01xCjYWvv4ZTToGgIDsxTlYWXHUVBAT42jJFUWpCYxg+uhfYa4z5zrW+CBhsjEkxxhQZY5zAv4FTvGiDT3joIejXr+n624cPtyIA8Pbb8Ic/2Od5802dPlNRmiNeEwJjzG/AryLSx7VpNLBJRDqUOmwCkOQtG3zB5s3w7LMwZkzjdwl5wqJF8OGH9lmuvBIGDIDPPvO1VYqi1CfeHjV0K/CWiGwAEoC/Ak+KyM+ubWcCd3jZhgbDGJg+3bqEHn3U19bUDyJ2TmX39JkiNsEd2Gk2m0BguqIo1eDvzYsbY9YDx/unrvTmPX3Jhx/azuGnn4aYGF9bU7+4p8+86KKSVBmzZtnnfeQR2wKqzaxriqL4Ho0srkfee8/60m+6ydeWeA+Ho6TA798fUlNh7Fjbr7B8uU9NUxSllqgQ1COvvgpfftlyRtdcdhn88gu88ILNeHrmmTbVtqIoTQvNPloPpKRAYSF06uRrS3xHbq4NTDtzlOGk/B/Y9dYq/rfrROL7FNB/oIPoE1rb/NuxsbbnWf1IiuJ1PB0+6tU+gpbCXXfZBG67dzfd2IE6YQwhv2xgesoCuHgh7NrFbJ7nBX4HH9pD2nOAeJJYTAIRwYX8Ft2fsNgwItqHlQhERUtMTMlYVkVRvIIKQR355ht46y07M1iLE4HNm23E2YIFNnOdwwFnnw0PPshzF17EA4fySFqdSdLaPJI2Crt+HUD4tIcg9SD3Lb6A138cRtfA/cT7bSa+YB0JRWuYwsLy94mKKisMVQlHmzbWDkVRPEZdQ3WgqMhG4B48CFu2tBAh2LmzpPDfsMG6eEaOtPmtL77Y4+FSX30FK1fCxo2QlARbthh69XSy8aNkOHiQa/+vIxmHnMS32kt88Hb6s5FeuRsISDtgP/C0NHA6y1/Yz8/OwOOJaMTG2tzg6qZSminqGmoAXn0V1q2D+fObuQjs3WtDjBcsgB9+sNtOPx2eeQYmTqzVlGcjR9rFTUGBkJrqgI49oWdPHD0g6Vd4/6fuOJ3DATtE9ZOf7fH/fN5Jp8hM4mMP0i1gH35pB61AHL+sW2dfK8uzHRTkeWsjJsZODq0ozQwVgjqwdSuMGAGTJ/vaEi+QkmIjyBYssFV3sNnpnnwSJk2Crl3r9XYBAWX15KWX7Gturm1tJSXZWdbAzu9w23Q/CgujgChCQ3vRrx/88Y9w7Swb5LZ/v71ecWX/2DHbiqhILEovmzbZV3fU3PFERnouHNHR6qZSmgQqBHVg9mxbKDUbz8KhQ7B4sS38v/zSul7697cRY5MnQ69eDW5SSAgMGmQXN4GBkJ5uy+ykpBL3kttT9OuvVqdatbLmx8dDfHwQY8d2oucgD4Z2GQPZ2dWLxs6d8O23VmAqSsIkUjM3VWRkM/oxKU0J7SOoBb/8YjOMnnyyry2pB44ehQ8+sIX/0qV2HOwJJ1if/+TJthRtYqSn226MpCS7/PwzZGRYF96UKTZdxr33ugXCLv3723K4VjidcPhw9cJx8KCNwDt8uOLrBAbWzE0VElLrz0hpGWgfgZcwxkYOr18Pe/ZAaKivLaoFOTl2AoIFC2DJEus26dIF7rjDFv6DBzfpmml0dNnobmPgwIGSOaOzsqyQv/KKrfi7WbXKdn1s2GC/3/h46NvXg/LWz8/eNDranlAd+fmeuam2brUuuspmCYqIqJmbyl//7krF6C+jhrz/PixbBv/4RxMTgWPHbLDDggU2KVJ2NrRvDzfcYAv/004rSSLUzBAp2/8wciR8/72tyO/eXeJecpfh770HM2eWnNuzpxWFuXPtSNbDh21MXK0jyAMDrUGedrJ74qbavdt25B88WLmbKjraczdVVFSTrgwoNcMj15CIBAJdjDHbvW9SeRqLaygvz+YSCg21NcZGX8EqKLCqtXChLd2OHLGFwcSJ1kcyfLh2ZlZAYSFs317iWtq40a6vXWu18rrrYN48O/ezuw9i4EC44AJfW45Vt4yMql1T7vcpKZW7qQICPG9txMaqm6qRUm+uIREZBzwFBALdRSQBeMgYM6HuZjYt/v53m1Nn2bJGLAJFRbBihS38Fy2yDvPISDvGf/JkGD265SRDqiX+/nDiiXaZOLH8/kmTbNmYlGRbFgsX2laDWwimT7fla+k+iLi4Bqpg+/nZoLo2bewDVEdBQfVuqtRU2LbNvi/tSytNeLjnotG2bSP+A7VMPPk2ZgGnAl+CTS0tIid41apGSlCQnZzlrLN8bclxOJ129MrChXa8/2+/2WbLhRfamv+YMZqmoR455xy7uMnKsn0Qbg4fhs8/t3NWuxkzxnrmwM701rGjFYjY2IaxuVICAqBDB7t4QnZ22VZFRcuePbb5dPCgbV5VRHS0Z6IRG2uHf6mbyqt4IgQFxpgMKftFNP6hRl7g7rsb0UQsxthgqYUL7bJnjy3sx42zNf9x45p5lFvjITy87MjaefPs66FDJUNb27Sx2woL4dprbX8x2LIwPh6uvtouxlgPXqtWDfsMHhMWZpdu3ao/1piq3VTuJSnJikt6esXX8ff3vLURG9vEOu8aB54IwWYRmQT4iUh34HbspPQthm+/tQFKEyY0gopJUlJJioft2+2fZMwYOyXaBRfUYQykUt+0aWO7YYYPL9nmcNh+XbdAuBe3qz4lxVbOO3Uq61o688x6j+HzPiI2CrB1a9uhUh0FBVYMqhOO7durdlOFhXkuGm3bqqsUDzqLRSQMeBA417XpU2CWMSbHy7YV48vO4qIiSEy0v8+tW33UJ7ZtW0nhv3Gj9QOfdZZ1+0yYUFLdVJo86enw8sslndSbNtkBX3Pn2hbDxo3wpz+VjX/o08cORGpx5ORU76YqvVTmpmrd2jPRcLupmtDouvqMI4g2xtwH3Ffq4oOBdXWwr8nwyit2hNDChQ0sArt3l+T3Wef6qIcPh+eft3NGtmvXgMYoDUV0NNx3X8l6YaENYG7b1q6npdl6wUcflYwS9fe3s8MNHWorKxs3WpHo2bOZDwoLDbXNJE+aSm6fmycpRpYvr9xN5XB43tqIjW0y7llPWgRrgPONMQdc60OBF40xDRZy6qsWweHD1vcbH28zLnjdLXTgALzzji38V6+22045xdb8f/97O/REUbCthF9+KWk5TJ9uxeKxx+CBB+wxwcE2NqJ/fxv30rq1rUSHhDQCF2djp7DQqq6nLY6srIqvExLiuWi0bVvvTTtPWwSeCMGpwLPAeGAQ8CRwgTFmd30Y6gm+EoLbb4fnnrMV8pNO8tJNjLFj/J991uZmNsbebPJku/To4aUbK82R7Gw7TUTp/odffrEthYAAuOUWO5qpf38bE9Opk11uuMGef+CAPa5NmyblAfE9bjeVp8JRUFDxdVq1Ki8QN99c61Qv9eYaMsZ8JyJ3Ap8B+cC5xpiUWlnVxDjtNFuL8poIrFtn0zqsWGHz+zz0kC38PRn/rSgVEBZm+7QSK/nr/+53toBPSoKPP7ZlUlxciRD84Q8260jpaR0SEuCNN+z+//zHis3xZZU7fUeLpS5uqsrEY8sWWzY0QHrjSlsEIvIeZYeJDgD2A+n2WczFXrfORWOJLK43fvvN9vi99pp1Cv/lL3ZMoQbZKA1MUZHNO+hO8f3ZZ7b8KV0excSUpAU/6SSbi6k0w4fb8gpssF1WVlmRSEiwE9eB/em3bq1hLQ1FfbQInqtHe5oUH35om9O33VbPI8vy8mDOHPjrX62T96677ByXUVH1eBNF8RyHo0QEoHyw3PF8/72twKaklAhF6Z+vw1ESGnDwoP2ZT5lSIgR9+ljhcc8+GhNjxeP2221F+YUX7LbS/bE6+6j30TTUx5GbazvYIiOt56ZeKunG2HQP994Lyclw0UXwt79Zd5CiNFOMsVleCwpsw9cY+Pe/y3tEzjvP1omysip2Md1/v607ZWTYTCnHu6WGD7f/2cJC66rX2UdLqM9cQ5mUuIj8AQdwzBjTLCOXZs+2Ize//LKeRGDtWtsP8PXXNjPZsmWNMEeFotQ/ImXjG0Xg+usrPz4srGJ3+eDBdn92to3IPn720eees0KwebP9i5WefTQ21ta/Ro2ybqlPPy0/rYPOPupZZ3GxRouIH3Ax4K3uU5+yZ48dfjdxov3h1IkDB2w/wNy5ttftxRdtP4C2cRWlQtwTurVta0c0HU+nTiWzpoJ1O6Wm2hQfYAv12bPLC4k7ncf69TB1avnr/u9/thP9m29sQ/34Fse551r3VH6+/fs2x79wjeq8xhgnsEhE7gb+zzsm+Y5777XN19mz63CR3NySfoCCArjnHjuwW/sBFKVeCQoqG1rTvr11MVXGmWeWZKco3fJwz0Nx5EjJ7KOpqSVTn/70kxWCV16xIzndo6ncyzPP2PjOpCQb7Fd6X1OZfdQT11DpLOt+QCLQBB6t5txyi+0oq1VOF2NsMNi991rf0oQJtnrRs2e926koSs0JCrJ/x8r+kuedZxewInDokBUKdyhPYiL83/+VbW38+GOJC3nBApvyqzSBgTYuLSICXn3Vhgodnz9v7FgrFkVFvmtteNIi+H2p94VAMnChV6zxETk59kcybJhdasyaNbYfYOVKO77utdds9UNRlCaJO47CndoDYMgQu1TGHXfY7C+lhSItrcR19euvVghSUuwAQrD7MjPt+6uvhv/+t6xITJoEl1/unWcsjSd9BFd63wzfsX8/nH++na/lySdrcfIDD9i8w7GxdkjENdc0TyeioihV4p62ujIeesguxpTMPpqRUbJ//HgrAm4RSU62HdwNQZVCICLDgVsAd6jrZuA5Y8zKys9qOvz0k/3wDx+GWbNqcGJuLjz1lO1ZLiiwWcIeeEBTQCuKUi0itiXgbim4mTLFLr6g0mwiIjIWeAP4HJgGXAt8AbwuImMaxjzvsWSJdQMZYz0648Z5cJIxNg3piSfaQLAxY2y2wscfVxFQFKXJUlWL4F5ggjHmx1Lb1ojI98DT2HkJmiSpqTaZZ58+Noq4UycPTvrhB5vicdUqGzM/b149jDFVFEXxPVXlF+x4nAgAds5ioL33TPIe7iDqmBibcGvFCg9EYN8+24tzyil27NnLL9vOYRUBRVGaCVUJQSUJtgGoZI64sohIKxFZJCJbRGSziJwuIm1E5DMR2eZ6bV39lepOVpbN7PDmm3Z91KjyProy5ObCI49A7952XNiMGXaQsAaFKYrSzKjKNdRTRBZXsF0AT5PkPwN8YoyZKCKBQCjwALDMGPO4iMwAZlBq9jNvsG+fHRn00082grBK3P0A995rx3tdcokdTqTzAiiK0kypSgguqWJftZlJRSQSGAFMBTDG5AP5InIhMMp12DxgOV4UgvXr7cigI0dsf4A7YKRCvv/e9gOsXg2DBtkk7CNHess0RVGURkGlQmCMWVbHa/cAUoHXROQkYC1wO9DOPe2lMeaAiMTW8T6Vsm+fzUzYqlVJrFeFGAM33QT/+peNFX/lFdsvoC4gRVFaAN6cjM4fGAz80xgzCNuvMMPTk0XkehFZIyJrUlNTa2VAp07Wq/Pdd9XMMrZnjxWBq66y/QDTpqkIKIrSYvCmEOwF9hpjvnOtL8IKQ4qIdABwvR6s6GRjzEvGmERjTGJMTEytjbjxRujYsZqD3OF7kybpnHuKorQ4qgoom+t6vaU2FzbG/Ab8KiJ9XJtGA5uA/wJXu7ZdDXxQm+vXKymuKZjbtfOtHYqiKD6gqs7iU0SkE3CdiMzjuIyjxpijHlz/VuAt14ihncA1WPF5W0SuBfZQNqmdb1AhUBSlBVOVELyMHdHTBdhIWSEwru1V4go+q2iatNGem9gAuIUg1mv91oqiKI2WSl1DxpinjDG9gNeNMV2MMZ1LLdWKQJMiJcUOLQoK8rUliqIoDY4naaivE5F4wJ2pf4UxZpN3zWpgUlLULaQoSoul2lFDInIz8DbWFdQFeEdEbvK2YQ2KCoGiKC0YT2YouwE4xRiTBSAifwVWAS9407AGJSUFBg70tRWKoig+wZM4AgEKSq0X0NzmLNYWgaIoLRhPWgRvAN+KyLuu9QnYHEHNg2PH7HxxKgSKorRQPOksflJEvgSGY1sCfzTG/OB1yxqKg67AZhUCRVFaKJ60CHAV/M2n8C+NBpMpitLC8WauoaaBCoGiKC0cFQIVAkVRWjiexBH8UUSiGsIYn6BCoChKC8eTFkE3YJ2I/EdEzvayPQ1PSopNPR0S4mtLFEVRfEK1QmCMmQH0At4C/uiadH6WiHTzsm0Ng8YQKIrSwvGoj8AY4wSSXYsT6AB8ICKPec2yhkKFQFGUFo4nfQQ3icj3wDPYeYcHGmOuAwYBk71sn/dRIVAUpYXjSRxBHDDFGLOz9EZjjFNELvCOWQ1ISgqMHOlrKxRFUXyGJ66h9yg1r7CIRIhIIoAxJslbhjUIBQWQnq4tAkVRWjSeCMFLQE6p9WzgRe+Y08CkptpXFQJFUVowngiBn6uzGCjuOA7wnkkNiMYQKIqieCQEu0TkRhFxiIifa6KaZC/b1TCoECiKongkBDdgJ5tPcS0jgeu8aVSDoUKgKIriURrqFGBiA9jS8KgQKIqiVC8EIhIETAX6A8Hu7caY671nVgORkgKhoRAe7mtLFEVRfIYnrqHXsfmGxgPfAT2BPC/a1HBoMJmiKIpHQtDbGHM/kGWMeQX4HRDvXbMaCBUCRVEUj4TAPXF9hoj0BSKArt4zqQFRIVAURfFICF4RkdbAQ8CnwC/A371qVUOhQqAoilJ1Z7GIOIA0Y8xh4EugS4NY1RAUFUFamgqBoigtnipbBMaYImB6A9nSsKSlgdOpQqAoSovHE9fQpyIyXUQ6iEike/G6Zd5GYwgURVEAz9JQ3+B6vavUNkNTdxOpECiKogCeRRZ3bghDGhwVAkVRFMCzyOLLKtpujPlP/ZvTgKgQKIqiAJ65hoaXeh8MnIWdsrLpC0FQEEQ2/e4ORVGUuuCJa+jG0uuumIK53jKowXDHEIj42hJFURSf4smooePJBHrXtyENjgaTKYqiAJ71EbyHHSUEVjj6Ax94cnERScYKRxFQaIxJFJGZ2PkMXPNE8oAxZknNzK4HUlIgLq7Bb6soitLY8KSP4LlS7wuB3caY5Brc40xjTNpx2+YYY2bX4Br1T0oKnHyyT01QFEVpDHgiBNuAg8aYPAARCRGRzsaYX71rmhdxOuHgQXUNKYqi4FkfwWLAWWrdCbzr4fUNsFRE1opI6YlsbhGRDSLyqqvzuWE5dMjmGlIhUBRF8UgI/I0x+e4VY8wxIMjD6w81xgwGxgI3i8gI4J/YyW0SgANUkslURK4XkTUisiY1NbWiQ2qPxhAoiqIU44kQpIvIee4VERkPHPLk4saY/a7Xg8B7wCnGmBRjTJExxgn8GzilknNfMsYkGmMSY2JiPLmd56gQKIqiFONJH8GNwH9E5HmsqycNuKK6k0QkDPAzxmS63p8LzBKRDsaYA67DJgBJtTO9DqgQKIqiFONJQNkvQKKItHKtZ3h47XbAe2IDtvyB/xhjPhGRN0QkASsqyZQktWs4VAgURVGK8SSO4BHg724BcHXuTjfGPFTVecaYncBJFWy/spa21h8pKRAQAK0bvp9aURSlseFJH8H40q0A12xl53vPpAYgJQViYzW9hKIoCp4JgUNEAt0rIhIMBFZxfONH00soiqIU40ln8QLgMxF5FevXv5bmkHlUhUBRFAXwrLP4ryKyATgbEOBJY8zHXrfMm6SkwIABvrZCURSlUeBJiwBjzEfARwAicqqIPGOMud2rlnkLYzS9hKIoSik8EgIRiQcuBaYA+/E8xUTjIyMD8vNVCBRFUVxUKgQi0gNb8F8GZAELgQBjzPDKzmkSaAyBoihKGapqEWwHvgYudgWVISK3NohV3kSFQFEUpQxVDR+djE0nsUxEXhCRkdjO4qaNCoGiKEoZKhUCY8w7xphLgH7Ad8D9QHsReVZEzmooA+sdFQJFUZQyVBtQZozJNMbMM8b8DugMbAFmetswr5GSAg4HREf72hJFUZRGQY0mrzfGpBljnjfGjPCWQV4nJQViYsCvRo+uKIrSbGl5paFGFSuKopRBhUBRFKWFo0KgKIrSwvFkPoLD2GRzpTkCrAHuMcYke8Eu72CMCoGiKMpxeJJi4lkgBZtxVLDRxjHYgLPXgDO9Zl19k5kJeXkqBIqiKKXwRAjONcacVmr9BRH51hhzmojc6y3DvILGECiKopTDoz4CEbn4uPfuCGOnN4zyGioEiqIo5fBECK4ArhORQyKSDlwHXCkiocB0r1pX3zRGIdjwNsyJh5mt7OuGt31tUZ0pchpeWrGDhFlLeWnFDoqcx3cxKT6nGf7ulNrjycQ024Gxlez+qn7N8TKNTQg2vA0f3gYFuXb9yK92HWDgJN/ZVQd2pWVz81vr2JWWTW5BEXM+28YH6/fz3GWD6d42zNfmKdAsf3dK3fBk1FBbYBrQrfTxxpjrvWeWl0hJsRPWt23ra0ssy2aV/BndFOTC5zOb3B8yJ7+QbSlZXPbyt+QcKyoeZpZbUMSmA0cZ/4+v+fukBNqGBxIdHkTb8EAiggN8anOzJz8bslMhO82+9hgFASHwyf1V/+6OHoCCHAiLgaAI+59RmjWedBZ/AHwLrASKvGuOl0lJsSLg79F8PN7nyN6Ktx/db1+3/s/W3mL7QWxfu7TuBn6OBjPxeI4VFrHjYDa/Hs5hTP/2ANz9zk8sWlvJs2BH7WbnF/HHN9cWbxvcpRWLbxoKwC3/WUdmXiHR4YFEh1mhOLF9BKP6xAKQcjSPqJAAggN899yNiux0+O2nkgLevYy4x/4+1s+Hj++0hXlpbv4BYnpDTlrF13X/7r59AVb9w753BEFYW7v8YRk4AmDLEkjfZoUiLMa1Pwai4rz2yIp38aREDDPG3OV1SxqCxhJDUFRg/1BRnSoWg6hO9jU7DfathY2LS/b5h8BdmyGkNfz6A+RlWIGI7FSvNbfCIicOP0FE+HxTCot/3MvW3zJJTs+hyGkQgc2zfkdwgINhJ7Sla5tQerWLYM+hbJ75fBvZ+SV1htBAB/eM6cOQbm1Iz84nPesYYUElP71Ahx8ZOfnsSM0iLesYeQVOzhvQvlgIxjy9goycAsICHUSHBxEdHsh58R24bkQPAF5fnUxUSABtXfuiw4JoHRqAv6ORx0s6nfb7cxfkbXpCZAdI3wGrn3NtTy/Zf8nL0Osc+PVbWHBZyXX8AmxBfPI1Vgja9obEaSUFtLuwbtXZHh/V2bqDjsddkJ80Bdr1LyUyaZB3xP5mATb/F36aX/bckNZwX7J9/7/7YN+6siLRuhsMvtLuz/gV/IMhtI1PKzVKCZ4Iwf9E5FxjzFKvW+NtfC0EhcfsH3zdG3DDVzD6obK+WrBN99EP2feDr7TLsSxI3Qqpm+HQTvtBHcZ8AAAgAElEQVSnA/juX5C0yL4PioSYE6HjIDjvSbstPwcCQ6s163B2Puv2HGZrSibbUrLY+lsm21OzWHbnSDq3CeXXwzls2n+U3u0iGBvfgd7tI+jTLoIAV0F70aBOxdc6mlfAc19sL3N9fz/hkpPjiKzEFfTU5IQy6zn5heQXlgxIe2BsX1KzjpGelU96tn01LudTXkERD36wsdw1rx/RgwfO60vWsUKunftDGZGIDg/klO5t6N0ugsIiJ9n5RUQG+yP1JaSF+fDbBluIZh0sKUx7nws9z4K07TD3PLvNlGpkn/8MnDwVjmXCpg9KCvF2/e1rhG2B0eV0mPYphLpq6sFRZSsBcSfbpTJGP1jJ7+5B+75df7tUxkX/hPNml3U7FeaV7A9ta693OBn2/mBbIDF9S4Rg0TTY+z0gEBptn63LaXD+03b/2nn2cwmLcT1jDITHQnBkNR+8UlvEmKpHdLgii6OAHCAfO3TUGGPaeN88S2JiolmzZk3dL9SzJ5x2Grz1Vt2vVVO2fw5L7oVDO+DE8TB+jv1xb3jb9hUc2WtrZKMf9Lx/IPcwHNwMBze5XrfYAmHqR3b/a+dZAYnti4ntS2ZkL3b492JtQVd+Scnk6jO60b9jFB9vOMDN/1kHQMeo4OKCfurQbnSICsEYU3+FZD1jjOFIbgFpWbal4W5x9O0QSWK3NhzMzOOWt34kzSUgR3ILAHhwfD+mDevO9oOZnP3UCgIcQpuwEqG4YURPhvVqS2pGJt/+vJV2/plEREQR0elE2oY6CF7xaNnaenYaDLoCRt0HOYfgye5lDQ2MgDMfgNNvsvs/f6hUbd1Vc47tZ38TDUFdfnc1xemE/KySgnzbZ1YkSn92rbvCuX+x++fEl2+x9B4Lly2w79+YAEjZFkenwdDdlRT5yD4rMAHB3nmeJoSIrDXGJFZ7nAdCUGHbzRjTYP0F9SYE4eFw/fXw1FN1v5anFOTC4utg84fQpgeM/Rv0Oturt8zIyWfrb5n0+PVdYo78TO6+JJwpmwgjjy+KEphWcC9twwP5IO4/dOrQkexWvdnj35VOvRKIjGzlVdt8TUGRk8PZ+YQc3UlEQTpH0w+Q9Mt2THYq+4jh04BzSMvO582ie4nI+dW6RFwsKhrB3QV/BAzbI27APySKHP9W7MwN4VhQNHtjRpLW9Tzahvlzlv8GItp0ID84Gr+wtvgH64gpjynMt62I4hZHmi3wTxht98+/DDIPuPYdtK2RxGth/FNQVAiPtAWMFV+3UAy6Ak6+2l57zStlRSS0rRUORyPpO6xH6iwEItLLGLNNRAZWtN8Ys6GONnpMvQhBdrYVgscfh/vuqx/DqsIYWzs3Bt6+CjqcBGfcCv5B9XYLp9Pg5yfkFRTxt0+38ktKJlt/y+Rg5jEAbj3rBO46tw9H8wp47OPNDI7K5IQ2/nTunUDbEAe8PNq2JIqOua4oMGw6nD3T1uI2Lrb9D9G9wD+w3uyuV4yxtc3sVCu6bpfGutchZVPZWmeb7jDF1Rp8bgik/VLqQgJ9x8PkN+3qEhs0XxjSlqOOKI5IFCkBcexxdCUt+xjnD+hA5+gwVvySymP/20J61jEOZedT6IqZ+OjWYcR3imL+93u4f/HPtA4NsP0bYYFEhwfy0Pn9aRcZzNbfMtmZmkV0eBCtQ/wwWekUFeQ30IfXTDAuN6L42d9DQbb9/Zoiu89ZZF2kgeHgLCzpFC9NSCvrXnUW2hab+Nn+C/EDcdj/rSPAXh9jtzcigoODiYuLIyCgrPvVUyGoSgJnANcCz1ewzwBNa3Kahowh2P45fPaQLXRad4NJr1fakVvkNLyycicvLN/BTaN6cu2wHjj8yh+7af9RtqYcZetvWcUF/tATonly4kkE+fvxwfr9dGwVzIjeMfRpF0Hv9hH072ib4pHBATx2SQV6fsNXtgZ1OLnEvdRpsN2XkQzvXmvf+/lD9AlWFIZcB92G2j8XVNzZVx9uh+w0e77bB52TZvtYRtxt9//vPtjycVn/dOvucPt6+/7nRbD/x5JaX5vu0C6+5Prn/Y0S90JM+Y5LVz+LP9DGtXQHSudaARjRO4YRvWMAK8xH86ybKq51CADxHaOYfnav4v6NtCzbWnN/x0t+PsAzy7YB8KcR0Qzu2ZGAiGj6dYjE3+HHoex8so4V4u8n+DsEfz8//P2ECFefRm3ddsYY0rKOcTDzGLERQbQND2q07r96xRhw9rUFvrPA9VoIAWFWLAry4Mge+79wFpb04bSKs7+RY1l2xBRi/xd+/rYlEdEBAsPsbzQ/q2Sfn7/tzK/FRFgm5xDOI/vxMwU4JQC/qI5IaHmPvDGG9PR09u7dS/fu3Su4UvV44hoKMMYUVLfNm9RLi2D1ajjjDFiyBMZWFh9XRzJ+hU/vd7mBesIl/4ZOlXfaHR98FRLgoFOrYC4/tSsZuQX4+wm3ju4FwFl/X87O1GwCHELPmHB6tYtgRK+2/D7RjgSpdz9+UYGtMR/cXGrZBOc+An3Ph+RvrK82pnep4a39bJP9kxnlOyLPfRS6nmFHtPg5IHkl7PyqbI099xDc9J390/z3VlurL01QFMzYbUV11XOQshHCoksK84gO0NOVA7GosEk09Y/kFLAvI5dD2fmE5PxG5+4n4DSGdpHBiAgHj+ZxKCefwiKD0/Vf9ROhf8dIRIRfD+VwJLegjEgE+vvRsZUVouxjhTiNsfscgsNPKCh0sudQDscKnTiNwU+EIH8/urQJJUiH6JbF3aJwtxAK8+1IL7eQuAUjKs4KQc4hyNhd/jpte9v9eUftb93hX1YsgqPs9Z1OEKEg+xCOo7/iVyrxsxOhKLIzAeHlp9k1xrBlyxb69u1bZnt9tAjcfAcM9mBb48bbLYKvn4KvXKN1Rj8Ip99SrRto4j9XcTgnH3cGhtyCIranZvPwR5vwE0js1qZYCJ68ZCBRIQF0axtWPFqnNPVem3MEVD16JCwGTrkOUrfYQn3DQtf22IqDlT6+076/6xeIaGfP+Xp2yaiRsLbQfoB1U/mF2NEzvcaU9eWWDm4645Zq7G/8IgAQFRpAVKhtzm/enEpsZNkOztjI4OJtRU5DkdPpGr5rP4eIYH8cfkKR01BQ5KSgyFkmpUfK0TyyjhWWuabY8R7FRYzTGHILivglJYvQIAchAY5iIfn1UA75RWVTioUFOmgfZffvTs8udoe5CQ/yp53L5l1p2cUC5iYyOICYCPvf2JGaVe4zaRVi3WhOp2FXena5/a1DA2kTFkhhkZPdh3LK7Y8OC6RVaCD5hU5+PVx+f0x4EJEhAeQVFLEvI7fc/tiIICKCA8jNL2T/kbxy+9tHtiEsyJ/sY4X8dtS1/4gBshAC6Ni6D8EOQ+6xY2Tl5OJnisjMKKRIsgh3ZhPDMfwKcjDOQsT1Lez2706h+NOq6BDRznT8KUno5sYPQ+HR/VCBENT1/1/pv0VEYoEOQIiIDChlVyRQ/ZjExoa3heDIXjvGe8xfS8ZrV0OPmDB+SC7vDx4YF8XbN5xeJoAqsVuDDdLyjJjeMObRkvXcDDtC6dUxlZ8z8VUICrfvh91hA6AqG0fe6WToVPGulorDT3Ac93m1Cg2kVRX/xrjWIRQUGQqLnBQ6DYVOw+GcfPILy3sCKvJeVOQvqHvmqKqv4On1Zz38MAV+gfzh5tvrbFF9YRCMIxAC/Sl0BnLUr2zfWpZfBFGtYgkOcJCZm096Zi4OiijEfq95EkJRWDv8slMqvH4AhRVurytVVZvGYVNLxGH7CdxCkAn8n1es8SZuIYitp+F5h3fDpw/AGbdBl1Nh7JM1qoVu+e0oyWk5BDiEgqKSn35YoINrhnZrelG0Ia3s5xAVV0mwUmeIv6RkvR47zZXKCfR3EOh//DY/9h3OLVNT9xOhY6sQWoeWLbi6tCmvMkVFJQMGu0ZXPRqquvxSPWPCK93n5yfV7o8OD6r0mEB/vyrPDw5wVLk/JNC/yv1hQVXvjwgOqDKNSmRIIJEhxw/CsNcryjmEowLvu1MC8EbJUGkPhjHmNWPMcOBaY8wIY8xw13KeMeYdL9jiXVJSoE0bCKhjfpuCPPjqb/D8qbDjCxvgBTUSgcXr9nLR899gMOXcPA4/YXTfRhD9XFtGP2j7BEpTOlhJ8Tk2eK7sNhG7PTk5mRNPPJGrr76agQMHMnHiRHJycujWrRuzZs1i2LBhvPPOO6xfv57TTjuNgQMHMmHCBA4fPgzAqFGjmD59OmeccQbx8fF8//33ABw6dIiLLrqIgQMHctppp7Fhgx10+NVXX5GQkEBCQgKDBg0iMzMTgL/97W8MGTKEgQMH8tBDDxXb+eijj9KnTx/OPvtstm7d2gCflo+I7IDzOOeQE7GR517Ak9IrVkQijTFHReRf2L6B+40xy7xikbeoj6ji7ctgyd228O93oe0A9dANBDYKdtZHm/jPd3s4tXsbnr1sELERzSzoxT06qKGClZor06fD+vX1e82EBHj6aRx+fvTvGFXpYVu3buWVV15h6NChTJs2jRdeeAGwQxRXrlwJwMCBA3n22WcZOXIkDz74IA8//DBPP20jg7Ozs1m1ahUrVqxg2rRpJCUl8dBDDzFo0CDef/99vvjiC6666irWr1/P7Nmzef755xk6dChZWVkEBwezdOlStm3bxvfff48xhgsuuIAVK1YQFhbGggUL+PHHHyksLGTw4MGcfHIVEdRNGEdYtFXnzANQlA+OQPwiOtiRS17AEyG43hjznIici3UT3Qi8BDStb6A+hCAlyY4pvvI9myqghuxMzWbR2r38cWRP7j63d+PPhVNbBk7Sgr8J07lzZ4YOtQkBr7jiCv7xD5uAbvLkyQAcOXKEjIwMRo4cCcDVV1/N73//++LzL730UgBGjBjB0aNHycjIYOXKlbz77rsAnHXWWaSnp3PkyBGGDh3KnXfeyeWXX87FF19MXFwcS5cuZenSpQwaNAiArKwstm3bRmZmJhMmTCA01LqrLrjgggb4NHxIaBuvFfzH44kQuB2JY4HXjDFrRTyLphCRZGyfQhFQaIxJFJE2wEJsWutkYJIx5nAN7a45KSkwuIYDnQrybBbGtr2h/0Vw2k1w6o01Dq7alpJJr3YR9OsYyZd3j6JTq5DqT1JaNq7atS84fgSKez0szLPo6IrOr2iYuogwY8YMxo0bx5IlSzjttNP4/PPPMcZw//33c8MNN5Q5/umnn24ZsQ4+wJMC/ScRWQKcj01AF07NBg6caYxJKDWWdQawzBjTC1jmWvc+NW0R/LIUXjgNvnwUdn9jtzkCaiQCRU7D35du5dynV/D5JttZrSKgNHb27NnD6tWrAZg/fz7Dhg0rsz8qKorWrVvz9ddfA/DGG28Utw4AFi60Q4lXrlxJVFQUUVFRjBgxgrdcOb6WL19O27ZtiYyMZMeOHQwYMID77ruPxMREtmzZwpgxY3j11VfJyrJDS/ft28fBgwcZMWIE7733Hrm5uWRmZvLhhx96/bNoKXjSIrgG6wbabozJcU1Uc20d7nkhMMr1fh6wHPBuzoe8PDh6tHIhKB0JG9EewtrBb+ttaoUr3y8JUqoB6VnHuH3BelZuT+P3J8cxrFcjmQxHUaqhb9++zJs3jxtuuIFevXpx44038uyzz5Y5Zt68efzxj38kJyeHHj168NprrxXva926NWeccQZHjx7l1VdfBWDmzJlcc801DBw4kNDQUObNmwfYWv6XX36Jw+GgX79+jB07lqCgIDZv3szpp58OQHh4OG+++SaDBw9m8uTJJCQk0LVrV4YPH95An0jzp9rIYgARmQL0NMY8KiKdgVhjzFoPztsFHMa2IF40xrwkIhnGmFaljjlsjGld1XXqHFm8ezd06wYvvwzXHqdhx0/b56b/xTDhxVrl2Fm35zA3v7WO9Ox8HrmwP5OHdKm97UqLYfPmzeUiQxua5ORkxo8fT1JSUq3OHzVqFLNnzyYxsdpgVqWeqej3U2+RxSLyHBCAzS30KJAN/AsY4oFtQ40x+13BaZ+JyBYPznHf93rgeoAuXepYkFYVTFbRdJFg86jXMtFaclo2AQ4/Ft94BvGdKh+doSiK0hjwxDV0hjFmsIj8CGCMOSQiHpWQxpj9rteDIvIecAqQIiIdjDEHRKQDcLCSc1/Cjk4iMTGxbsGMVQlBZdNFVra9ErKOFbJhbwZn9GzLxYPjOG9Ah6YXFKa0eLp161br1gBY/7/S9PCks7jANUrIAIhINOCs+hQQkTARiXC/B84FkoD/Ale7DrsaOyeyd6lKCCqbZ7UG869uS8nkwudW8od5aziUbVNGqAgoitJUqFQIRMTdWngeeBeIEZGHsZPYP+HBtdsBK0XkJ+B74GNjzCfA48A5IrINOMe17l2qSi8x+sHyucVrEAn7wfp9XPj8NxzJLeDlqxNpE9ZI8/YriqJUQlWuoe+BwcaY10VkLXA2Nt/Q740x1bYdjTE7gZMq2J4OjK6lvbUjJQWioiC4gije/hPg/ZsgIBTysz2OhDXGMPO/G5m3ejeJXVvz/OWDizMuKoqiNCWqEoLiyA1jzEag/AzhTYWqYggObLB5xS/8txUFDxERggMc/GFYd+4be2KFqaEVRVGaAlWVXjEicmdlS4NZWB9UJQSxfeGKxdB9ZMX7j2PFL6ms3W0DoWeMPZE/j++nIqA0GxwOR3ESuISEBB5/3HpuR40aRWVDuG+//XY6deqE01lt1yEZGRnFuYsaE1OnTmXRokVevUdNPtvly5cjIrzyyivF23788UdEhNmzZ9e7bVW1CBzYnKhNP6Y7JQXi4yveFxhaMil2FTidhme/2M7Ty35hRK8Y5k07RcPdlWZHSEgI62uQ7M7pdPLee+/RuXNnVqxYwahRo6o83i0EN910Ux0t9S2FhYX4+1dcfE6dOpWpU6eW+yxq+tkOGDCAhQsXcq0r9mnBggWcdFI5b3u9UFVV9oAxZpYx5uGKFq9Y4y0qaxE4nbBitp2GsQoOZ+dzzdwfmPP5L0xI6MQ/r2hak7Mpirf48ssviY+P58Ybb2T+/PnF22fOnFmm5hofH09ycjIzZsxgx44dJCQkcM8992CM4Z577iE+Pr644HNTUSrq5ORk+vbty3XXXUf//v0599xzyc21cUDbt2/n7LPP5qSTTmLw4MHs2LGj0usbY7jlllvo168f48aN4+DBklHsa9euZeTIkZx88smMGTOGAwcOALbm/sADDzBy5EieeeYZ732oLrp06UJeXh4pKSkYY/jkk08Y66Vpdj3qI2jS5OfD4cMVC0HaL/DFIxDezrqIKmB/Ri6//9dqUjOP8eiEeC47pYu2BJQGoaLK9aRJcNNNkJMD551Xfv/UqXZJS4OJE8vu82SIf25uLgkJCcXr999/f3HW0YqYP38+l156KRdeeCEPPPAABQUFBFQx58fjjz9OUlJScc343XffZf369fz000+kpaUxZMgQRowYwc8//1xhKuouXbqwbds25s+fz7///W8mTZrEu+++yxVXXMHll1/OjBkzmDBhAnl5eTidThYvXlzh9VevXs3WrVv5+eefSUlJoV+/fkybNo2CggJuvfVWPvjgA2JiYli4cCF/+tOfilNlZGRk8NVXX1X/QdbDZwswceJE3nnnHQYNGsTgwYMJCvLOhE5VCUHDjuzxFm6lr0gI9qyyr13PqPT09pHBDO/VlstO7cLAuFaVHqcozYGauC/y8/NZsmQJc+bMISIiglNPPZWlS5cybtw4j++3cuVKLr30UhwOB+3atWPkyJH88MMPrFixosJU1F26dKF79+7FBerJJ59McnIymZmZ7Nu3jwkT7ICPYNcIwaqu797esWNHzjrLppXfunUrSUlJnHPOOYCdja1Dh5LJYCoruD/99FPuu8+mTNuzZw8rV64kPDycoKAgvvvuuxp/tm4mTZrE5MmT2bJlC5deeimrVq2q0fmeUqkQGGMOeeWODU1VwWS7V9vJ1tv0KLM5J7+Qx/+3hZtGnUD7qGAev2RgAxiqKGWpqgYfGlr1/rZtPWsB1IVPPvmEI0eOMGDAAABycnIIDQ1l3Lhx+Pv7l+k8zssrPwk8UGF6avf2ilJRJycnl6kVOxwOcnNzq7xOZVTUsjfG0L9//+Lsq8dTWSruMWPGMGaMna+7sj6C2tC+fXsCAgL47LPPeOaZZ7wmBM1/uEtVQrBnNXQ9nSIDL63YQcKspTy2ZDMXPreSN77dzaodaQ1rq6I0IebPn8/LL79McnIyycnJ7Nq1i6VLlxZPbblu3ToA1q1bx65duwCIiIgono4S7OQ1CxcupKioiNTUVFasWMEpp5xSaSrqyoiMjCQuLo73338fgGPHjpGTk1Pp9UeMGMGCBQsoKiriwIEDfPnllwD06dOH1NTUYiEoKChg40bfjpyfNWsWTzzxBA6H97IVeD7RblOlMiHIToOcdNKjT+bKZ1eyKy2b3IIiXlyxE4fA3y45iYsHe55mQlGaA8f7sX/3u98VD3McN25csf//9NNPZ9myZbz44ovFx4aFhTFs2DA+/PBDLrnkEl5//XUSEhIYMmQIvXv3BiA6OpqhQ4cSHx/P2LFjefLJJ1m9ejUnnXQSIsKTTz5J+/btad++fYWpqKsqDN944w1uuOEGHnzwQQICAnjnnXeYMGFChdefMGECX3zxBQMGDKB3797F8ykEBgayaNEibrvtNo4cOUJhYSHTp0+nf//+DfrZ3nzzzcXHnXFG5a7r+sKjNNS+pk5pqB9/HO6/H7KzbXu6NEUFDH30Uw7kCs5SH4OfQOvQQNb+3zm1N1pRakhjSEOtNF3qkoa6ZbiGwsPLiwCAI4DO7aPLiACA00DvdhENY5+iKIqPaRlCUFH/wDtTYe1c+raPIDSwbHMzLNDBpCHqFlIUpWXQMvoIjheCnEOw8T02FnXhtfUxBPqX1UOHnzC6bw3mN1YURWnCtAwhcHVUFbPHjgh45OdWnN4jmrnThhDkr/MHKIrSMmmRrqHUjV+Sb/zJiTmJF686WUVAUZQWTfNuERQWQnp6GSFwOg3pm75iv18vXp42lMjgysPhFUVRWgLNu0WQmgrGlBECP4G4Hv2IO+0SYnUiGUUpg4hw5ZVXFq8XFhYSExPD+PHjAZg7dy633HJLufO6devGJZdcUry+aNEipk6dWnyOn58fGzZsKN7vTkJ3PDk5OVx++eUMGDCA+Ph4hg0bVhxUJiLcddddxcfOnj2bmTNnevRcycnJhISElEkD/frrrxfbnpZWNnh07ty5iAjLli0r3vbee+8hIl5PV+0LmrcQlAomyzpWyLxVyRgg/PJ5RI+5x6emKUpdKXKa4oj4l1bsoOj4cdC1ICwsjKSkpOKMnp999hmdOnXy6Nw1a9ZUGoUbFxfHo48+Wu01nnnmGdq1a8fPP/9MUlISr7zySnGgVVBQEIsXLy5XaB/PqFGjKhSZnj17sn79+uLlqquuqvI6AwYMKJNR1ZtpoH1NixCC/JhYbnxzLbM+2sTmXysPU1eUpsKutGzOf3Ylcz7bRkZOAXM+28YFz9kI+boyduxYPv74Y6Aku6gn3H333fz1r3+tcN/48ePZuHEjW7durfIaBw4cKCM8ffr0Kc4t5O/vz/XXX8+cOXM8sqeuDB8+nO+//56CggKysrLYvn17mcjg5kSzFYIip+GljUdIuPU/TPg2l6+3pfH4xQPo9+Uf4D9TfG2eolTL5BdXl1veWJ0MwCUvrGLTgaPkFhQBkFtQxMb9Rxn/7NcAHMrOL3eup0yZMoUFCxaQl5fHhg0bOPXUUz06b9KkSaxbt47t27eX2+fn58e9995bqVC4mTZtGk888QSnn346f/7zn9m2bVuZ/TfffDNvvfUWR44c8fh53LjnQXAvX3/9dZXHiwhnn302n376KR988AEXXHBBje/ZVGiWQlBcWzoYQkZoJBvT84mNCCKxcwTsXQOtu/raREWpEyfEVpwFs3099HsNHDiQ5ORk5s+fz3kVTXpQCQ6Hg3vuuYfHHnuswv2XXXYZ3377bXECuopISEhg586d3HPPPRw6dIghQ4aweXPJxFGRkZFcddVV/OMf/yhz3muvvVZcwK9Zs4bzzjuPhISE4rTUUN41NHz48GqfyS2KCxYs8Lhl1BRplqOGJv5zFYdz8nGW0rm0rGPMfPEt5jlzoMvpPrROUTxj4Q2V/04vPbULG/cfJTu/qHhbWKCDW846AYA2YYFVnl8dF1xwAXfffTfLly8nPT3d4/OuvPJKHnvssQqTtPn7+3PXXXfxxBNPFG977733ePhhO+Hhyy+/TGJiIuHh4Vx88cVcfPHF+Pn5sWTJkjI5dKZPn87gwYO55pprirddc801xeujRo1i7ty5dOvWraaPXY5TTjmFpKQkQkJCihPnNUeaZYugV7vwCvMHnRO+066oEChNnNF92+HwK5tPvz4j4qdNm8aDDz5YPNeApwQEBHDHHXfw9NNPV7h/6tSpfP7556SmpgIwYcKE4hp6YmIi33zzDYcPHwbsxDebNm2ia9eyLfg2bdowadKkMhO7e5PHHnusWpdWU6dZtggmD+nMz3uPlKstjQ7dAf49IELTRyhNm8jgADbMHOO168fFxXH77bdXuG/u3LnFef8Bvv322zL7r732Wv7yl79UeG5gYCC33XZbpdfesWMHN954I8YYnE4n48aNKzMs1c1dd93Fc8895+njFF+7dGfvtGnTuO222wDrDvPzs/XiSZMmMXBgyWRU3ponuDHRLNNQH80rYNjjX3A0r7B4W2SwP99elEWoyYNBl3vDTEWpE5qGWqkLdUlD3SxbBN6uLSmKojQnmmUfQYUc3Awpm2yksaIoilJMyxGCr/8Ob0yo/jhFUZQWRssQAmNg9yroejqIVH+8oihKC6JlCEHGHji6D7p4fxJoRVGUpkbLEALXRDR01fgBRVGU42kZQrB7FQRFQWw/X1uiKI2a2qahLs3y5cuJivGSN7kAAAxFSURBVIoqk9fn888/ByA8PLzc8TNnzkREyuQomjNnDiKCp8PGZ86cSadOncrcMyMjg+XLlxfbXppRo0bRpUsXSg+fv+iiiyq0ryXQMoTgnIfhysXgpzORKc2IDW/DnHiY2cq+bni7zpesSxrq0gwfPrxMXp+zzz67yuMHDBjAggULitcXLVpEv37lK27JycmMGjWqwmvccccdZe7ZqlWrKu/ZqlUrvvnmGwAyMjI4cOBANU/VfGkZQhDSGuKqjalQlKbDhrfhw9vgyK+Asa8f3lYvYlDbNNR14aKLLuKDDz4AYOfOnURFRRETE+PVe7oTygEsXryYiy++2Kv3a8w0fyHY8x2smA3HMn1tiaLUjNfGlV++/7fd9/nDUJBb9viCXPjfffZ9dnr5cz2ktmmoS/P111+XcdPs2LGjyuMjIyPp3LkzSUlJzJ8/n8mTJ9f4nnPmzCm+35lnnlnt8aNHj2bFihUUFRWxYMGCWt2zudAsI4vLsOkD+OFlOONWX1uiKPXH0X0Vb889VOdL1zYNdWmGDx/ORx99VKNz3AL06aefsmzZMl577bXifRMmTGDXrl3k5+ezZ8+e4pxBt99+e3HW0TvuuIO7777b4/s5HA6GDRvGwoULyc3NrZdspU0VrwuBiDiANcA+Y8x4EZkLjATcM0tMNcas95oBe1ZZt5B/kNduoShe4ZqPK98XFedyCx2/vbN9DYuu+vxqqEka6uNTSdeW888/n3vuuYfExEQiIyPL3QNsH8HUqVNZvnx5re9TmilTpjBhwgSP5z5urjREi+B2YDNQ+pu9xxjj3RmgN7wNn8+0NaegSLs+cJJXb6koDcboB22fQGn3UECI3V4PTJs2jaioKAYMGFBtoTthwoQyE8DUtpAOCQnhiSeeaNC8/8OHD+f+++9v1pPOeIJXhUBE4oBxwKPAnd68VxncHWnuP8mxo3YdVAyU5oH7d7xsFhzZa1sIox+st993TdNQx8XFlTnG3Ufg5s9//jMTJ04kJyenzLF33lm2WJgypfbTyM6ZM4c333yzeN1t47Jly8rc85133il+LyI1cic1V7yahlpEFgGPARHA3aVcQ6cDx4BlwAxjzLGqrlPTNNTMia+82XxHkufXUZQGRNNQK3WhLmmovTZqSETGAweNMWuP23U/cCIwBGgD3FfJ+deLyBoRWeOezchjjuyt2XZFUZQWjDeHjw4FLhCRZGABcJaIvGmMOWAsx4DXgFMqOtkY85IxJtEYk1jj8cRRcTXbriiK0oLxmhAYY+43xsQZY7oBU4AvjDFXiEgHABER4CKg/n01ox+0HWelqceONEVRlOaEL+II3hKRGECA9cAf6/0OXu5IUxRvYYxBNFW6UkPq2tfbIEJgjFkOLHe9P6sh7snASVrwK02K4OBg0tPTiY6OVjFQPMYYQ3p6OsHBwbW+RvOPLFaUJkJcXBx79+6lxoMjlBZPcHBwuSG8NUGFQFEaCQEBAXTv3t3XZigtkOafdE5RFEWpEhUCRVGUFo4KgaIoSgvHqykm6gsRSQV2H7e5LZDmA3O8RXN7Hmh+z9Tcngea3zM1t+eBuj1TV2NMtRG5TUIIKkJE1niSQ6Op0NyeB5rfMzW354Hm90zN7XmgYZ5JXUOKoigtHBUCRVGUFk5TFoKXfG1APdPcngea3zM1t+eB5vdMze15oAGeqcn2ESiKoij1Q1NuESiKoij1QJMTAhH5nYhsFZHtIjLD1/bUByKSLCI/i8h6EanBVGyNAxF5VUQOikhSqW1tROQzEdnmem3tSxtrSiXPNFNE9rm+p/Uicp4vbawJItJZRL4Ukc0islFEbndtb5LfUxXP05S/o2AR+V5EfnI908Ou7d1F5DvXd7RQRALr/d5NyTUkIg7gF+AcYC/wA3CpMWaTTw2rI67JexKNMU1y/LOIjACygNeNMfGubU8Ch4wxj7sEu7UxpsLZ6BojlTzTTCDLGDPbl7bVBtc8IB2MMetEJAJYi50PZCpN8Huq4nkm0XS/IwHCjDFZIhIArARux873vtgYs0BE/gX8ZIz5Z33eu6m1CE4Bthtjdhpj8rEzn13oY5taPMaYFcCh4zZfCMxzvZ+H/ZM2GSp5piaLa2bAda73mcBmoBNN9Huq4nmaLK6ZG7NcqwGuxQBnAYtc273yHTU1IegElJ6Vfi9N/Mt3YYClIrJWRK73tTH1RDtjzAGwf1og1sf21Be3iMgGl+uoSbhRjkdEugGDgO9oBt/Tcc8DTfg7EhGHiKwHDgKfATuADGNMoesQr5R5TU0IKpqto+n4tipnqDFmMDAWuNnlllAaH/8EegIJwAHg7741p+aISDjwLjDdGHPU1/bUlQqep0l/R8aYImNMAhCH9YD0reiw+r5vUxOCvUDnUutxwH4f2VJvGGP+v71zC9GqiuL47++YadPFBrWESDOEejGtyBCtgcLooUxSKpKUDLIrKb4URZLUU1kghGHF9KCW4qUZgrJMSZBQQrOJCIIZogJ7qUF9CHJWD2t9erRP5+LIzJmzfnA4+1z2Pnt/+/v22pfv/Ncfsf8T2I5/AcrOkYJ/6ol4D6fUmNmR+KF2A+spWT3FvPNWYIOZbYvTpa2neuUpex3VMLO/ca+OtwNjJdV8x1yQNq9shuAAMDVW0UcBDwOtg5yn80JSYyx2IakRmAu0nztWKWgFFkd4MfDpIOZlQKg1mMF8SlRPsRD5AfCTma0pXCplPZ2tPCWvo/GSxkZ4DHA3vvaxG1gQt12QOirVv4YA4u9g7wANwIdm9vogZ+m8kDQFHwWAe4zbWLYySdoENOMqiUeAV4EdwGbgWuBXYKGZlWbx9SxlasanHAzoBJ6sza8PdSTNBvYCPwDdcfolfF69dPV0jvI8QnnraBq+GNyAd9I3m9lr0UZ8DDQBB4FFZvbPgD67bIYgSZIkGVjKNjWUJEmSDDBpCJIkSSpOGoIkSZKKk4YgSZKk4qQhSJIkqThpCJJhi6Q9ki64/1pJz4cK5oY61zaF3MHyfqTbLGnWwOQySc7OyJ5vSZLqIWlkQd+lJ54G7jWzjjPSuBqYZWaT+pmNZlwBdV9vI0hqMLMT/XxeUlFyRJAMKpImR296fWiw74y3Kk/r0UsaF3LdSFoiaYekNkkdkp6VtELSQUnfSmoqPGKRpH2S2iXdFvEbQ5DsQMSZV0h3i6Q2YGedvK6IdNolvRDn1gFTgNY6vf6dwITQxZ8j6XpJn4e44F5JN0Qa94Xe/EFJX0m6KoTUlgHLC/FbJC0o5OdY7Jvl2vwb8ReskLRIrm1/SNJ7IWbWEGm0y/1f9HmUkgxTzCy33AZtAyYD/wLT43gz/uYkuNbKrREeB3RGeAnwC3AZMB7oApbFtbdxAbJa/PURvgNoj/AbhWeMxX1cNEa6vwFNdfJ5C97INgKXAj8CM+JaJzDuLGVrLxzvAqZGeCbwdYSv5NTLnU8Ab0V4FbCyEL8FWFA4Phb7ZuA4cF0c3wi0ARfF8bvAY1GGLwvxxw52/ec2NLacGkqGAh1mdijC3+ENaE/sNtehPyqpC2/4wBvraYX7NoH7F5B0eWi5zAXul7Qy7hmNSyyAN5T1JBZmA9vN7DiApG3AHPyV/x4JlcxZwBaXyQHg4thfA3wSOjmjgI7/p9Aj++3U1NRdeKN/IJ41BheTawOmSFoLfEadUU9STdIQJEOBom7KCbzhAh8p1KYvR58jTnfhuJvTv9dnaqgYLmf+oJn9XLwgaSbes65HPQn0vjAC15WfXufaWmCNmbVKasZHAvU4+XmE6FrRZWEx3wI+MrMXz0xA0k3APcAzuDevx/tWjGQ4kmsEyVCmE+/Zwin1xb7yEJwUKesysy7gC+C5aEyRNKMX6XwDPCDpklCJnY+LnvUKc638DkkL45mKRhngCuD3CC8uRDuKT3/V6OTU5zEP92BVj13AAkkT4llNkiZJGgeMMLOtwCvAzb3NfzK8SUOQDGXeBJ6StA9fI+gPf0X8dcDSOLcab0QPy53Tr+4pEXO3iC3Aflyx830z69W0UIFHgaWSvsfXGGpuVlfhU0Z7gaLf6jZgfm2xGNfXv1PSfnyNoe7oxdyH98u417vDuKeribhnqz1yD1gtwP9GDEk1SfXRJEmSipMjgiRJkoqThiBJkqTipCFIkiSpOGkIkiRJKk4agiRJkoqThiBJkqTipCFIkiSpOGkIkiRJKs5/4kvZYAq9OaUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc70c1257b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "x = [1,2,5,10,20,30]\n",
    "y1 = [47,60,62,64,63,62]\n",
    "y2 = [60,61,67,64,62,61]\n",
    "y3 = [47,48.3,51,52,51,51]\n",
    "y4 = [45,49.9,52,51,52,51]\n",
    "\n",
    "plt.plot(x,y1,'-r')\n",
    "plt.plot(x,y2,'--b')\n",
    "plt.plot(x,y3,'--p')\n",
    "plt.plot(x,y4,'--o')\n",
    "plt.ylabel('Testing Accuracy of Duke')\n",
    "plt.xlabel('number of features')\n",
    "plt.legend(['proposed', 'ELAutoencoder +ELM','MLNN-SN+ELM','ML-ELM+ELM'], loc='lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.math.sin(tf.constant([0.9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
