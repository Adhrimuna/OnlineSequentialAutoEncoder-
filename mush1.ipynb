{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tqdm import tqdm_notebook as tqdm # Jupyter notebook should use this\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import scipy.io as scipy_io\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"; \n",
    "train_dataset = np.array(pd.read_csv(\"UCI dataset/mushroom\", header = None,delimiter=' '))\n",
    "train_dataset.shape\n",
    "\n",
    "label = train_dataset[:,0]\n",
    "data = train_dataset[:,1:22]\n",
    "label = label.reshape(label.shape[0], 1)\n",
    "print(label)\n",
    "\n",
    "tr_file = 'UCI dataset/mushroom'\n",
    "INPUT_DIMENSION = 112\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "def process_data(fname, NUM_ATTR, NUM_CLASSES):\n",
    "    I = np.eye(NUM_CLASSES)\n",
    "    with open(fname) as file:\n",
    "        xx = file.readlines()\n",
    "        #print(xx)\n",
    "        data = np.zeros([len(xx), NUM_ATTR])\n",
    "        label = np.zeros(len(xx), dtype=int)\n",
    "        label_onehot = []\n",
    "        for i in range(len(xx)):\n",
    "            tmp = xx[i].split(' ')\n",
    "            label[i] = int(tmp[0])-1\n",
    "            label_onehot.append(I[label[i]])\n",
    "            for j in range(1,len(tmp)-1):\n",
    "                position = int(tmp[j].split(':')[0])\n",
    "                value = 1.0*int(tmp[j].split(':')[1])\n",
    "                data[i][position-1] = value \n",
    "    return data, label, np.array(label_onehot, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tr_label, tr_onehot = process_data(tr_file, NUM_ATTR=112, NUM_CLASSES=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   ... 0.   0.01 0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.01 0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.01 ... 0.   0.   0.  ]\n",
      " [0.   0.   0.01 ... 0.   0.   0.  ]]\n",
      "(4124, 112)\n",
      "(4000, 2)\n",
      "(4124, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = tr_label[:4000]\n",
    "y_test = tr_label[4000:]\n",
    "\n",
    "tr_data = tr_data*0.01\n",
    "x_train = tr_data[:4000]\n",
    "x_test = tr_data[4000:]\n",
    "y_train_onehot = tr_onehot[:4000]\n",
    "y_test_onehot = tr_onehot[4000:]\n",
    "print(x_train)\n",
    "print(x_test.shape)\n",
    "print(y_train_onehot.shape)\n",
    "print(y_test_onehot.shape)\n",
    "INPUT_DIMENSION = 112\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.savetxt(\"x_train.csv\", x_train, delimiter=\",\")\n",
    "np.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
    "np.savetxt(\"x_test.csv\", x_test, delimiter=\",\")\n",
    "np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "border = 400\n",
    "x_train_init = x_train[:border]\n",
    "y_train_init = y_train[:border]\n",
    "x_train_seq = x_train[border:]\n",
    "y_train_seq = y_train[border:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(0.55)\n",
    "time_sum = 0\n",
    "t1 = time.time()\n",
    "pca.fit(x_train)\n",
    "t2 = time.time()\n",
    "time_sum+= t2-t1\n",
    "train_img = pca.transform(x_train)\n",
    "test_img  = pca.transform(x_test)\n",
    "x_train.shape,train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 112), (4000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "border = 146\n",
    "x_train_init = train_img[:border]\n",
    "y_train_init = y_train[:border]\n",
    "x_train_seq = train_img[border:]\n",
    "y_train_seq = y_train[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # clear all the tensors\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "\"\"\"Placeholders\"\"\"\n",
    "X_ = tf.placeholder(tf.float32, [None, INPUT_DIMENSION])\n",
    "#X_ = tf.reshape(X, [-1, INPUT_DIMENSION]) # Flatten X: [N,D]\n",
    "Y = tf.placeholder(tf.int64, [None]) # labels\n",
    "Y_ = tf.one_hot(indices=Y, depth=NUM_CLASSES) # one_hot labels: [N,M]\n",
    "\n",
    "\"\"\"Some constants\"\"\"\n",
    "D = INPUT_DIMENSION\n",
    "M = NUM_CLASSES # Number of outputs\n",
    "C = tf.constant(2.0**(-3))\n",
    "\n",
    "\"\"\"Weights\"\"\"\n",
    "alpha_1 = tf.get_variable('alpha_1',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False) # 1st subnetwork\n",
    "alpha_2 = tf.get_variable('alpha_2',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False) # 2st subnetwork\n",
    "alpha_3 = tf.get_variable('alpha_3',shape=[D, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_1 = tf.get_variable('beta_1',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_2 = tf.get_variable('beta_2',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "beta_3 = tf.get_variable('beta_3',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tf.get_variable('k',shape=[D, D],initializer=tf.random_uniform_initializer(-1,1),trainable=False)\n",
    "m = tf.get_variable('m',shape=[M, M],initializer=tf.random_uniform_initializer(-1,1),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions\"\"\"\n",
    "def mul(A, B):\n",
    "    return tf.matmul(A, B)\n",
    "\n",
    "def inv(A):\n",
    "    return tf.matrix_inverse(A)\n",
    "\n",
    "def t(A):\n",
    "    return tf.transpose(A)\n",
    "\n",
    "def sin(A):\n",
    "    return tf.math.sin(A)\n",
    "\n",
    "def asin(A):\n",
    "    return tf.math.asin(A)\n",
    "\n",
    "def sqrt(A):\n",
    "    return tf.sqrt(A)\n",
    "\n",
    "def sqr(A):\n",
    "    return tf.math.pow(A, 2)\n",
    "\n",
    "def pseudo_inv(A, I, C):\n",
    "    C_I = I/C\n",
    "    return mul(t(A), inv(C_I + mul(A, t(A))))\n",
    "\n",
    "def h(A):\n",
    "    '''activation function'''\n",
    "    return sin(A)\n",
    "\n",
    "def h_(A):\n",
    "    '''inverse activation function'''\n",
    "    return asin(A)\n",
    "\n",
    "def u(A):\n",
    "    '''normalize the input to (0,1]'''\n",
    "    return tf.math.sigmoid(A) # sigmoid\n",
    "    \n",
    "def u_(A):\n",
    "    '''the inverse of u'''\n",
    "    ONE = tf.constant(1.0)\n",
    "    return -(tf.math.log(ONE/A - ONE)) # the inverse of sigmoid\n",
    "    \n",
    "def subnet_output(alpha, beta, A):\n",
    "    return t(mul(beta, h(mul(t(alpha), t(A))))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial Training Graph\"\"\"\n",
    "# D: input dimension\n",
    "# N: number of input samples\n",
    "# M: number of classes (number of outputs)\n",
    "'''some pre-computations'''\n",
    "X_init = t(X_) # [D,N]\n",
    "Y_init = t(Y_) # [M,N]\n",
    "N_init = D # number of dimensions\n",
    "I_DxD = tf.eye(N_init, dtype=tf.float32) # [D,D]\n",
    "I_MxM = tf.eye(M, dtype=tf.float32) # [M,M]\n",
    "C_I = I_DxD/C\n",
    "H_I = I_MxM/C\n",
    "\n",
    "add = C_I + mul(X_init, t(X_init))\n",
    "k = tf.assign(k,add)\n",
    "X_inv_init = pseudo_inv(X_init, I_DxD, C) # [N,D]\n",
    "\n",
    "'''1st subnet'''\n",
    "alpha_1_init_calculated = t(mul(h_(Y_init), X_inv_init)) # ([M,N]x[N,D])T=[D,M]\n",
    "alpha_1_init = tf.assign(alpha_1, alpha_1_init_calculated) # [D,M]\n",
    "H_1_init = h(mul(t(alpha_1_init), X_init)) # [M,N]\n",
    "H_add = H_I + mul(H_1_init,t(H_1_init))\n",
    "m = tf.assign(m,H_add)\n",
    "H_pseudo_init = pseudo_inv(H_1_init,I_MxM,C) #[N,M]\n",
    "\n",
    "beta_1_init_calculated = mul(Y_init, t(H_1_init))/sqr(tf.norm(H_1_init)) # [M,M]\n",
    "beta_1_init_calculated = mul(Y_init,H_pseudo_init)\n",
    "\n",
    "beta_1_init = tf.assign(beta_1, beta_1_init_calculated) # [M,M]\n",
    "H_beta_1_init = mul(beta_1_init, t(mul(t(X_init), alpha_1_init))) # [M,N]\n",
    "E_1_init = Y_init - H_beta_1_init # [M,N]\n",
    "\n",
    "'''2nd subnet'''\n",
    "#alpha_2_init_calculated = t(mul(h_(E_1_init), X_inv_init)) # [D,M]    \n",
    "alpha_2_init_calculated = t(mul(asin(Y_init), X_inv_init)) # [D,M]\n",
    "\n",
    "alpha_2_init = tf.assign(alpha_2, alpha_2_init_calculated) # [D,M]\n",
    "H_2_init = h(mul(t(alpha_2_init), X_init)) # [M,N]\n",
    "H_2_inv_init = pseudo_inv(H_2_init, I_MxM, C) # [M,N]\n",
    "H_add = H_I + mul(H_2_init,t(H_2_init))\n",
    "#m = tf.assign(m,H_add)\n",
    "H_pseudo_init = pseudo_inv(H_2_init,I_MxM,C) #[N,M]\n",
    "\n",
    "beta_2_init_calculated = mul(E_1_init, t(H_2_init))/sqr(tf.norm(H_2_init)) # [M,M]\n",
    "beta_2_init_calculated = mul(E_1_init, H_pseudo_init)\n",
    "\n",
    "beta_2_init = tf.assign(beta_2, beta_2_init_calculated) # [M,M]\n",
    "H_beta_2_init = mul(beta_2_init, t(mul(t(X_init), alpha_2_init))) # [M,N]\n",
    "E_2_init = Y_init - (H_beta_1_init+H_beta_2_init) # [M,N]\n",
    "\n",
    "'''3rd subnetwork'''\n",
    "alpha_3_init_calculated = t(mul(h_(E_2_init), X_inv_init)) # [D,M]    \n",
    "alpha_3_init_calculated = t(mul(asin(Y_init), X_inv_init)) # [D,M]\n",
    "\n",
    "alpha_3_init = tf.assign(alpha_3, alpha_3_init_calculated) # [D,M]\n",
    "H_3_init = h(mul(t(alpha_3_init), X_init)) # [M,N]\n",
    "H_3_inv_init = pseudo_inv(H_3_init, I_MxM, C) # [M,N]\n",
    "\n",
    "beta_3_init_calculated = mul(E_2_init, t(H_3_init))/sqr(tf.norm(H_3_init)) # [M,M]\n",
    "beta_3_init_calculated = mul(E_2_init, H_3_inv_init)\n",
    "\n",
    "beta_3_init = tf.assign(beta_3, beta_3_init_calculated) # [M,M]\n",
    "H_beta_3_init = mul(beta_3_init, t(mul(t(X_init), alpha_3_init))) # [M,N]\n",
    "E_3_init = Y_init - (H_beta_3_init+H_beta_2_init+ H_beta_1_init) # [M,N]\n",
    "\n",
    "#init_train_graph = H_beta_1_init\n",
    "init_train_graph = E_3_init\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_3:0' shape=(2, 2) dtype=float32_ref>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''With one subnetwork'''\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) \n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training done\n",
      "Initial train training loss:  0.3311794\n",
      "Initial train training accuracy:  0.82725\n",
      "Initial train testing loss:  0.45841968\n",
      "Initial train testing accuracy:  0.21799225\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "sess.run(E_1_init, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) \n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training done\n",
      "Initial train training loss:  0.2444909\n",
      "Initial train training accuracy:  0.82725\n",
      "Initial train testing loss:  0.44731468\n",
      "Initial train testing accuracy:  0.21799225\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "import time\n",
    "s = 0\n",
    "t1 = time.time()\n",
    "sess.run(E_2_init, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+=t2-t2\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "#logits_init =  subnet_output(alpha_1, beta_1, X_)\n",
    "logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "loss_init = tf.losses.mean_squared_error(labels=Y_, predictions=logits_init)\n",
    "accuracy_init = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_init, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training done\n",
      "Initial train training loss:  0.19943665\n",
      "Initial train training accuracy:  0.82725\n",
      "Initial train testing loss:  0.44852966\n",
      "Initial train testing accuracy:  0.21799225\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initial training\"\"\"\n",
    "sess.run(init_train_graph, feed_dict={X_: x_train_init, Y: y_train_init})\n",
    "print(\"Initial training done\")\n",
    "\n",
    "\"\"\"Initial training evaluation\"\"\"\n",
    "tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_train, Y: y_train})\n",
    "ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X_: x_test, Y: y_test})\n",
    "print(\"Initial train training loss: \", tr_loss)\n",
    "print(\"Initial train training accuracy: \", tr_acc)\n",
    "print(\"Initial train testing loss: \", ts_loss)\n",
    "print(\"Initial train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_init = subnet_output(alpha_1, beta_1, X_)+ subnet_output(alpha_2, beta_2, X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logic = sess.run(logits_init, feed_dict={X_ : [x_test[4]]})\n",
    "print(np.argmax(logic,axis =1))\n",
    "print(y_test[4])\n",
    "#plt.imshow(x_test[4200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sequential Training Graph\"\"\"\n",
    "# D: input dimension\n",
    "# N: number of input samples\n",
    "# M: number of classes (number of outputs)\n",
    "X_seq = t(X_) # [D,N]\n",
    "Y_seq = t(Y_) # [M,N]\n",
    "pseudo = mul(X_seq, X_) #DXD\n",
    "k = tf.assign(k, tf.add(k,pseudo)) #DXD\n",
    "k_inv = inv(k)\n",
    "\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_1))\n",
    "alpha1_seq = tf.assign(alpha_1,tf.add(alpha_1,new)) #DXM\n",
    "H_1_seq = h(mul(t(alpha1_seq), X_seq)) # [M,N]\n",
    "m_su = mul(H_1_seq,t(H_1_seq))\n",
    "m = tf.assign(m,tf.add(m,m_su))\n",
    "m_inv = inv(m)\n",
    "#update = tf.matmul(tf.matmul(m_inv,H_1_seq),h_(Y_seq)- tf.matmul())\n",
    "H_pseudo_init = pseudo_inv(H_1_seq,I_MxM,C) #[N,M]\n",
    "#UPDATE = tf.matmul(tf.matmul(K_inverse, HT), inverse_acti_y - tf.matmul(H, self.__outputWeight))\n",
    "beta_1_seq_calculated = mul(Y_seq, H_pseudo_init) # [M,M]\n",
    "beta_1_seq = tf.assign(beta_1, beta_1_seq_calculated) # [M,M]\n",
    "H_beta_1_seq = mul(beta_1_seq, t(mul(X_, alpha1_seq))) # [M,N]\n",
    "E_1_seq = Y_seq - H_beta_1_seq # [M,N]\n",
    "\n",
    "'''2nd subnetwork'''\n",
    "\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_2))\n",
    "alpha2_seq = tf.assign(alpha_2,tf.add(alpha_2,new)) #DXM\n",
    "H_2_seq = h(mul(t(alpha2_seq), X_seq)) # [M,N]\n",
    "H_pseudo_init = pseudo_inv(H_2_seq,I_MxM,C) #[N,M]\n",
    "beta_2_seq_calculated = mul(E_1_seq, H_pseudo_init) # [M,M]\n",
    "beta_2_seq = tf.assign(beta_2, beta_2_seq_calculated) # [M,M]\n",
    "H_beta_2_seq = mul(beta_2_seq, t(mul(t(X_seq), alpha2_seq))) # [M,N]\n",
    "E_2_seq = Y_seq - (H_beta_2_seq+ H_beta_1_seq) # [M,N]\n",
    "\n",
    "'''3rd subnetwork'''\n",
    "new = tf.matmul(tf.matmul(k_inv, X_seq),h_(Y_) - tf.matmul(X_, alpha_3))\n",
    "alpha3_seq = tf.assign(alpha_3,tf.add(alpha_3,new)) #DXM\n",
    "H_3_seq = h(mul(t(alpha3_seq), X_seq)) # [M,N]\n",
    "H_pseudo_init = pseudo_inv(H_3_seq,I_MxM,C) #[N,M]\n",
    "beta_3_seq_calculated = mul(E_2_seq, H_pseudo_init) # [M,M]\n",
    "beta_3_seq = tf.assign(beta_3, beta_3_seq_calculated) # [M,M]\n",
    "H_beta_3_seq = mul(beta_3_seq, t(mul(t(X_seq), alpha3_seq))) # [M,N]\n",
    "E_3_seq = Y_seq - (H_beta_3_seq +H_beta_2_seq + H_beta_1_seq )# [M,N]\n",
    "seq_train_graph = E_3_seq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) + subnet_output(alpha_3, beta_3, X_)\n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.433832, train_accuracy: 0.172750\n",
      "test_loss: 0.192498, test_accuracy: 0.782008\n",
      "train_loss: 0.380313, train_accuracy: 0.172750\n",
      "test_loss: 0.180496, test_accuracy: 0.782008\n",
      "train_loss: 0.329648, train_accuracy: 0.172750\n",
      "test_loss: 0.169515, test_accuracy: 0.782008\n",
      "train_loss: 0.285872, train_accuracy: 0.185500\n",
      "test_loss: 0.160452, test_accuracy: 0.783463\n",
      "train_loss: 0.248746, train_accuracy: 0.540250\n",
      "test_loss: 0.153814, test_accuracy: 0.802861\n",
      "train_loss: 0.218575, train_accuracy: 0.753500\n",
      "test_loss: 0.149407, test_accuracy: 0.830262\n",
      "train_loss: 0.195069, train_accuracy: 0.775500\n",
      "test_loss: 0.146696, test_accuracy: 0.844083\n",
      "train_loss: 0.177257, train_accuracy: 0.780000\n",
      "test_loss: 0.145119, test_accuracy: 0.847721\n",
      "train_loss: 0.163924, train_accuracy: 0.786500\n",
      "test_loss: 0.144240, test_accuracy: 0.850873\n",
      "train_loss: 0.153938, train_accuracy: 0.793500\n",
      "test_loss: 0.143770, test_accuracy: 0.856208\n",
      "train_loss: 0.146394, train_accuracy: 0.813500\n",
      "test_loss: 0.143536, test_accuracy: 0.855238\n",
      "train_loss: 0.140613, train_accuracy: 0.826500\n",
      "test_loss: 0.143435, test_accuracy: 0.853783\n",
      "train_loss: 0.136106, train_accuracy: 0.847750\n",
      "test_loss: 0.143412, test_accuracy: 0.851843\n",
      "train_loss: 0.132530, train_accuracy: 0.860250\n",
      "test_loss: 0.143435, test_accuracy: 0.850388\n",
      "train_loss: 0.129638, train_accuracy: 0.874000\n",
      "test_loss: 0.143486, test_accuracy: 0.849903\n",
      "train_loss: 0.127258, train_accuracy: 0.888000\n",
      "test_loss: 0.143553, test_accuracy: 0.847236\n",
      "train_loss: 0.125267, train_accuracy: 0.900000\n",
      "test_loss: 0.143629, test_accuracy: 0.847236\n",
      "train_loss: 0.123573, train_accuracy: 0.910250\n",
      "test_loss: 0.143710, test_accuracy: 0.844326\n",
      "train_loss: 0.122111, train_accuracy: 0.921750\n",
      "test_loss: 0.143793, test_accuracy: 0.843356\n",
      "train_loss: 0.120834, train_accuracy: 0.931750\n",
      "test_loss: 0.143875, test_accuracy: 0.841659\n",
      "train_loss: 0.119705, train_accuracy: 0.938000\n",
      "test_loss: 0.143956, test_accuracy: 0.841659\n",
      "train_loss: 0.118695, train_accuracy: 0.944750\n",
      "test_loss: 0.144032, test_accuracy: 0.841659\n",
      "train_loss: 0.117783, train_accuracy: 0.950750\n",
      "test_loss: 0.144104, test_accuracy: 0.840204\n",
      "train_loss: 0.116954, train_accuracy: 0.953750\n",
      "test_loss: 0.144171, test_accuracy: 0.839961\n",
      "train_loss: 0.116194, train_accuracy: 0.960250\n",
      "test_loss: 0.144231, test_accuracy: 0.840689\n",
      "train_loss: 0.115492, train_accuracy: 0.961750\n",
      "test_loss: 0.144284, test_accuracy: 0.839961\n",
      "train_loss: 0.114840, train_accuracy: 0.965250\n",
      "test_loss: 0.144331, test_accuracy: 0.838749\n",
      "train_loss: 0.114231, train_accuracy: 0.966500\n",
      "test_loss: 0.144370, test_accuracy: 0.838749\n",
      "train_loss: 0.113660, train_accuracy: 0.967500\n",
      "test_loss: 0.144401, test_accuracy: 0.838506\n",
      "train_loss: 0.113122, train_accuracy: 0.968750\n",
      "test_loss: 0.144424, test_accuracy: 0.839476\n",
      "train_loss: 0.112613, train_accuracy: 0.971250\n",
      "test_loss: 0.144439, test_accuracy: 0.839961\n",
      "train_loss: 0.112129, train_accuracy: 0.972750\n",
      "test_loss: 0.144446, test_accuracy: 0.839234\n",
      "train_loss: 0.111669, train_accuracy: 0.973500\n",
      "test_loss: 0.144445, test_accuracy: 0.838264\n",
      "train_loss: 0.111229, train_accuracy: 0.973500\n",
      "test_loss: 0.144435, test_accuracy: 0.839719\n",
      "train_loss: 0.110807, train_accuracy: 0.974000\n",
      "test_loss: 0.144418, test_accuracy: 0.839476\n",
      "train_loss: 0.110402, train_accuracy: 0.974500\n",
      "test_loss: 0.144392, test_accuracy: 0.841659\n",
      "train_loss: 0.110012, train_accuracy: 0.974500\n",
      "test_loss: 0.144359, test_accuracy: 0.841901\n",
      "train_loss: 0.109636, train_accuracy: 0.974500\n",
      "test_loss: 0.144318, test_accuracy: 0.841416\n",
      "train_loss: 0.109273, train_accuracy: 0.974500\n",
      "test_loss: 0.144269, test_accuracy: 0.842386\n",
      "train_loss: 0.108922, train_accuracy: 0.974750\n",
      "test_loss: 0.144213, test_accuracy: 0.842629\n",
      "train_loss: 0.108581, train_accuracy: 0.975250\n",
      "test_loss: 0.144150, test_accuracy: 0.842629\n",
      "train_loss: 0.108250, train_accuracy: 0.975500\n",
      "test_loss: 0.144080, test_accuracy: 0.842386\n",
      "train_loss: 0.107928, train_accuracy: 0.975500\n",
      "test_loss: 0.144004, test_accuracy: 0.843598\n",
      "train_loss: 0.107615, train_accuracy: 0.975250\n",
      "test_loss: 0.143921, test_accuracy: 0.844083\n",
      "train_loss: 0.107310, train_accuracy: 0.975250\n",
      "test_loss: 0.143832, test_accuracy: 0.843841\n",
      "train_loss: 0.107012, train_accuracy: 0.975250\n",
      "test_loss: 0.143738, test_accuracy: 0.844811\n",
      "train_loss: 0.106721, train_accuracy: 0.975250\n",
      "test_loss: 0.143637, test_accuracy: 0.845538\n",
      "train_loss: 0.106437, train_accuracy: 0.975250\n",
      "test_loss: 0.143532, test_accuracy: 0.845296\n",
      "train_loss: 0.106160, train_accuracy: 0.975250\n",
      "test_loss: 0.143422, test_accuracy: 0.846023\n",
      "train_loss: 0.105888, train_accuracy: 0.975250\n",
      "test_loss: 0.143307, test_accuracy: 0.846023\n",
      "train_loss: 0.105623, train_accuracy: 0.975250\n",
      "test_loss: 0.143187, test_accuracy: 0.846751\n",
      "train_loss: 0.105362, train_accuracy: 0.975250\n",
      "test_loss: 0.143064, test_accuracy: 0.846993\n",
      "train_loss: 0.105107, train_accuracy: 0.975250\n",
      "test_loss: 0.142936, test_accuracy: 0.847478\n",
      "train_loss: 0.104857, train_accuracy: 0.975250\n",
      "test_loss: 0.142805, test_accuracy: 0.848448\n",
      "train_loss: 0.104612, train_accuracy: 0.975250\n",
      "test_loss: 0.142671, test_accuracy: 0.851358\n",
      "train_loss: 0.104371, train_accuracy: 0.975250\n",
      "test_loss: 0.142534, test_accuracy: 0.851843\n",
      "train_loss: 0.104135, train_accuracy: 0.975250\n",
      "test_loss: 0.142393, test_accuracy: 0.852328\n",
      "train_loss: 0.103904, train_accuracy: 0.975250\n",
      "test_loss: 0.142251, test_accuracy: 0.852813\n",
      "train_loss: 0.103676, train_accuracy: 0.975250\n",
      "test_loss: 0.142105, test_accuracy: 0.853055\n",
      "train_loss: 0.103453, train_accuracy: 0.975250\n",
      "test_loss: 0.141958, test_accuracy: 0.853055\n",
      "train_loss: 0.103233, train_accuracy: 0.975250\n",
      "test_loss: 0.141809, test_accuracy: 0.853783\n",
      "train_loss: 0.103018, train_accuracy: 0.975250\n",
      "test_loss: 0.141658, test_accuracy: 0.854025\n",
      "train_loss: 0.102806, train_accuracy: 0.975250\n",
      "test_loss: 0.141505, test_accuracy: 0.854268\n",
      "train_loss: 0.102598, train_accuracy: 0.975250\n",
      "test_loss: 0.141351, test_accuracy: 0.854995\n",
      "train_loss: 0.102393, train_accuracy: 0.975250\n",
      "test_loss: 0.141196, test_accuracy: 0.854995\n",
      "train_loss: 0.102192, train_accuracy: 0.975250\n",
      "test_loss: 0.141040, test_accuracy: 0.855480\n",
      "train_loss: 0.101994, train_accuracy: 0.975250\n",
      "test_loss: 0.140883, test_accuracy: 0.855723\n",
      "train_loss: 0.101800, train_accuracy: 0.975250\n",
      "test_loss: 0.140726, test_accuracy: 0.855965\n",
      "train_loss: 0.101609, train_accuracy: 0.975250\n",
      "test_loss: 0.140567, test_accuracy: 0.856450\n",
      "train_loss: 0.101421, train_accuracy: 0.975250\n",
      "test_loss: 0.140409, test_accuracy: 0.856935\n",
      "train_loss: 0.101237, train_accuracy: 0.975250\n",
      "test_loss: 0.140250, test_accuracy: 0.857177\n",
      "train_loss: 0.101055, train_accuracy: 0.975250\n",
      "test_loss: 0.140091, test_accuracy: 0.857420\n",
      "train_loss: 0.100877, train_accuracy: 0.975250\n",
      "test_loss: 0.139932, test_accuracy: 0.857662\n",
      "train_loss: 0.100701, train_accuracy: 0.975250\n",
      "test_loss: 0.139773, test_accuracy: 0.857905\n",
      "train_loss: 0.100529, train_accuracy: 0.975250\n",
      "test_loss: 0.139614, test_accuracy: 0.858147\n",
      "train_loss: 0.100359, train_accuracy: 0.975250\n",
      "test_loss: 0.139456, test_accuracy: 0.858390\n",
      "train_loss: 0.100192, train_accuracy: 0.975250\n",
      "test_loss: 0.139298, test_accuracy: 0.858632\n",
      "train_loss: 0.100028, train_accuracy: 0.975250\n",
      "test_loss: 0.139140, test_accuracy: 0.858875\n",
      "train_loss: 0.099867, train_accuracy: 0.975250\n",
      "test_loss: 0.138983, test_accuracy: 0.858875\n",
      "train_loss: 0.099708, train_accuracy: 0.975250\n",
      "test_loss: 0.138827, test_accuracy: 0.860087\n",
      "train_loss: 0.099552, train_accuracy: 0.975250\n",
      "test_loss: 0.138671, test_accuracy: 0.860330\n",
      "train_loss: 0.099399, train_accuracy: 0.975250\n",
      "test_loss: 0.138516, test_accuracy: 0.860572\n",
      "train_loss: 0.099248, train_accuracy: 0.975250\n",
      "test_loss: 0.138362, test_accuracy: 0.861300\n",
      "train_loss: 0.099100, train_accuracy: 0.975250\n",
      "test_loss: 0.138208, test_accuracy: 0.861542\n",
      "train_loss: 0.098954, train_accuracy: 0.975250\n",
      "test_loss: 0.138056, test_accuracy: 0.861785\n",
      "train_loss: 0.098810, train_accuracy: 0.975250\n",
      "test_loss: 0.137905, test_accuracy: 0.862027\n",
      "train_loss: 0.098669, train_accuracy: 0.975250\n",
      "test_loss: 0.137754, test_accuracy: 0.862512\n",
      "train_loss: 0.098530, train_accuracy: 0.975250\n",
      "test_loss: 0.137605, test_accuracy: 0.863240\n",
      "train_loss: 0.098394, train_accuracy: 0.975250\n",
      "test_loss: 0.137456, test_accuracy: 0.863482\n",
      "train_loss: 0.098260, train_accuracy: 0.975250\n",
      "test_loss: 0.137309, test_accuracy: 0.863725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.098128, train_accuracy: 0.975250\n",
      "test_loss: 0.137163, test_accuracy: 0.863725\n",
      "train_loss: 0.097998, train_accuracy: 0.975250\n",
      "test_loss: 0.137018, test_accuracy: 0.863725\n",
      "train_loss: 0.097870, train_accuracy: 0.975250\n",
      "test_loss: 0.136875, test_accuracy: 0.863725\n",
      "train_loss: 0.097745, train_accuracy: 0.975250\n",
      "test_loss: 0.136732, test_accuracy: 0.863967\n",
      "train_loss: 0.097621, train_accuracy: 0.975250\n",
      "test_loss: 0.136591, test_accuracy: 0.864210\n",
      "train_loss: 0.097500, train_accuracy: 0.975250\n",
      "test_loss: 0.136451, test_accuracy: 0.864452\n",
      "train_loss: 0.097380, train_accuracy: 0.975250\n",
      "test_loss: 0.136312, test_accuracy: 0.864937\n",
      "train_loss: 0.097263, train_accuracy: 0.975250\n",
      "test_loss: 0.136175, test_accuracy: 0.865179\n",
      "train_loss: 0.097147, train_accuracy: 0.975250\n",
      "test_loss: 0.136039, test_accuracy: 0.865179\n",
      "train_loss: 0.097033, train_accuracy: 0.975250\n",
      "test_loss: 0.135904, test_accuracy: 0.865664\n",
      "train_loss: 0.096921, train_accuracy: 0.975250\n",
      "test_loss: 0.135770, test_accuracy: 0.865664\n",
      "train_loss: 0.096811, train_accuracy: 0.975250\n",
      "test_loss: 0.135638, test_accuracy: 0.868574\n",
      "train_loss: 0.096703, train_accuracy: 0.975250\n",
      "test_loss: 0.135507, test_accuracy: 0.868574\n",
      "train_loss: 0.096597, train_accuracy: 0.975250\n",
      "test_loss: 0.135378, test_accuracy: 0.868574\n",
      "train_loss: 0.096492, train_accuracy: 0.975250\n",
      "test_loss: 0.135249, test_accuracy: 0.868817\n",
      "train_loss: 0.096389, train_accuracy: 0.975250\n",
      "test_loss: 0.135122, test_accuracy: 0.869059\n",
      "train_loss: 0.096287, train_accuracy: 0.975250\n",
      "test_loss: 0.134997, test_accuracy: 0.870999\n",
      "train_loss: 0.096187, train_accuracy: 0.975250\n",
      "test_loss: 0.134873, test_accuracy: 0.870999\n",
      "train_loss: 0.096089, train_accuracy: 0.975250\n",
      "test_loss: 0.134750, test_accuracy: 0.870999\n",
      "train_loss: 0.095992, train_accuracy: 0.975250\n",
      "test_loss: 0.134628, test_accuracy: 0.871242\n",
      "train_loss: 0.095897, train_accuracy: 0.975250\n",
      "test_loss: 0.134508, test_accuracy: 0.871726\n",
      "train_loss: 0.095803, train_accuracy: 0.975250\n",
      "test_loss: 0.134389, test_accuracy: 0.871969\n",
      "train_loss: 0.095711, train_accuracy: 0.975250\n",
      "test_loss: 0.134271, test_accuracy: 0.871969\n",
      "train_loss: 0.095620, train_accuracy: 0.975250\n",
      "test_loss: 0.134155, test_accuracy: 0.871969\n",
      "train_loss: 0.095531, train_accuracy: 0.975250\n",
      "test_loss: 0.134040, test_accuracy: 0.872454\n",
      "train_loss: 0.095443, train_accuracy: 0.975250\n",
      "test_loss: 0.133926, test_accuracy: 0.872939\n",
      "train_loss: 0.095356, train_accuracy: 0.975250\n",
      "test_loss: 0.133813, test_accuracy: 0.872939\n",
      "train_loss: 0.095271, train_accuracy: 0.975250\n",
      "test_loss: 0.133702, test_accuracy: 0.872939\n",
      "train_loss: 0.095187, train_accuracy: 0.975250\n",
      "test_loss: 0.133592, test_accuracy: 0.872939\n",
      "train_loss: 0.095104, train_accuracy: 0.975250\n",
      "test_loss: 0.133483, test_accuracy: 0.872939\n",
      "train_loss: 0.095023, train_accuracy: 0.975250\n",
      "test_loss: 0.133376, test_accuracy: 0.873424\n",
      "train_loss: 0.094943, train_accuracy: 0.975250\n",
      "test_loss: 0.133270, test_accuracy: 0.873666\n",
      "train_loss: 0.094864, train_accuracy: 0.975250\n",
      "test_loss: 0.133165, test_accuracy: 0.874151\n",
      "train_loss: 0.094786, train_accuracy: 0.975250\n",
      "test_loss: 0.133061, test_accuracy: 0.874151\n",
      "train_loss: 0.094709, train_accuracy: 0.975250\n",
      "test_loss: 0.132958, test_accuracy: 0.874394\n",
      "train_loss: 0.094633, train_accuracy: 0.975250\n",
      "test_loss: 0.132857, test_accuracy: 0.874636\n",
      "train_loss: 0.094559, train_accuracy: 0.975250\n",
      "test_loss: 0.132756, test_accuracy: 0.874636\n",
      "train_loss: 0.094486, train_accuracy: 0.975250\n",
      "test_loss: 0.132657, test_accuracy: 0.874879\n",
      "train_loss: 0.094413, train_accuracy: 0.975250\n",
      "test_loss: 0.132559, test_accuracy: 0.874879\n",
      "train_loss: 0.094342, train_accuracy: 0.975250\n",
      "test_loss: 0.132462, test_accuracy: 0.878031\n",
      "train_loss: 0.094272, train_accuracy: 0.975250\n",
      "test_loss: 0.132367, test_accuracy: 0.878031\n",
      "train_loss: 0.094203, train_accuracy: 0.975250\n",
      "test_loss: 0.132272, test_accuracy: 0.878031\n",
      "train_loss: 0.094134, train_accuracy: 0.975250\n",
      "test_loss: 0.132179, test_accuracy: 0.878031\n",
      "train_loss: 0.094067, train_accuracy: 0.975250\n",
      "test_loss: 0.132086, test_accuracy: 0.878274\n",
      "train_loss: 0.094001, train_accuracy: 0.975250\n",
      "test_loss: 0.131995, test_accuracy: 0.878274\n",
      "train_loss: 0.093935, train_accuracy: 0.975250\n",
      "test_loss: 0.131905, test_accuracy: 0.878274\n",
      "train_loss: 0.093871, train_accuracy: 0.975250\n",
      "test_loss: 0.131815, test_accuracy: 0.878516\n",
      "train_loss: 0.093807, train_accuracy: 0.975250\n",
      "test_loss: 0.131727, test_accuracy: 0.878758\n",
      "train_loss: 0.093744, train_accuracy: 0.975250\n",
      "test_loss: 0.131640, test_accuracy: 0.878758\n",
      "train_loss: 0.093682, train_accuracy: 0.975250\n",
      "test_loss: 0.131554, test_accuracy: 0.878758\n",
      "train_loss: 0.093621, train_accuracy: 0.975250\n",
      "test_loss: 0.131469, test_accuracy: 0.879001\n",
      "train_loss: 0.093561, train_accuracy: 0.975250\n",
      "test_loss: 0.131385, test_accuracy: 0.879001\n",
      "train_loss: 0.093502, train_accuracy: 0.975250\n",
      "test_loss: 0.131302, test_accuracy: 0.879001\n",
      "train_loss: 0.093443, train_accuracy: 0.975250\n",
      "test_loss: 0.131219, test_accuracy: 0.879001\n",
      "train_loss: 0.093385, train_accuracy: 0.975250\n",
      "test_loss: 0.131138, test_accuracy: 0.879001\n",
      "train_loss: 0.093328, train_accuracy: 0.975250\n",
      "test_loss: 0.131058, test_accuracy: 0.879001\n",
      "train_loss: 0.093271, train_accuracy: 0.975250\n",
      "test_loss: 0.130979, test_accuracy: 0.879243\n",
      "train_loss: 0.093216, train_accuracy: 0.975250\n",
      "test_loss: 0.130900, test_accuracy: 0.879243\n",
      "train_loss: 0.093161, train_accuracy: 0.975250\n",
      "test_loss: 0.130823, test_accuracy: 0.879243\n",
      "train_loss: 0.093106, train_accuracy: 0.975250\n",
      "test_loss: 0.130746, test_accuracy: 0.879243\n",
      "train_loss: 0.093052, train_accuracy: 0.975250\n",
      "test_loss: 0.130670, test_accuracy: 0.879243\n",
      "train_loss: 0.092999, train_accuracy: 0.975250\n",
      "test_loss: 0.130595, test_accuracy: 0.879486\n",
      "train_loss: 0.092947, train_accuracy: 0.975250\n",
      "test_loss: 0.130521, test_accuracy: 0.879486\n",
      "train_loss: 0.092895, train_accuracy: 0.975250\n",
      "test_loss: 0.130448, test_accuracy: 0.879486\n",
      "train_loss: 0.092844, train_accuracy: 0.975250\n",
      "test_loss: 0.130376, test_accuracy: 0.879486\n",
      "train_loss: 0.092794, train_accuracy: 0.975250\n",
      "test_loss: 0.130305, test_accuracy: 0.879486\n",
      "train_loss: 0.092744, train_accuracy: 0.975250\n",
      "test_loss: 0.130234, test_accuracy: 0.879486\n",
      "train_loss: 0.092694, train_accuracy: 0.975250\n",
      "test_loss: 0.130164, test_accuracy: 0.879728\n",
      "train_loss: 0.092646, train_accuracy: 0.975250\n",
      "test_loss: 0.130095, test_accuracy: 0.879728\n",
      "train_loss: 0.092598, train_accuracy: 0.975250\n",
      "test_loss: 0.130027, test_accuracy: 0.879728\n",
      "train_loss: 0.092550, train_accuracy: 0.975250\n",
      "test_loss: 0.129960, test_accuracy: 0.879728\n",
      "train_loss: 0.092503, train_accuracy: 0.975250\n",
      "test_loss: 0.129893, test_accuracy: 0.879971\n",
      "train_loss: 0.092456, train_accuracy: 0.975250\n",
      "test_loss: 0.129827, test_accuracy: 0.879971\n",
      "train_loss: 0.092410, train_accuracy: 0.975250\n",
      "test_loss: 0.129762, test_accuracy: 0.879971\n",
      "train_loss: 0.092364, train_accuracy: 0.975250\n",
      "test_loss: 0.129697, test_accuracy: 0.880213\n",
      "train_loss: 0.092319, train_accuracy: 0.975250\n",
      "test_loss: 0.129634, test_accuracy: 0.880456\n",
      "train_loss: 0.092275, train_accuracy: 0.975250\n",
      "test_loss: 0.129571, test_accuracy: 0.880941\n",
      "train_loss: 0.092231, train_accuracy: 0.975250\n",
      "test_loss: 0.129508, test_accuracy: 0.881426\n",
      "train_loss: 0.092187, train_accuracy: 0.975250\n",
      "test_loss: 0.129447, test_accuracy: 0.881668\n",
      "train_loss: 0.092144, train_accuracy: 0.975250\n",
      "test_loss: 0.129386, test_accuracy: 0.881911\n",
      "train_loss: 0.092101, train_accuracy: 0.975250\n",
      "test_loss: 0.129326, test_accuracy: 0.881911\n",
      "train_loss: 0.092059, train_accuracy: 0.975250\n",
      "test_loss: 0.129266, test_accuracy: 0.881911\n",
      "train_loss: 0.092017, train_accuracy: 0.975250\n",
      "test_loss: 0.129207, test_accuracy: 0.881911\n",
      "train_loss: 0.091975, train_accuracy: 0.975250\n",
      "test_loss: 0.129149, test_accuracy: 0.881911\n",
      "train_loss: 0.091934, train_accuracy: 0.975250\n",
      "test_loss: 0.129091, test_accuracy: 0.881911\n",
      "train_loss: 0.091893, train_accuracy: 0.975250\n",
      "test_loss: 0.129035, test_accuracy: 0.882396\n",
      "train_loss: 0.091853, train_accuracy: 0.975250\n",
      "test_loss: 0.128978, test_accuracy: 0.882638\n",
      "train_loss: 0.091813, train_accuracy: 0.975250\n",
      "test_loss: 0.128923, test_accuracy: 0.883123\n",
      "train_loss: 0.091773, train_accuracy: 0.975250\n",
      "test_loss: 0.128868, test_accuracy: 0.883123\n",
      "train_loss: 0.091734, train_accuracy: 0.975250\n",
      "test_loss: 0.128813, test_accuracy: 0.883366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.091695, train_accuracy: 0.975250\n",
      "test_loss: 0.128759, test_accuracy: 0.883366\n",
      "train_loss: 0.091657, train_accuracy: 0.975250\n",
      "test_loss: 0.128706, test_accuracy: 0.883123\n",
      "train_loss: 0.091619, train_accuracy: 0.975250\n",
      "test_loss: 0.128653, test_accuracy: 0.883123\n",
      "train_loss: 0.091581, train_accuracy: 0.975250\n",
      "test_loss: 0.128601, test_accuracy: 0.883123\n",
      "train_loss: 0.091543, train_accuracy: 0.975250\n",
      "test_loss: 0.128550, test_accuracy: 0.883123\n",
      "train_loss: 0.091506, train_accuracy: 0.975250\n",
      "test_loss: 0.128499, test_accuracy: 0.883123\n",
      "train_loss: 0.091469, train_accuracy: 0.975250\n",
      "test_loss: 0.128448, test_accuracy: 0.883123\n",
      "train_loss: 0.091433, train_accuracy: 0.975250\n",
      "test_loss: 0.128398, test_accuracy: 0.883366\n",
      "train_loss: 0.091397, train_accuracy: 0.975250\n",
      "test_loss: 0.128349, test_accuracy: 0.883366\n",
      "train_loss: 0.091361, train_accuracy: 0.975250\n",
      "test_loss: 0.128300, test_accuracy: 0.883366\n",
      "train_loss: 0.091325, train_accuracy: 0.975250\n",
      "test_loss: 0.128252, test_accuracy: 0.883366\n",
      "train_loss: 0.091290, train_accuracy: 0.975250\n",
      "test_loss: 0.128204, test_accuracy: 0.883366\n",
      "train_loss: 0.091255, train_accuracy: 0.975250\n",
      "test_loss: 0.128157, test_accuracy: 0.883366\n",
      "train_loss: 0.091220, train_accuracy: 0.975250\n",
      "test_loss: 0.128110, test_accuracy: 0.883608\n",
      "train_loss: 0.091186, train_accuracy: 0.975250\n",
      "test_loss: 0.128064, test_accuracy: 0.883608\n",
      "train_loss: 0.091151, train_accuracy: 0.975250\n",
      "test_loss: 0.128018, test_accuracy: 0.883608\n",
      "train_loss: 0.091117, train_accuracy: 0.975250\n",
      "test_loss: 0.127973, test_accuracy: 0.883608\n",
      "train_loss: 0.091084, train_accuracy: 0.975250\n",
      "test_loss: 0.127928, test_accuracy: 0.883608\n",
      "train_loss: 0.091050, train_accuracy: 0.975250\n",
      "test_loss: 0.127883, test_accuracy: 0.883608\n",
      "train_loss: 0.091017, train_accuracy: 0.975250\n",
      "test_loss: 0.127840, test_accuracy: 0.883608\n",
      "train_loss: 0.090984, train_accuracy: 0.975250\n",
      "test_loss: 0.127796, test_accuracy: 0.883366\n",
      "train_loss: 0.090951, train_accuracy: 0.975250\n",
      "test_loss: 0.127753, test_accuracy: 0.883366\n",
      "train_loss: 0.090919, train_accuracy: 0.975250\n",
      "test_loss: 0.127711, test_accuracy: 0.883366\n",
      "train_loss: 0.090886, train_accuracy: 0.975250\n",
      "test_loss: 0.127669, test_accuracy: 0.883366\n",
      "train_loss: 0.090854, train_accuracy: 0.975250\n",
      "test_loss: 0.127627, test_accuracy: 0.883366\n",
      "train_loss: 0.090822, train_accuracy: 0.975250\n",
      "test_loss: 0.127586, test_accuracy: 0.883366\n",
      "train_loss: 0.090791, train_accuracy: 0.975250\n",
      "test_loss: 0.127545, test_accuracy: 0.883366\n",
      "train_loss: 0.090759, train_accuracy: 0.975250\n",
      "test_loss: 0.127505, test_accuracy: 0.883366\n",
      "train_loss: 0.090728, train_accuracy: 0.975250\n",
      "test_loss: 0.127465, test_accuracy: 0.883366\n",
      "train_loss: 0.090697, train_accuracy: 0.975250\n",
      "test_loss: 0.127425, test_accuracy: 0.883366\n",
      "train_loss: 0.090666, train_accuracy: 0.975250\n",
      "test_loss: 0.127386, test_accuracy: 0.883366\n",
      "train_loss: 0.090635, train_accuracy: 0.975250\n",
      "test_loss: 0.127347, test_accuracy: 0.883366\n",
      "train_loss: 0.090605, train_accuracy: 0.975250\n",
      "test_loss: 0.127309, test_accuracy: 0.883366\n",
      "train_loss: 0.090574, train_accuracy: 0.975250\n",
      "test_loss: 0.127271, test_accuracy: 0.883366\n",
      "train_loss: 0.090544, train_accuracy: 0.975250\n",
      "test_loss: 0.127233, test_accuracy: 0.883366\n",
      "train_loss: 0.090514, train_accuracy: 0.975250\n",
      "test_loss: 0.127196, test_accuracy: 0.883366\n",
      "train_loss: 0.090485, train_accuracy: 0.975250\n",
      "test_loss: 0.127159, test_accuracy: 0.883366\n",
      "train_loss: 0.090455, train_accuracy: 0.975250\n",
      "test_loss: 0.127123, test_accuracy: 0.883366\n",
      "train_loss: 0.090426, train_accuracy: 0.975250\n",
      "test_loss: 0.127087, test_accuracy: 0.883366\n",
      "train_loss: 0.090396, train_accuracy: 0.975250\n",
      "test_loss: 0.127051, test_accuracy: 0.883366\n",
      "train_loss: 0.090367, train_accuracy: 0.975250\n",
      "test_loss: 0.127016, test_accuracy: 0.883366\n",
      "train_loss: 0.090338, train_accuracy: 0.975250\n",
      "test_loss: 0.126981, test_accuracy: 0.883366\n",
      "train_loss: 0.090310, train_accuracy: 0.975250\n",
      "test_loss: 0.126946, test_accuracy: 0.883366\n",
      "train_loss: 0.090281, train_accuracy: 0.975250\n",
      "test_loss: 0.126912, test_accuracy: 0.883366\n",
      "train_loss: 0.090253, train_accuracy: 0.975250\n",
      "test_loss: 0.126878, test_accuracy: 0.883366\n",
      "train_loss: 0.090224, train_accuracy: 0.975250\n",
      "test_loss: 0.126845, test_accuracy: 0.883366\n",
      "train_loss: 0.090196, train_accuracy: 0.975250\n",
      "test_loss: 0.126811, test_accuracy: 0.883366\n",
      "train_loss: 0.090168, train_accuracy: 0.975250\n",
      "test_loss: 0.126778, test_accuracy: 0.883366\n",
      "train_loss: 0.090140, train_accuracy: 0.975250\n",
      "test_loss: 0.126746, test_accuracy: 0.883366\n",
      "train_loss: 0.090112, train_accuracy: 0.975250\n",
      "test_loss: 0.126714, test_accuracy: 0.883366\n",
      "train_loss: 0.090085, train_accuracy: 0.975250\n",
      "test_loss: 0.126682, test_accuracy: 0.883366\n",
      "train_loss: 0.090057, train_accuracy: 0.975250\n",
      "test_loss: 0.126650, test_accuracy: 0.883366\n",
      "train_loss: 0.090030, train_accuracy: 0.975250\n",
      "test_loss: 0.126619, test_accuracy: 0.883366\n",
      "train_loss: 0.090003, train_accuracy: 0.975250\n",
      "test_loss: 0.126588, test_accuracy: 0.883366\n",
      "train_loss: 0.089975, train_accuracy: 0.975250\n",
      "test_loss: 0.126557, test_accuracy: 0.883366\n",
      "train_loss: 0.089948, train_accuracy: 0.975250\n",
      "test_loss: 0.126526, test_accuracy: 0.883366\n",
      "train_loss: 0.089922, train_accuracy: 0.975250\n",
      "test_loss: 0.126496, test_accuracy: 0.883608\n",
      "train_loss: 0.089895, train_accuracy: 0.975250\n",
      "test_loss: 0.126466, test_accuracy: 0.883608\n",
      "train_loss: 0.089868, train_accuracy: 0.975250\n",
      "test_loss: 0.126437, test_accuracy: 0.883608\n",
      "train_loss: 0.089842, train_accuracy: 0.975250\n",
      "test_loss: 0.126408, test_accuracy: 0.883608\n",
      "train_loss: 0.089815, train_accuracy: 0.975250\n",
      "test_loss: 0.126379, test_accuracy: 0.883608\n",
      "train_loss: 0.089789, train_accuracy: 0.975250\n",
      "test_loss: 0.126350, test_accuracy: 0.883608\n",
      "train_loss: 0.089763, train_accuracy: 0.975250\n",
      "test_loss: 0.126322, test_accuracy: 0.883608\n",
      "train_loss: 0.089737, train_accuracy: 0.975250\n",
      "test_loss: 0.126294, test_accuracy: 0.883608\n",
      "train_loss: 0.089711, train_accuracy: 0.975250\n",
      "test_loss: 0.126266, test_accuracy: 0.883608\n",
      "train_loss: 0.089685, train_accuracy: 0.975250\n",
      "test_loss: 0.126238, test_accuracy: 0.883851\n",
      "train_loss: 0.089659, train_accuracy: 0.975250\n",
      "test_loss: 0.126211, test_accuracy: 0.883851\n",
      "train_loss: 0.089633, train_accuracy: 0.975250\n",
      "test_loss: 0.126184, test_accuracy: 0.883851\n",
      "train_loss: 0.089608, train_accuracy: 0.975250\n",
      "test_loss: 0.126157, test_accuracy: 0.883851\n",
      "train_loss: 0.089582, train_accuracy: 0.975250\n",
      "test_loss: 0.126130, test_accuracy: 0.883851\n",
      "train_loss: 0.089557, train_accuracy: 0.975250\n",
      "test_loss: 0.126104, test_accuracy: 0.883851\n",
      "train_loss: 0.089532, train_accuracy: 0.975250\n",
      "test_loss: 0.126078, test_accuracy: 0.883851\n",
      "train_loss: 0.089506, train_accuracy: 0.975250\n",
      "test_loss: 0.126052, test_accuracy: 0.884093\n",
      "train_loss: 0.089481, train_accuracy: 0.975250\n",
      "test_loss: 0.126027, test_accuracy: 0.884093\n",
      "train_loss: 0.089456, train_accuracy: 0.975250\n",
      "test_loss: 0.126001, test_accuracy: 0.884093\n",
      "train_loss: 0.089431, train_accuracy: 0.975250\n",
      "test_loss: 0.125976, test_accuracy: 0.884093\n",
      "train_loss: 0.089407, train_accuracy: 0.975250\n",
      "test_loss: 0.125952, test_accuracy: 0.884093\n",
      "train_loss: 0.089382, train_accuracy: 0.975250\n",
      "test_loss: 0.125927, test_accuracy: 0.884336\n",
      "train_loss: 0.089357, train_accuracy: 0.975250\n",
      "test_loss: 0.125903, test_accuracy: 0.884336\n",
      "train_loss: 0.089333, train_accuracy: 0.975250\n",
      "test_loss: 0.125879, test_accuracy: 0.884336\n",
      "train_loss: 0.089308, train_accuracy: 0.975250\n",
      "test_loss: 0.125855, test_accuracy: 0.884336\n",
      "train_loss: 0.089284, train_accuracy: 0.975250\n",
      "test_loss: 0.125831, test_accuracy: 0.884336\n",
      "train_loss: 0.089259, train_accuracy: 0.975250\n",
      "test_loss: 0.125808, test_accuracy: 0.884336\n",
      "train_loss: 0.089235, train_accuracy: 0.975250\n",
      "test_loss: 0.125784, test_accuracy: 0.884336\n",
      "train_loss: 0.089211, train_accuracy: 0.975250\n",
      "test_loss: 0.125761, test_accuracy: 0.884336\n",
      "train_loss: 0.089187, train_accuracy: 0.975250\n",
      "test_loss: 0.125739, test_accuracy: 0.884336\n",
      "train_loss: 0.089163, train_accuracy: 0.975250\n",
      "test_loss: 0.125716, test_accuracy: 0.884578\n",
      "train_loss: 0.089139, train_accuracy: 0.975250\n",
      "test_loss: 0.125694, test_accuracy: 0.884578\n",
      "train_loss: 0.089115, train_accuracy: 0.975250\n",
      "test_loss: 0.125672, test_accuracy: 0.884578\n",
      "train_loss: 0.089091, train_accuracy: 0.975250\n",
      "test_loss: 0.125650, test_accuracy: 0.885063\n",
      "train_loss: 0.089067, train_accuracy: 0.975250\n",
      "test_loss: 0.125628, test_accuracy: 0.885063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.089043, train_accuracy: 0.975250\n",
      "test_loss: 0.125606, test_accuracy: 0.885063\n",
      "train_loss: 0.089020, train_accuracy: 0.975250\n",
      "test_loss: 0.125585, test_accuracy: 0.885063\n",
      "train_loss: 0.088996, train_accuracy: 0.975250\n",
      "test_loss: 0.125564, test_accuracy: 0.885063\n",
      "train_loss: 0.088973, train_accuracy: 0.975250\n",
      "test_loss: 0.125543, test_accuracy: 0.885063\n",
      "train_loss: 0.088949, train_accuracy: 0.975250\n",
      "test_loss: 0.125522, test_accuracy: 0.885063\n",
      "train_loss: 0.088926, train_accuracy: 0.975250\n",
      "test_loss: 0.125502, test_accuracy: 0.885063\n",
      "train_loss: 0.088903, train_accuracy: 0.975250\n",
      "test_loss: 0.125481, test_accuracy: 0.885306\n",
      "train_loss: 0.088880, train_accuracy: 0.975250\n",
      "test_loss: 0.125461, test_accuracy: 0.885306\n",
      "train_loss: 0.088856, train_accuracy: 0.975250\n",
      "test_loss: 0.125441, test_accuracy: 0.885306\n",
      "train_loss: 0.088833, train_accuracy: 0.975250\n",
      "test_loss: 0.125422, test_accuracy: 0.885548\n",
      "train_loss: 0.088810, train_accuracy: 0.975250\n",
      "test_loss: 0.125402, test_accuracy: 0.885548\n",
      "train_loss: 0.088787, train_accuracy: 0.975250\n",
      "test_loss: 0.125383, test_accuracy: 0.885548\n",
      "train_loss: 0.088764, train_accuracy: 0.975250\n",
      "test_loss: 0.125363, test_accuracy: 0.885790\n",
      "train_loss: 0.088742, train_accuracy: 0.975250\n",
      "test_loss: 0.125344, test_accuracy: 0.886033\n",
      "train_loss: 0.088719, train_accuracy: 0.975250\n",
      "test_loss: 0.125325, test_accuracy: 0.886033\n",
      "train_loss: 0.088696, train_accuracy: 0.975250\n",
      "test_loss: 0.125307, test_accuracy: 0.886275\n",
      "train_loss: 0.088673, train_accuracy: 0.975250\n",
      "test_loss: 0.125288, test_accuracy: 0.886275\n",
      "train_loss: 0.088651, train_accuracy: 0.975250\n",
      "test_loss: 0.125270, test_accuracy: 0.886275\n",
      "train_loss: 0.088628, train_accuracy: 0.975250\n",
      "test_loss: 0.125252, test_accuracy: 0.886275\n",
      "train_loss: 0.088606, train_accuracy: 0.975250\n",
      "test_loss: 0.125234, test_accuracy: 0.885790\n",
      "train_loss: 0.088583, train_accuracy: 0.975250\n",
      "test_loss: 0.125216, test_accuracy: 0.885790\n",
      "train_loss: 0.088561, train_accuracy: 0.975250\n",
      "test_loss: 0.125198, test_accuracy: 0.885790\n",
      "train_loss: 0.088538, train_accuracy: 0.975250\n",
      "test_loss: 0.125181, test_accuracy: 0.885790\n",
      "train_loss: 0.088516, train_accuracy: 0.975250\n",
      "test_loss: 0.125163, test_accuracy: 0.886033\n",
      "train_loss: 0.088494, train_accuracy: 0.975250\n",
      "test_loss: 0.125146, test_accuracy: 0.886033\n",
      "train_loss: 0.088472, train_accuracy: 0.975250\n",
      "test_loss: 0.125129, test_accuracy: 0.886033\n",
      "train_loss: 0.088449, train_accuracy: 0.975250\n",
      "test_loss: 0.125112, test_accuracy: 0.886033\n",
      "train_loss: 0.088427, train_accuracy: 0.975250\n",
      "test_loss: 0.125096, test_accuracy: 0.886033\n",
      "train_loss: 0.088405, train_accuracy: 0.975250\n",
      "test_loss: 0.125079, test_accuracy: 0.886033\n",
      "train_loss: 0.088383, train_accuracy: 0.975250\n",
      "test_loss: 0.125063, test_accuracy: 0.886033\n",
      "train_loss: 0.088361, train_accuracy: 0.975250\n",
      "test_loss: 0.125047, test_accuracy: 0.886033\n",
      "train_loss: 0.088340, train_accuracy: 0.975250\n",
      "test_loss: 0.125030, test_accuracy: 0.886033\n",
      "train_loss: 0.088318, train_accuracy: 0.975250\n",
      "test_loss: 0.125014, test_accuracy: 0.886275\n",
      "train_loss: 0.088296, train_accuracy: 0.975250\n",
      "test_loss: 0.124999, test_accuracy: 0.886275\n",
      "train_loss: 0.088274, train_accuracy: 0.975250\n",
      "test_loss: 0.124983, test_accuracy: 0.886275\n",
      "train_loss: 0.088252, train_accuracy: 0.975250\n",
      "test_loss: 0.124968, test_accuracy: 0.886275\n",
      "train_loss: 0.088231, train_accuracy: 0.975250\n",
      "test_loss: 0.124952, test_accuracy: 0.886275\n",
      "train_loss: 0.088209, train_accuracy: 0.975250\n",
      "test_loss: 0.124937, test_accuracy: 0.886275\n",
      "train_loss: 0.088188, train_accuracy: 0.975250\n",
      "test_loss: 0.124922, test_accuracy: 0.886275\n",
      "train_loss: 0.088166, train_accuracy: 0.975250\n",
      "test_loss: 0.124907, test_accuracy: 0.886275\n",
      "train_loss: 0.088145, train_accuracy: 0.975250\n",
      "test_loss: 0.124892, test_accuracy: 0.886275\n",
      "train_loss: 0.088123, train_accuracy: 0.975250\n",
      "test_loss: 0.124878, test_accuracy: 0.886275\n",
      "train_loss: 0.088102, train_accuracy: 0.975250\n",
      "test_loss: 0.124863, test_accuracy: 0.886275\n",
      "train_loss: 0.088080, train_accuracy: 0.975250\n",
      "test_loss: 0.124849, test_accuracy: 0.886275\n",
      "train_loss: 0.088059, train_accuracy: 0.975250\n",
      "test_loss: 0.124834, test_accuracy: 0.886275\n",
      "train_loss: 0.088038, train_accuracy: 0.975250\n",
      "test_loss: 0.124820, test_accuracy: 0.886275\n",
      "train_loss: 0.088017, train_accuracy: 0.975250\n",
      "test_loss: 0.124806, test_accuracy: 0.886275\n",
      "train_loss: 0.087995, train_accuracy: 0.975250\n",
      "test_loss: 0.124793, test_accuracy: 0.886275\n",
      "train_loss: 0.087974, train_accuracy: 0.975250\n",
      "test_loss: 0.124779, test_accuracy: 0.886275\n",
      "train_loss: 0.087953, train_accuracy: 0.975250\n",
      "test_loss: 0.124765, test_accuracy: 0.886275\n",
      "train_loss: 0.087932, train_accuracy: 0.975250\n",
      "test_loss: 0.124752, test_accuracy: 0.886275\n",
      "train_loss: 0.087911, train_accuracy: 0.975250\n",
      "test_loss: 0.124738, test_accuracy: 0.886275\n",
      "train_loss: 0.087890, train_accuracy: 0.975250\n",
      "test_loss: 0.124725, test_accuracy: 0.886275\n",
      "train_loss: 0.087869, train_accuracy: 0.975250\n",
      "test_loss: 0.124712, test_accuracy: 0.885790\n",
      "train_loss: 0.087848, train_accuracy: 0.975250\n",
      "test_loss: 0.124699, test_accuracy: 0.885306\n",
      "train_loss: 0.087828, train_accuracy: 0.975250\n",
      "test_loss: 0.124686, test_accuracy: 0.885306\n",
      "train_loss: 0.087807, train_accuracy: 0.975250\n",
      "test_loss: 0.124674, test_accuracy: 0.885306\n",
      "train_loss: 0.087786, train_accuracy: 0.975250\n",
      "test_loss: 0.124661, test_accuracy: 0.885306\n",
      "train_loss: 0.087765, train_accuracy: 0.975250\n",
      "test_loss: 0.124649, test_accuracy: 0.885306\n",
      "train_loss: 0.087745, train_accuracy: 0.975250\n",
      "test_loss: 0.124636, test_accuracy: 0.885306\n",
      "train_loss: 0.087724, train_accuracy: 0.975250\n",
      "test_loss: 0.124624, test_accuracy: 0.885306\n",
      "train_loss: 0.087703, train_accuracy: 0.975250\n",
      "test_loss: 0.124612, test_accuracy: 0.885306\n",
      "train_loss: 0.087683, train_accuracy: 0.975250\n",
      "test_loss: 0.124600, test_accuracy: 0.885306\n",
      "train_loss: 0.087662, train_accuracy: 0.975250\n",
      "test_loss: 0.124588, test_accuracy: 0.885306\n",
      "train_loss: 0.087642, train_accuracy: 0.975250\n",
      "test_loss: 0.124576, test_accuracy: 0.885306\n",
      "train_loss: 0.087621, train_accuracy: 0.975250\n",
      "test_loss: 0.124564, test_accuracy: 0.885306\n",
      "train_loss: 0.087601, train_accuracy: 0.975250\n",
      "test_loss: 0.124553, test_accuracy: 0.885306\n",
      "train_loss: 0.087581, train_accuracy: 0.975250\n",
      "test_loss: 0.124541, test_accuracy: 0.885306\n",
      "train_loss: 0.087560, train_accuracy: 0.975250\n",
      "test_loss: 0.124530, test_accuracy: 0.885306\n",
      "train_loss: 0.087540, train_accuracy: 0.975250\n",
      "test_loss: 0.124519, test_accuracy: 0.885306\n",
      "train_loss: 0.087520, train_accuracy: 0.975250\n",
      "test_loss: 0.124508, test_accuracy: 0.885306\n",
      "train_loss: 0.087500, train_accuracy: 0.975250\n",
      "test_loss: 0.124496, test_accuracy: 0.885306\n",
      "train_loss: 0.087479, train_accuracy: 0.975250\n",
      "test_loss: 0.124486, test_accuracy: 0.885306\n",
      "train_loss: 0.087459, train_accuracy: 0.975250\n",
      "test_loss: 0.124475, test_accuracy: 0.885306\n",
      "train_loss: 0.087439, train_accuracy: 0.975250\n",
      "test_loss: 0.124464, test_accuracy: 0.885306\n",
      "train_loss: 0.087419, train_accuracy: 0.975250\n",
      "test_loss: 0.124453, test_accuracy: 0.885306\n",
      "train_loss: 0.087399, train_accuracy: 0.975500\n",
      "test_loss: 0.124443, test_accuracy: 0.885306\n",
      "train_loss: 0.087379, train_accuracy: 0.976000\n",
      "test_loss: 0.124432, test_accuracy: 0.885306\n",
      "train_loss: 0.087359, train_accuracy: 0.976000\n",
      "test_loss: 0.124422, test_accuracy: 0.885306\n",
      "train_loss: 0.087339, train_accuracy: 0.976500\n",
      "test_loss: 0.124412, test_accuracy: 0.885306\n",
      "train_loss: 0.087319, train_accuracy: 0.977000\n",
      "test_loss: 0.124402, test_accuracy: 0.885306\n",
      "train_loss: 0.087299, train_accuracy: 0.977500\n",
      "test_loss: 0.124392, test_accuracy: 0.885306\n",
      "train_loss: 0.087279, train_accuracy: 0.977750\n",
      "test_loss: 0.124382, test_accuracy: 0.885306\n",
      "train_loss: 0.087260, train_accuracy: 0.978250\n",
      "test_loss: 0.124372, test_accuracy: 0.885306\n",
      "train_loss: 0.087240, train_accuracy: 0.978250\n",
      "test_loss: 0.124362, test_accuracy: 0.885306\n",
      "train_loss: 0.087220, train_accuracy: 0.978250\n",
      "test_loss: 0.124353, test_accuracy: 0.885306\n",
      "train_loss: 0.087201, train_accuracy: 0.978250\n",
      "test_loss: 0.124343, test_accuracy: 0.885306\n",
      "train_loss: 0.087181, train_accuracy: 0.978250\n",
      "test_loss: 0.124334, test_accuracy: 0.885306\n",
      "train_loss: 0.087161, train_accuracy: 0.978250\n",
      "test_loss: 0.124324, test_accuracy: 0.885306\n",
      "train_loss: 0.087142, train_accuracy: 0.978250\n",
      "test_loss: 0.124315, test_accuracy: 0.885306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.087122, train_accuracy: 0.978250\n",
      "test_loss: 0.124306, test_accuracy: 0.885306\n",
      "train_loss: 0.087103, train_accuracy: 0.978250\n",
      "test_loss: 0.124297, test_accuracy: 0.885306\n",
      "train_loss: 0.087083, train_accuracy: 0.978500\n",
      "test_loss: 0.124288, test_accuracy: 0.885306\n",
      "train_loss: 0.087064, train_accuracy: 0.978500\n",
      "test_loss: 0.124279, test_accuracy: 0.885306\n",
      "train_loss: 0.087044, train_accuracy: 0.978500\n",
      "test_loss: 0.124270, test_accuracy: 0.885306\n",
      "train_loss: 0.087025, train_accuracy: 0.978750\n",
      "test_loss: 0.124261, test_accuracy: 0.885306\n",
      "train_loss: 0.087006, train_accuracy: 0.979000\n",
      "test_loss: 0.124253, test_accuracy: 0.885306\n",
      "train_loss: 0.086986, train_accuracy: 0.979000\n",
      "test_loss: 0.124244, test_accuracy: 0.885306\n",
      "train_loss: 0.086967, train_accuracy: 0.979750\n",
      "test_loss: 0.124236, test_accuracy: 0.885306\n",
      "train_loss: 0.086948, train_accuracy: 0.980000\n",
      "test_loss: 0.124227, test_accuracy: 0.885306\n",
      "train_loss: 0.086929, train_accuracy: 0.980250\n",
      "test_loss: 0.124219, test_accuracy: 0.885306\n",
      "train_loss: 0.086909, train_accuracy: 0.980750\n",
      "test_loss: 0.124211, test_accuracy: 0.885306\n",
      "train_loss: 0.086890, train_accuracy: 0.981250\n",
      "test_loss: 0.124202, test_accuracy: 0.885306\n",
      "train_loss: 0.086871, train_accuracy: 0.981750\n",
      "test_loss: 0.124194, test_accuracy: 0.885306\n",
      "train_loss: 0.086852, train_accuracy: 0.982000\n",
      "test_loss: 0.124186, test_accuracy: 0.885306\n",
      "train_loss: 0.086833, train_accuracy: 0.982250\n",
      "test_loss: 0.124178, test_accuracy: 0.885306\n",
      "train_loss: 0.086814, train_accuracy: 0.982250\n",
      "test_loss: 0.124171, test_accuracy: 0.885306\n",
      "train_loss: 0.086795, train_accuracy: 0.982250\n",
      "test_loss: 0.124163, test_accuracy: 0.885306\n",
      "train_loss: 0.086776, train_accuracy: 0.982250\n",
      "test_loss: 0.124155, test_accuracy: 0.885306\n",
      "train_loss: 0.086757, train_accuracy: 0.982250\n",
      "test_loss: 0.124148, test_accuracy: 0.885306\n",
      "train_loss: 0.086738, train_accuracy: 0.982250\n",
      "test_loss: 0.124140, test_accuracy: 0.885306\n",
      "train_loss: 0.086719, train_accuracy: 0.982250\n",
      "test_loss: 0.124133, test_accuracy: 0.885306\n",
      "train_loss: 0.086701, train_accuracy: 0.982250\n",
      "test_loss: 0.124125, test_accuracy: 0.885306\n",
      "train_loss: 0.086682, train_accuracy: 0.982500\n",
      "test_loss: 0.124118, test_accuracy: 0.885306\n",
      "train_loss: 0.086663, train_accuracy: 0.982500\n",
      "test_loss: 0.124111, test_accuracy: 0.885306\n",
      "train_loss: 0.086644, train_accuracy: 0.982750\n",
      "test_loss: 0.124104, test_accuracy: 0.885306\n",
      "train_loss: 0.086626, train_accuracy: 0.983000\n",
      "test_loss: 0.124096, test_accuracy: 0.885306\n",
      "train_loss: 0.086607, train_accuracy: 0.983000\n",
      "test_loss: 0.124089, test_accuracy: 0.885306\n",
      "train_loss: 0.086588, train_accuracy: 0.983000\n",
      "test_loss: 0.124083, test_accuracy: 0.885306\n",
      "train_loss: 0.086570, train_accuracy: 0.983250\n",
      "test_loss: 0.124076, test_accuracy: 0.885306\n",
      "train_loss: 0.086551, train_accuracy: 0.983250\n",
      "test_loss: 0.124069, test_accuracy: 0.885306\n",
      "train_loss: 0.086533, train_accuracy: 0.983250\n",
      "test_loss: 0.124062, test_accuracy: 0.885306\n",
      "train_loss: 0.086514, train_accuracy: 0.983250\n",
      "test_loss: 0.124056, test_accuracy: 0.885548\n",
      "train_loss: 0.086496, train_accuracy: 0.983250\n",
      "test_loss: 0.124049, test_accuracy: 0.885548\n",
      "train_loss: 0.086477, train_accuracy: 0.983250\n",
      "test_loss: 0.124042, test_accuracy: 0.885548\n",
      "train_loss: 0.086459, train_accuracy: 0.983250\n",
      "test_loss: 0.124036, test_accuracy: 0.885548\n",
      "train_loss: 0.086440, train_accuracy: 0.983250\n",
      "test_loss: 0.124030, test_accuracy: 0.885548\n",
      "train_loss: 0.086422, train_accuracy: 0.983250\n",
      "test_loss: 0.124023, test_accuracy: 0.885548\n",
      "train_loss: 0.086404, train_accuracy: 0.983250\n",
      "test_loss: 0.124017, test_accuracy: 0.885548\n",
      "train_loss: 0.086385, train_accuracy: 0.983250\n",
      "test_loss: 0.124011, test_accuracy: 0.885548\n",
      "train_loss: 0.086367, train_accuracy: 0.983250\n",
      "test_loss: 0.124005, test_accuracy: 0.885548\n",
      "train_loss: 0.086349, train_accuracy: 0.983250\n",
      "test_loss: 0.123999, test_accuracy: 0.885548\n",
      "train_loss: 0.086331, train_accuracy: 0.983250\n",
      "test_loss: 0.123993, test_accuracy: 0.885548\n",
      "train_loss: 0.086313, train_accuracy: 0.983250\n",
      "test_loss: 0.123987, test_accuracy: 0.885548\n",
      "train_loss: 0.086294, train_accuracy: 0.983250\n",
      "test_loss: 0.123981, test_accuracy: 0.885548\n",
      "train_loss: 0.086276, train_accuracy: 0.983250\n",
      "test_loss: 0.123975, test_accuracy: 0.885548\n",
      "train_loss: 0.086258, train_accuracy: 0.983250\n",
      "test_loss: 0.123969, test_accuracy: 0.885548\n",
      "train_loss: 0.086240, train_accuracy: 0.983250\n",
      "test_loss: 0.123964, test_accuracy: 0.885548\n",
      "train_loss: 0.086222, train_accuracy: 0.983250\n",
      "test_loss: 0.123958, test_accuracy: 0.885548\n",
      "train_loss: 0.086204, train_accuracy: 0.983250\n",
      "test_loss: 0.123953, test_accuracy: 0.885548\n",
      "train_loss: 0.086186, train_accuracy: 0.983250\n",
      "test_loss: 0.123947, test_accuracy: 0.885548\n",
      "train_loss: 0.086168, train_accuracy: 0.983250\n",
      "test_loss: 0.123942, test_accuracy: 0.885548\n",
      "train_loss: 0.086150, train_accuracy: 0.983250\n",
      "test_loss: 0.123936, test_accuracy: 0.885548\n",
      "train_loss: 0.086133, train_accuracy: 0.983250\n",
      "test_loss: 0.123931, test_accuracy: 0.885548\n",
      "train_loss: 0.086115, train_accuracy: 0.983250\n",
      "test_loss: 0.123926, test_accuracy: 0.885548\n",
      "train_loss: 0.086097, train_accuracy: 0.983250\n",
      "test_loss: 0.123920, test_accuracy: 0.885548\n",
      "train_loss: 0.086079, train_accuracy: 0.983250\n",
      "test_loss: 0.123915, test_accuracy: 0.885548\n",
      "train_loss: 0.086061, train_accuracy: 0.983250\n",
      "test_loss: 0.123910, test_accuracy: 0.885790\n",
      "train_loss: 0.086044, train_accuracy: 0.983250\n",
      "test_loss: 0.123905, test_accuracy: 0.885790\n",
      "train_loss: 0.086026, train_accuracy: 0.983250\n",
      "test_loss: 0.123900, test_accuracy: 0.885790\n",
      "train_loss: 0.086008, train_accuracy: 0.983250\n",
      "test_loss: 0.123895, test_accuracy: 0.885790\n",
      "train_loss: 0.085991, train_accuracy: 0.983250\n",
      "test_loss: 0.123891, test_accuracy: 0.885790\n",
      "train_loss: 0.085973, train_accuracy: 0.983250\n",
      "test_loss: 0.123886, test_accuracy: 0.885790\n",
      "train_loss: 0.085956, train_accuracy: 0.983250\n",
      "test_loss: 0.123881, test_accuracy: 0.885790\n",
      "train_loss: 0.085938, train_accuracy: 0.983250\n",
      "test_loss: 0.123876, test_accuracy: 0.885790\n",
      "train_loss: 0.085921, train_accuracy: 0.983250\n",
      "test_loss: 0.123872, test_accuracy: 0.885790\n",
      "train_loss: 0.085903, train_accuracy: 0.983250\n",
      "test_loss: 0.123867, test_accuracy: 0.885790\n",
      "train_loss: 0.085886, train_accuracy: 0.983250\n",
      "test_loss: 0.123862, test_accuracy: 0.885790\n",
      "train_loss: 0.085868, train_accuracy: 0.983250\n",
      "test_loss: 0.123858, test_accuracy: 0.885790\n",
      "train_loss: 0.085851, train_accuracy: 0.983250\n",
      "test_loss: 0.123854, test_accuracy: 0.885790\n",
      "train_loss: 0.085834, train_accuracy: 0.983250\n",
      "test_loss: 0.123849, test_accuracy: 0.885790\n",
      "train_loss: 0.085816, train_accuracy: 0.983250\n",
      "test_loss: 0.123845, test_accuracy: 0.885790\n",
      "train_loss: 0.085799, train_accuracy: 0.983250\n",
      "test_loss: 0.123841, test_accuracy: 0.885790\n",
      "train_loss: 0.085782, train_accuracy: 0.983250\n",
      "test_loss: 0.123836, test_accuracy: 0.885790\n",
      "train_loss: 0.085764, train_accuracy: 0.983250\n",
      "test_loss: 0.123832, test_accuracy: 0.886033\n",
      "train_loss: 0.085747, train_accuracy: 0.983250\n",
      "test_loss: 0.123828, test_accuracy: 0.886275\n",
      "train_loss: 0.085730, train_accuracy: 0.983250\n",
      "test_loss: 0.123824, test_accuracy: 0.886275\n",
      "train_loss: 0.085713, train_accuracy: 0.983250\n",
      "test_loss: 0.123820, test_accuracy: 0.886275\n",
      "train_loss: 0.085696, train_accuracy: 0.983250\n",
      "test_loss: 0.123816, test_accuracy: 0.886275\n",
      "train_loss: 0.085679, train_accuracy: 0.983250\n",
      "test_loss: 0.123812, test_accuracy: 0.886275\n",
      "train_loss: 0.085662, train_accuracy: 0.983250\n",
      "test_loss: 0.123808, test_accuracy: 0.886275\n",
      "train_loss: 0.085645, train_accuracy: 0.983250\n",
      "test_loss: 0.123804, test_accuracy: 0.886275\n",
      "train_loss: 0.085628, train_accuracy: 0.983250\n",
      "test_loss: 0.123800, test_accuracy: 0.886275\n",
      "train_loss: 0.085611, train_accuracy: 0.983250\n",
      "test_loss: 0.123797, test_accuracy: 0.886275\n",
      "train_loss: 0.085594, train_accuracy: 0.983250\n",
      "test_loss: 0.123793, test_accuracy: 0.886275\n",
      "train_loss: 0.085577, train_accuracy: 0.983250\n",
      "test_loss: 0.123789, test_accuracy: 0.886275\n",
      "train_loss: 0.085560, train_accuracy: 0.983250\n",
      "test_loss: 0.123786, test_accuracy: 0.886275\n",
      "train_loss: 0.085543, train_accuracy: 0.983250\n",
      "test_loss: 0.123782, test_accuracy: 0.886275\n",
      "train_loss: 0.085526, train_accuracy: 0.983250\n",
      "test_loss: 0.123779, test_accuracy: 0.886275\n",
      "train_loss: 0.085509, train_accuracy: 0.983250\n",
      "test_loss: 0.123775, test_accuracy: 0.886275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.085492, train_accuracy: 0.983250\n",
      "test_loss: 0.123772, test_accuracy: 0.886275\n",
      "train_loss: 0.085476, train_accuracy: 0.983250\n",
      "test_loss: 0.123768, test_accuracy: 0.886275\n",
      "train_loss: 0.085459, train_accuracy: 0.983250\n",
      "test_loss: 0.123765, test_accuracy: 0.886275\n",
      "train_loss: 0.085442, train_accuracy: 0.983250\n",
      "test_loss: 0.123762, test_accuracy: 0.886275\n",
      "train_loss: 0.085426, train_accuracy: 0.983250\n",
      "test_loss: 0.123758, test_accuracy: 0.886275\n",
      "train_loss: 0.085409, train_accuracy: 0.983250\n",
      "test_loss: 0.123755, test_accuracy: 0.886275\n",
      "train_loss: 0.085392, train_accuracy: 0.983250\n",
      "test_loss: 0.123752, test_accuracy: 0.886275\n",
      "train_loss: 0.085376, train_accuracy: 0.983250\n",
      "test_loss: 0.123749, test_accuracy: 0.886275\n",
      "train_loss: 0.085359, train_accuracy: 0.983250\n",
      "test_loss: 0.123746, test_accuracy: 0.886275\n",
      "train_loss: 0.085343, train_accuracy: 0.983250\n",
      "test_loss: 0.123743, test_accuracy: 0.886760\n",
      "train_loss: 0.085326, train_accuracy: 0.983250\n",
      "test_loss: 0.123740, test_accuracy: 0.886760\n",
      "train_loss: 0.085310, train_accuracy: 0.983250\n",
      "test_loss: 0.123737, test_accuracy: 0.886760\n",
      "train_loss: 0.085293, train_accuracy: 0.983250\n",
      "test_loss: 0.123734, test_accuracy: 0.886760\n",
      "train_loss: 0.085277, train_accuracy: 0.983250\n",
      "test_loss: 0.123731, test_accuracy: 0.886760\n",
      "train_loss: 0.085261, train_accuracy: 0.983250\n",
      "test_loss: 0.123728, test_accuracy: 0.886760\n",
      "train_loss: 0.085244, train_accuracy: 0.983250\n",
      "test_loss: 0.123725, test_accuracy: 0.886760\n",
      "train_loss: 0.085228, train_accuracy: 0.983250\n",
      "test_loss: 0.123722, test_accuracy: 0.886760\n",
      "train_loss: 0.085212, train_accuracy: 0.983250\n",
      "test_loss: 0.123720, test_accuracy: 0.886760\n",
      "train_loss: 0.085195, train_accuracy: 0.983250\n",
      "test_loss: 0.123717, test_accuracy: 0.886518\n",
      "train_loss: 0.085179, train_accuracy: 0.983250\n",
      "test_loss: 0.123714, test_accuracy: 0.886518\n",
      "train_loss: 0.085163, train_accuracy: 0.983250\n",
      "test_loss: 0.123712, test_accuracy: 0.886518\n",
      "train_loss: 0.085147, train_accuracy: 0.983250\n",
      "test_loss: 0.123709, test_accuracy: 0.886518\n",
      "train_loss: 0.085130, train_accuracy: 0.983250\n",
      "test_loss: 0.123707, test_accuracy: 0.886518\n",
      "train_loss: 0.085114, train_accuracy: 0.983250\n",
      "test_loss: 0.123704, test_accuracy: 0.886518\n",
      "train_loss: 0.085098, train_accuracy: 0.983250\n",
      "test_loss: 0.123702, test_accuracy: 0.886518\n",
      "train_loss: 0.085082, train_accuracy: 0.983250\n",
      "test_loss: 0.123699, test_accuracy: 0.886518\n",
      "train_loss: 0.085066, train_accuracy: 0.983250\n",
      "test_loss: 0.123697, test_accuracy: 0.886518\n",
      "train_loss: 0.085050, train_accuracy: 0.983250\n",
      "test_loss: 0.123694, test_accuracy: 0.886518\n",
      "train_loss: 0.085034, train_accuracy: 0.983250\n",
      "test_loss: 0.123692, test_accuracy: 0.886518\n",
      "train_loss: 0.085018, train_accuracy: 0.983250\n",
      "test_loss: 0.123690, test_accuracy: 0.886275\n",
      "train_loss: 0.085002, train_accuracy: 0.983250\n",
      "test_loss: 0.123687, test_accuracy: 0.886275\n",
      "train_loss: 0.084986, train_accuracy: 0.983250\n",
      "test_loss: 0.123685, test_accuracy: 0.886275\n",
      "train_loss: 0.084970, train_accuracy: 0.983250\n",
      "test_loss: 0.123683, test_accuracy: 0.886275\n",
      "train_loss: 0.084954, train_accuracy: 0.983250\n",
      "test_loss: 0.123681, test_accuracy: 0.886275\n",
      "train_loss: 0.084939, train_accuracy: 0.983250\n",
      "test_loss: 0.123679, test_accuracy: 0.886275\n",
      "train_loss: 0.084923, train_accuracy: 0.983250\n",
      "test_loss: 0.123677, test_accuracy: 0.886275\n",
      "train_loss: 0.084907, train_accuracy: 0.983250\n",
      "test_loss: 0.123674, test_accuracy: 0.886275\n",
      "train_loss: 0.084891, train_accuracy: 0.983250\n",
      "test_loss: 0.123672, test_accuracy: 0.886275\n",
      "train_loss: 0.084875, train_accuracy: 0.983250\n",
      "test_loss: 0.123670, test_accuracy: 0.886275\n",
      "train_loss: 0.084860, train_accuracy: 0.983250\n",
      "test_loss: 0.123668, test_accuracy: 0.886275\n",
      "train_loss: 0.084844, train_accuracy: 0.983250\n",
      "test_loss: 0.123667, test_accuracy: 0.886275\n",
      "train_loss: 0.084828, train_accuracy: 0.983250\n",
      "test_loss: 0.123665, test_accuracy: 0.886275\n",
      "train_loss: 0.084813, train_accuracy: 0.983250\n",
      "test_loss: 0.123663, test_accuracy: 0.886275\n",
      "train_loss: 0.084797, train_accuracy: 0.983250\n",
      "test_loss: 0.123661, test_accuracy: 0.886275\n",
      "train_loss: 0.084782, train_accuracy: 0.983250\n",
      "test_loss: 0.123659, test_accuracy: 0.886275\n",
      "train_loss: 0.084766, train_accuracy: 0.983250\n",
      "test_loss: 0.123657, test_accuracy: 0.886275\n",
      "train_loss: 0.084751, train_accuracy: 0.983250\n",
      "test_loss: 0.123656, test_accuracy: 0.886275\n",
      "train_loss: 0.084735, train_accuracy: 0.983250\n",
      "test_loss: 0.123654, test_accuracy: 0.886275\n",
      "train_loss: 0.084720, train_accuracy: 0.983250\n",
      "test_loss: 0.123652, test_accuracy: 0.886275\n",
      "train_loss: 0.084704, train_accuracy: 0.983250\n",
      "test_loss: 0.123650, test_accuracy: 0.886275\n",
      "train_loss: 0.084689, train_accuracy: 0.983250\n",
      "test_loss: 0.123649, test_accuracy: 0.886275\n",
      "train_loss: 0.084673, train_accuracy: 0.983250\n",
      "test_loss: 0.123647, test_accuracy: 0.886275\n",
      "train_loss: 0.084658, train_accuracy: 0.983750\n",
      "test_loss: 0.123646, test_accuracy: 0.886275\n",
      "train_loss: 0.084643, train_accuracy: 0.983750\n",
      "test_loss: 0.123644, test_accuracy: 0.886275\n",
      "train_loss: 0.084627, train_accuracy: 0.983750\n",
      "test_loss: 0.123643, test_accuracy: 0.886275\n",
      "train_loss: 0.084612, train_accuracy: 0.983750\n",
      "test_loss: 0.123641, test_accuracy: 0.886275\n",
      "train_loss: 0.084597, train_accuracy: 0.984250\n",
      "test_loss: 0.123640, test_accuracy: 0.886275\n",
      "train_loss: 0.084582, train_accuracy: 0.984750\n",
      "test_loss: 0.123638, test_accuracy: 0.886275\n",
      "train_loss: 0.084566, train_accuracy: 0.984750\n",
      "test_loss: 0.123637, test_accuracy: 0.886275\n",
      "train_loss: 0.084551, train_accuracy: 0.984750\n",
      "test_loss: 0.123635, test_accuracy: 0.886275\n",
      "train_loss: 0.084536, train_accuracy: 0.985000\n",
      "test_loss: 0.123634, test_accuracy: 0.886275\n",
      "train_loss: 0.084521, train_accuracy: 0.985250\n",
      "test_loss: 0.123633, test_accuracy: 0.886275\n",
      "train_loss: 0.084506, train_accuracy: 0.985250\n",
      "test_loss: 0.123631, test_accuracy: 0.886275\n",
      "train_loss: 0.084491, train_accuracy: 0.985750\n",
      "test_loss: 0.123630, test_accuracy: 0.886275\n",
      "train_loss: 0.084476, train_accuracy: 0.985750\n",
      "test_loss: 0.123629, test_accuracy: 0.886275\n",
      "train_loss: 0.084461, train_accuracy: 0.985750\n",
      "test_loss: 0.123628, test_accuracy: 0.886275\n",
      "train_loss: 0.084446, train_accuracy: 0.985750\n",
      "test_loss: 0.123626, test_accuracy: 0.886275\n",
      "train_loss: 0.084431, train_accuracy: 0.986250\n",
      "test_loss: 0.123625, test_accuracy: 0.886275\n",
      "train_loss: 0.084416, train_accuracy: 0.987250\n",
      "test_loss: 0.123624, test_accuracy: 0.886275\n",
      "train_loss: 0.084401, train_accuracy: 0.987250\n",
      "test_loss: 0.123623, test_accuracy: 0.886275\n",
      "train_loss: 0.084386, train_accuracy: 0.987250\n",
      "test_loss: 0.123622, test_accuracy: 0.886275\n",
      "train_loss: 0.084371, train_accuracy: 0.987500\n",
      "test_loss: 0.123621, test_accuracy: 0.886275\n",
      "train_loss: 0.084356, train_accuracy: 0.988750\n",
      "test_loss: 0.123620, test_accuracy: 0.886275\n",
      "train_loss: 0.084341, train_accuracy: 0.989250\n",
      "test_loss: 0.123619, test_accuracy: 0.886275\n",
      "train_loss: 0.084327, train_accuracy: 0.989250\n",
      "test_loss: 0.123618, test_accuracy: 0.886275\n",
      "train_loss: 0.084312, train_accuracy: 0.989750\n",
      "test_loss: 0.123617, test_accuracy: 0.886275\n",
      "train_loss: 0.084297, train_accuracy: 0.990000\n",
      "test_loss: 0.123616, test_accuracy: 0.886275\n",
      "train_loss: 0.084282, train_accuracy: 0.990750\n",
      "test_loss: 0.123615, test_accuracy: 0.886275\n",
      "train_loss: 0.084268, train_accuracy: 0.990750\n",
      "test_loss: 0.123614, test_accuracy: 0.886275\n",
      "train_loss: 0.084253, train_accuracy: 0.990750\n",
      "test_loss: 0.123613, test_accuracy: 0.886275\n",
      "train_loss: 0.084238, train_accuracy: 0.991250\n",
      "test_loss: 0.123612, test_accuracy: 0.886275\n",
      "train_loss: 0.084224, train_accuracy: 0.991250\n",
      "test_loss: 0.123611, test_accuracy: 0.886275\n",
      "train_loss: 0.084209, train_accuracy: 0.991250\n",
      "test_loss: 0.123611, test_accuracy: 0.886275\n",
      "train_loss: 0.084195, train_accuracy: 0.991750\n",
      "test_loss: 0.123610, test_accuracy: 0.886275\n",
      "train_loss: 0.084180, train_accuracy: 0.992250\n",
      "test_loss: 0.123609, test_accuracy: 0.886275\n",
      "train_loss: 0.084165, train_accuracy: 0.992250\n",
      "test_loss: 0.123608, test_accuracy: 0.886275\n",
      "train_loss: 0.084151, train_accuracy: 0.992250\n",
      "test_loss: 0.123608, test_accuracy: 0.886275\n",
      "train_loss: 0.084137, train_accuracy: 0.993000\n",
      "test_loss: 0.123607, test_accuracy: 0.886275\n",
      "train_loss: 0.084122, train_accuracy: 0.994000\n",
      "test_loss: 0.123606, test_accuracy: 0.886275\n",
      "train_loss: 0.084108, train_accuracy: 0.994750\n",
      "test_loss: 0.123606, test_accuracy: 0.886275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.084093, train_accuracy: 0.994750\n",
      "test_loss: 0.123605, test_accuracy: 0.886275\n",
      "train_loss: 0.084079, train_accuracy: 0.994750\n",
      "test_loss: 0.123604, test_accuracy: 0.886275\n",
      "train_loss: 0.084065, train_accuracy: 0.995750\n",
      "test_loss: 0.123604, test_accuracy: 0.886275\n",
      "train_loss: 0.084050, train_accuracy: 0.996250\n",
      "test_loss: 0.123603, test_accuracy: 0.886275\n",
      "train_loss: 0.084036, train_accuracy: 0.996750\n",
      "test_loss: 0.123603, test_accuracy: 0.886275\n",
      "train_loss: 0.084022, train_accuracy: 0.996750\n",
      "test_loss: 0.123602, test_accuracy: 0.886275\n",
      "train_loss: 0.084007, train_accuracy: 0.996750\n",
      "test_loss: 0.123602, test_accuracy: 0.886275\n",
      "train_loss: 0.083993, train_accuracy: 0.997000\n",
      "test_loss: 0.123601, test_accuracy: 0.886275\n",
      "train_loss: 0.083979, train_accuracy: 0.997250\n",
      "test_loss: 0.123601, test_accuracy: 0.886275\n",
      "train_loss: 0.083965, train_accuracy: 0.997250\n",
      "test_loss: 0.123600, test_accuracy: 0.886275\n",
      "train_loss: 0.083951, train_accuracy: 0.997250\n",
      "test_loss: 0.123600, test_accuracy: 0.886275\n",
      "train_loss: 0.083936, train_accuracy: 0.997250\n",
      "test_loss: 0.123599, test_accuracy: 0.886275\n",
      "train_loss: 0.083922, train_accuracy: 0.997250\n",
      "test_loss: 0.123599, test_accuracy: 0.886275\n",
      "train_loss: 0.083908, train_accuracy: 0.997500\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083894, train_accuracy: 0.997750\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083880, train_accuracy: 0.997750\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083866, train_accuracy: 0.997750\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083852, train_accuracy: 0.998250\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083838, train_accuracy: 0.998250\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083824, train_accuracy: 0.998750\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083810, train_accuracy: 0.998750\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083796, train_accuracy: 0.998750\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083783, train_accuracy: 0.999000\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083769, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083755, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083741, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083727, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083714, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083700, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083686, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083672, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083659, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083645, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083631, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083618, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083604, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083591, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083577, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083564, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083550, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083537, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083523, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083510, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083496, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083483, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083470, train_accuracy: 0.999250\n",
      "test_loss: 0.123595, test_accuracy: 0.886275\n",
      "train_loss: 0.083456, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083443, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083430, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083417, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083403, train_accuracy: 0.999250\n",
      "test_loss: 0.123596, test_accuracy: 0.886275\n",
      "train_loss: 0.083390, train_accuracy: 0.999250\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083377, train_accuracy: 0.999250\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083364, train_accuracy: 0.999250\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083351, train_accuracy: 0.999250\n",
      "test_loss: 0.123597, test_accuracy: 0.886275\n",
      "train_loss: 0.083337, train_accuracy: 0.999250\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083324, train_accuracy: 0.999250\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083311, train_accuracy: 0.999250\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083298, train_accuracy: 0.999250\n",
      "test_loss: 0.123598, test_accuracy: 0.886275\n",
      "train_loss: 0.083285, train_accuracy: 0.999250\n",
      "test_loss: 0.123599, test_accuracy: 0.886275\n",
      "train_loss: 0.083272, train_accuracy: 0.999250\n",
      "test_loss: 0.123599, test_accuracy: 0.886275\n",
      "train_loss: 0.083259, train_accuracy: 0.999250\n",
      "test_loss: 0.123599, test_accuracy: 0.886275\n",
      "train_loss: 0.083246, train_accuracy: 0.999250\n",
      "test_loss: 0.123600, test_accuracy: 0.886275\n",
      "train_loss: 0.083233, train_accuracy: 0.999250\n",
      "test_loss: 0.123600, test_accuracy: 0.886275\n",
      "train_loss: 0.083220, train_accuracy: 0.999250\n",
      "test_loss: 0.123601, test_accuracy: 0.886275\n",
      "train_loss: 0.083207, train_accuracy: 0.999250\n",
      "test_loss: 0.123601, test_accuracy: 0.886275\n",
      "train_loss: 0.083195, train_accuracy: 0.999250\n",
      "test_loss: 0.123601, test_accuracy: 0.886275\n",
      "train_loss: 0.083182, train_accuracy: 0.999250\n",
      "test_loss: 0.123602, test_accuracy: 0.886275\n",
      "train_loss: 0.083169, train_accuracy: 0.999250\n",
      "test_loss: 0.123602, test_accuracy: 0.886275\n",
      "train_loss: 0.083156, train_accuracy: 0.999250\n",
      "test_loss: 0.123603, test_accuracy: 0.886275\n",
      "train_loss: 0.083143, train_accuracy: 0.999250\n",
      "test_loss: 0.123603, test_accuracy: 0.886275\n",
      "train_loss: 0.083130, train_accuracy: 0.999250\n",
      "test_loss: 0.123604, test_accuracy: 0.886275\n",
      "train_loss: 0.083118, train_accuracy: 0.999250\n",
      "test_loss: 0.123604, test_accuracy: 0.886275\n",
      "train_loss: 0.083105, train_accuracy: 0.999250\n",
      "test_loss: 0.123605, test_accuracy: 0.886275\n",
      "train_loss: 0.083092, train_accuracy: 0.999250\n",
      "test_loss: 0.123605, test_accuracy: 0.886275\n",
      "train_loss: 0.083080, train_accuracy: 0.999250\n",
      "test_loss: 0.123606, test_accuracy: 0.886275\n",
      "train_loss: 0.083067, train_accuracy: 0.999250\n",
      "test_loss: 0.123606, test_accuracy: 0.886275\n",
      "train_loss: 0.083054, train_accuracy: 0.999250\n",
      "test_loss: 0.123607, test_accuracy: 0.886275\n",
      "train_loss: 0.083042, train_accuracy: 0.999250\n",
      "test_loss: 0.123607, test_accuracy: 0.886518\n",
      "train_loss: 0.083029, train_accuracy: 0.999250\n",
      "test_loss: 0.123608, test_accuracy: 0.886518\n",
      "train_loss: 0.083016, train_accuracy: 0.999250\n",
      "test_loss: 0.123608, test_accuracy: 0.886518\n",
      "train_loss: 0.083004, train_accuracy: 0.999250\n",
      "test_loss: 0.123609, test_accuracy: 0.886518\n",
      "train_loss: 0.082991, train_accuracy: 0.999250\n",
      "test_loss: 0.123609, test_accuracy: 0.886518\n",
      "train_loss: 0.082979, train_accuracy: 0.999250\n",
      "test_loss: 0.123610, test_accuracy: 0.886518\n",
      "train_loss: 0.082966, train_accuracy: 0.999250\n",
      "test_loss: 0.123611, test_accuracy: 0.886518\n",
      "train_loss: 0.082954, train_accuracy: 0.999250\n",
      "test_loss: 0.123611, test_accuracy: 0.886760\n",
      "train_loss: 0.082941, train_accuracy: 0.999250\n",
      "test_loss: 0.123612, test_accuracy: 0.886760\n",
      "train_loss: 0.082929, train_accuracy: 0.999250\n",
      "test_loss: 0.123613, test_accuracy: 0.886760\n",
      "train_loss: 0.082916, train_accuracy: 0.999250\n",
      "test_loss: 0.123613, test_accuracy: 0.886760\n",
      "train_loss: 0.082904, train_accuracy: 0.999250\n",
      "test_loss: 0.123614, test_accuracy: 0.887003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.082891, train_accuracy: 0.999250\n",
      "test_loss: 0.123615, test_accuracy: 0.887003\n",
      "train_loss: 0.082879, train_accuracy: 0.999250\n",
      "test_loss: 0.123615, test_accuracy: 0.887003\n",
      "train_loss: 0.082867, train_accuracy: 0.999250\n",
      "test_loss: 0.123616, test_accuracy: 0.887003\n",
      "train_loss: 0.082854, train_accuracy: 0.999250\n",
      "test_loss: 0.123617, test_accuracy: 0.887003\n",
      "train_loss: 0.082842, train_accuracy: 0.999250\n",
      "test_loss: 0.123617, test_accuracy: 0.887245\n",
      "train_loss: 0.082830, train_accuracy: 0.999250\n",
      "test_loss: 0.123618, test_accuracy: 0.887245\n",
      "train_loss: 0.082818, train_accuracy: 0.999250\n",
      "test_loss: 0.123619, test_accuracy: 0.887245\n",
      "train_loss: 0.082805, train_accuracy: 0.999250\n",
      "test_loss: 0.123619, test_accuracy: 0.887245\n",
      "train_loss: 0.082793, train_accuracy: 0.999250\n",
      "test_loss: 0.123620, test_accuracy: 0.887245\n",
      "train_loss: 0.082781, train_accuracy: 0.999250\n",
      "test_loss: 0.123621, test_accuracy: 0.887245\n",
      "train_loss: 0.082769, train_accuracy: 0.999250\n",
      "test_loss: 0.123622, test_accuracy: 0.887245\n",
      "train_loss: 0.082757, train_accuracy: 0.999250\n",
      "test_loss: 0.123622, test_accuracy: 0.887245\n",
      "train_loss: 0.082744, train_accuracy: 0.999250\n",
      "test_loss: 0.123623, test_accuracy: 0.887245\n",
      "train_loss: 0.082732, train_accuracy: 0.999250\n",
      "test_loss: 0.123624, test_accuracy: 0.887245\n",
      "train_loss: 0.082720, train_accuracy: 0.999250\n",
      "test_loss: 0.123625, test_accuracy: 0.887245\n",
      "train_loss: 0.082708, train_accuracy: 0.999250\n",
      "test_loss: 0.123626, test_accuracy: 0.887488\n",
      "train_loss: 0.082696, train_accuracy: 0.999250\n",
      "test_loss: 0.123626, test_accuracy: 0.887488\n",
      "train_loss: 0.082684, train_accuracy: 0.999250\n",
      "test_loss: 0.123627, test_accuracy: 0.887730\n",
      "train_loss: 0.082672, train_accuracy: 0.999250\n",
      "test_loss: 0.123628, test_accuracy: 0.887730\n",
      "train_loss: 0.082660, train_accuracy: 0.999250\n",
      "test_loss: 0.123629, test_accuracy: 0.887730\n",
      "train_loss: 0.082648, train_accuracy: 0.999250\n",
      "test_loss: 0.123630, test_accuracy: 0.887973\n",
      "train_loss: 0.082636, train_accuracy: 0.999250\n",
      "test_loss: 0.123630, test_accuracy: 0.887973\n",
      "train_loss: 0.082624, train_accuracy: 0.999250\n",
      "test_loss: 0.123631, test_accuracy: 0.888215\n",
      "train_loss: 0.082612, train_accuracy: 0.999250\n",
      "test_loss: 0.123632, test_accuracy: 0.888215\n",
      "train_loss: 0.082600, train_accuracy: 0.999250\n",
      "test_loss: 0.123633, test_accuracy: 0.888215\n",
      "train_loss: 0.082588, train_accuracy: 0.999250\n",
      "test_loss: 0.123634, test_accuracy: 0.888215\n",
      "train_loss: 0.082576, train_accuracy: 0.999250\n",
      "test_loss: 0.123635, test_accuracy: 0.888215\n",
      "train_loss: 0.082564, train_accuracy: 0.999250\n",
      "test_loss: 0.123636, test_accuracy: 0.888215\n",
      "train_loss: 0.082553, train_accuracy: 0.999250\n",
      "test_loss: 0.123636, test_accuracy: 0.888215\n",
      "train_loss: 0.082541, train_accuracy: 0.999250\n",
      "test_loss: 0.123637, test_accuracy: 0.888215\n",
      "train_loss: 0.082529, train_accuracy: 0.999250\n",
      "test_loss: 0.123638, test_accuracy: 0.888215\n",
      "train_loss: 0.082517, train_accuracy: 0.999250\n",
      "test_loss: 0.123639, test_accuracy: 0.888215\n",
      "train_loss: 0.082505, train_accuracy: 0.999250\n",
      "test_loss: 0.123640, test_accuracy: 0.888215\n",
      "train_loss: 0.082494, train_accuracy: 0.999250\n",
      "test_loss: 0.123641, test_accuracy: 0.888215\n",
      "train_loss: 0.082482, train_accuracy: 0.999250\n",
      "test_loss: 0.123642, test_accuracy: 0.888215\n",
      "train_loss: 0.082470, train_accuracy: 0.999250\n",
      "test_loss: 0.123643, test_accuracy: 0.888215\n",
      "train_loss: 0.082459, train_accuracy: 0.999250\n",
      "test_loss: 0.123644, test_accuracy: 0.888215\n",
      "train_loss: 0.082447, train_accuracy: 0.999250\n",
      "test_loss: 0.123645, test_accuracy: 0.888215\n",
      "train_loss: 0.082435, train_accuracy: 0.999250\n",
      "test_loss: 0.123646, test_accuracy: 0.888215\n",
      "train_loss: 0.082424, train_accuracy: 0.999250\n",
      "test_loss: 0.123647, test_accuracy: 0.888215\n",
      "train_loss: 0.082412, train_accuracy: 0.999250\n",
      "test_loss: 0.123648, test_accuracy: 0.888215\n",
      "train_loss: 0.082400, train_accuracy: 0.999250\n",
      "test_loss: 0.123649, test_accuracy: 0.888215\n",
      "train_loss: 0.082389, train_accuracy: 0.999250\n",
      "test_loss: 0.123649, test_accuracy: 0.888215\n",
      "train_loss: 0.082377, train_accuracy: 0.999250\n",
      "test_loss: 0.123650, test_accuracy: 0.888215\n",
      "train_loss: 0.082366, train_accuracy: 0.999250\n",
      "test_loss: 0.123651, test_accuracy: 0.888215\n",
      "train_loss: 0.082354, train_accuracy: 0.999250\n",
      "test_loss: 0.123652, test_accuracy: 0.888215\n",
      "train_loss: 0.082343, train_accuracy: 0.999250\n",
      "test_loss: 0.123653, test_accuracy: 0.888215\n",
      "train_loss: 0.082331, train_accuracy: 0.999250\n",
      "test_loss: 0.123654, test_accuracy: 0.888215\n",
      "train_loss: 0.082320, train_accuracy: 0.999250\n",
      "test_loss: 0.123655, test_accuracy: 0.888215\n",
      "train_loss: 0.082308, train_accuracy: 0.999250\n",
      "test_loss: 0.123656, test_accuracy: 0.888215\n",
      "train_loss: 0.082297, train_accuracy: 0.999250\n",
      "test_loss: 0.123657, test_accuracy: 0.888215\n",
      "train_loss: 0.082285, train_accuracy: 0.999250\n",
      "test_loss: 0.123658, test_accuracy: 0.888215\n",
      "train_loss: 0.082274, train_accuracy: 0.999250\n",
      "test_loss: 0.123660, test_accuracy: 0.888215\n",
      "train_loss: 0.082263, train_accuracy: 0.999250\n",
      "test_loss: 0.123661, test_accuracy: 0.888215\n",
      "train_loss: 0.082251, train_accuracy: 0.999250\n",
      "test_loss: 0.123662, test_accuracy: 0.888215\n",
      "train_loss: 0.082240, train_accuracy: 0.999250\n",
      "test_loss: 0.123663, test_accuracy: 0.888215\n",
      "train_loss: 0.082229, train_accuracy: 0.999250\n",
      "test_loss: 0.123664, test_accuracy: 0.888215\n",
      "train_loss: 0.082217, train_accuracy: 0.999250\n",
      "test_loss: 0.123665, test_accuracy: 0.888215\n",
      "train_loss: 0.082206, train_accuracy: 0.999250\n",
      "test_loss: 0.123666, test_accuracy: 0.888215\n",
      "train_loss: 0.082195, train_accuracy: 0.999250\n",
      "test_loss: 0.123667, test_accuracy: 0.888215\n",
      "train_loss: 0.082184, train_accuracy: 0.999250\n",
      "test_loss: 0.123668, test_accuracy: 0.888215\n",
      "train_loss: 0.082172, train_accuracy: 0.999250\n",
      "test_loss: 0.123669, test_accuracy: 0.888215\n",
      "train_loss: 0.082161, train_accuracy: 0.999250\n",
      "test_loss: 0.123670, test_accuracy: 0.888215\n",
      "train_loss: 0.082150, train_accuracy: 0.999250\n",
      "test_loss: 0.123671, test_accuracy: 0.888215\n",
      "train_loss: 0.082139, train_accuracy: 0.999250\n",
      "test_loss: 0.123672, test_accuracy: 0.888215\n",
      "train_loss: 0.082128, train_accuracy: 0.999250\n",
      "test_loss: 0.123673, test_accuracy: 0.888458\n",
      "train_loss: 0.082116, train_accuracy: 0.999250\n",
      "test_loss: 0.123674, test_accuracy: 0.888458\n",
      "train_loss: 0.082105, train_accuracy: 0.999250\n",
      "test_loss: 0.123675, test_accuracy: 0.888458\n",
      "train_loss: 0.082094, train_accuracy: 0.999250\n",
      "test_loss: 0.123677, test_accuracy: 0.888458\n",
      "train_loss: 0.082083, train_accuracy: 0.999250\n",
      "test_loss: 0.123678, test_accuracy: 0.888700\n",
      "train_loss: 0.082072, train_accuracy: 0.999250\n",
      "test_loss: 0.123679, test_accuracy: 0.888700\n",
      "train_loss: 0.082061, train_accuracy: 0.999250\n",
      "test_loss: 0.123680, test_accuracy: 0.888943\n",
      "train_loss: 0.082050, train_accuracy: 0.999250\n",
      "test_loss: 0.123681, test_accuracy: 0.888943\n",
      "train_loss: 0.082039, train_accuracy: 0.999250\n",
      "test_loss: 0.123682, test_accuracy: 0.888943\n",
      "Sequential training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 100\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "t1 = time.time()\n",
    "for epoch in range(705):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(seq_train_graph, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "t2 = time.time()\n",
    "s+=(t2-t1)/705\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\"\n",
    "#tr_loss, tr_acc = sess.run([loss_init, accuracy_init], feed_dict={X: x_train, Y: y_train})\n",
    "#ts_loss, ts_acc = sess.run([loss_init, accuracy_init], feed_dict={X: x_test, Y: y_test})\n",
    "#print(\"Sequential train training loss: \", tr_loss)\n",
    "#print(\"Sequential train training accuracy: \", tr_acc)\n",
    "#print(\"Sequential train testing loss: \", ts_loss)\n",
    "#print(\"Sequential train testing accuracy: \", ts_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10442599370969949"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_) \n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.133966, train_accuracy: 0.999250\n",
      "test_loss: 0.176850, test_accuracy: 0.889185\n",
      "train_loss: 0.134085, train_accuracy: 0.999250\n",
      "test_loss: 0.176779, test_accuracy: 0.889185\n",
      "train_loss: 0.134144, train_accuracy: 0.999250\n",
      "test_loss: 0.176729, test_accuracy: 0.889185\n",
      "train_loss: 0.134167, train_accuracy: 0.999250\n",
      "test_loss: 0.176691, test_accuracy: 0.889185\n",
      "train_loss: 0.134169, train_accuracy: 0.999250\n",
      "test_loss: 0.176661, test_accuracy: 0.889185\n",
      "train_loss: 0.134159, train_accuracy: 0.999250\n",
      "test_loss: 0.176637, test_accuracy: 0.889185\n",
      "train_loss: 0.134142, train_accuracy: 0.999250\n",
      "test_loss: 0.176617, test_accuracy: 0.889185\n",
      "train_loss: 0.134121, train_accuracy: 0.999250\n",
      "test_loss: 0.176599, test_accuracy: 0.889185\n",
      "train_loss: 0.134098, train_accuracy: 0.999250\n",
      "test_loss: 0.176583, test_accuracy: 0.889185\n",
      "train_loss: 0.134074, train_accuracy: 0.999250\n",
      "test_loss: 0.176569, test_accuracy: 0.889185\n",
      "train_loss: 0.134050, train_accuracy: 0.999250\n",
      "test_loss: 0.176556, test_accuracy: 0.889185\n",
      "train_loss: 0.134027, train_accuracy: 0.999250\n",
      "test_loss: 0.176545, test_accuracy: 0.889185\n",
      "train_loss: 0.134004, train_accuracy: 0.999250\n",
      "test_loss: 0.176535, test_accuracy: 0.889185\n",
      "train_loss: 0.133981, train_accuracy: 0.999250\n",
      "test_loss: 0.176526, test_accuracy: 0.889185\n",
      "train_loss: 0.133960, train_accuracy: 0.999250\n",
      "test_loss: 0.176518, test_accuracy: 0.889185\n",
      "train_loss: 0.133939, train_accuracy: 0.999250\n",
      "test_loss: 0.176510, test_accuracy: 0.889185\n",
      "train_loss: 0.133918, train_accuracy: 0.999250\n",
      "test_loss: 0.176504, test_accuracy: 0.889185\n",
      "train_loss: 0.133899, train_accuracy: 0.999250\n",
      "test_loss: 0.176499, test_accuracy: 0.889185\n",
      "train_loss: 0.133880, train_accuracy: 0.999250\n",
      "test_loss: 0.176494, test_accuracy: 0.889185\n",
      "train_loss: 0.133862, train_accuracy: 0.999250\n",
      "test_loss: 0.176490, test_accuracy: 0.889185\n",
      "train_loss: 0.133844, train_accuracy: 0.999250\n",
      "test_loss: 0.176487, test_accuracy: 0.889428\n",
      "train_loss: 0.133827, train_accuracy: 0.999250\n",
      "test_loss: 0.176485, test_accuracy: 0.889428\n",
      "train_loss: 0.133810, train_accuracy: 0.999250\n",
      "test_loss: 0.176484, test_accuracy: 0.889428\n",
      "train_loss: 0.133794, train_accuracy: 0.999250\n",
      "test_loss: 0.176483, test_accuracy: 0.889428\n",
      "train_loss: 0.133778, train_accuracy: 0.999250\n",
      "test_loss: 0.176482, test_accuracy: 0.889428\n",
      "train_loss: 0.133763, train_accuracy: 0.999250\n",
      "test_loss: 0.176483, test_accuracy: 0.889428\n",
      "train_loss: 0.133748, train_accuracy: 0.999250\n",
      "test_loss: 0.176484, test_accuracy: 0.889428\n",
      "train_loss: 0.133734, train_accuracy: 0.999250\n",
      "test_loss: 0.176485, test_accuracy: 0.889428\n",
      "train_loss: 0.133720, train_accuracy: 0.999250\n",
      "test_loss: 0.176487, test_accuracy: 0.889428\n",
      "train_loss: 0.133707, train_accuracy: 0.999250\n",
      "test_loss: 0.176490, test_accuracy: 0.889428\n",
      "train_loss: 0.133694, train_accuracy: 0.999250\n",
      "test_loss: 0.176493, test_accuracy: 0.889670\n",
      "train_loss: 0.133681, train_accuracy: 0.999250\n",
      "test_loss: 0.176497, test_accuracy: 0.889670\n",
      "train_loss: 0.133669, train_accuracy: 0.999250\n",
      "test_loss: 0.176501, test_accuracy: 0.889670\n",
      "train_loss: 0.133657, train_accuracy: 0.999250\n",
      "test_loss: 0.176506, test_accuracy: 0.889670\n",
      "train_loss: 0.133645, train_accuracy: 0.999250\n",
      "test_loss: 0.176511, test_accuracy: 0.889670\n",
      "train_loss: 0.133634, train_accuracy: 0.999250\n",
      "test_loss: 0.176516, test_accuracy: 0.889670\n",
      "train_loss: 0.133623, train_accuracy: 0.999250\n",
      "test_loss: 0.176522, test_accuracy: 0.889670\n",
      "train_loss: 0.133612, train_accuracy: 0.999250\n",
      "test_loss: 0.176528, test_accuracy: 0.889913\n",
      "train_loss: 0.133602, train_accuracy: 0.999250\n",
      "test_loss: 0.176535, test_accuracy: 0.889913\n",
      "train_loss: 0.133591, train_accuracy: 0.999250\n",
      "test_loss: 0.176542, test_accuracy: 0.889913\n",
      "train_loss: 0.133581, train_accuracy: 0.999250\n",
      "test_loss: 0.176549, test_accuracy: 0.889913\n",
      "train_loss: 0.133572, train_accuracy: 0.999250\n",
      "test_loss: 0.176557, test_accuracy: 0.889913\n",
      "train_loss: 0.133562, train_accuracy: 0.999250\n",
      "test_loss: 0.176565, test_accuracy: 0.889913\n",
      "train_loss: 0.133553, train_accuracy: 0.999250\n",
      "test_loss: 0.176573, test_accuracy: 0.889913\n",
      "train_loss: 0.133544, train_accuracy: 0.999250\n",
      "test_loss: 0.176582, test_accuracy: 0.889913\n",
      "train_loss: 0.133535, train_accuracy: 0.999250\n",
      "test_loss: 0.176591, test_accuracy: 0.889913\n",
      "train_loss: 0.133526, train_accuracy: 0.999250\n",
      "test_loss: 0.176600, test_accuracy: 0.889913\n",
      "train_loss: 0.133518, train_accuracy: 0.999250\n",
      "test_loss: 0.176610, test_accuracy: 0.889913\n",
      "train_loss: 0.133510, train_accuracy: 0.999250\n",
      "test_loss: 0.176619, test_accuracy: 0.889913\n",
      "train_loss: 0.133502, train_accuracy: 0.999250\n",
      "test_loss: 0.176629, test_accuracy: 0.890155\n",
      "train_loss: 0.133494, train_accuracy: 0.999250\n",
      "test_loss: 0.176640, test_accuracy: 0.890155\n",
      "train_loss: 0.133486, train_accuracy: 0.999250\n",
      "test_loss: 0.176650, test_accuracy: 0.890155\n",
      "train_loss: 0.133478, train_accuracy: 0.999250\n",
      "test_loss: 0.176661, test_accuracy: 0.890155\n",
      "train_loss: 0.133471, train_accuracy: 0.999250\n",
      "test_loss: 0.176672, test_accuracy: 0.890155\n",
      "train_loss: 0.133464, train_accuracy: 0.999250\n",
      "test_loss: 0.176683, test_accuracy: 0.890155\n",
      "train_loss: 0.133457, train_accuracy: 0.999250\n",
      "test_loss: 0.176694, test_accuracy: 0.890155\n",
      "train_loss: 0.133450, train_accuracy: 0.999250\n",
      "test_loss: 0.176706, test_accuracy: 0.890155\n",
      "train_loss: 0.133443, train_accuracy: 0.999250\n",
      "test_loss: 0.176717, test_accuracy: 0.890155\n",
      "train_loss: 0.133436, train_accuracy: 0.999250\n",
      "test_loss: 0.176729, test_accuracy: 0.890155\n",
      "train_loss: 0.133429, train_accuracy: 0.999250\n",
      "test_loss: 0.176741, test_accuracy: 0.890155\n",
      "train_loss: 0.133423, train_accuracy: 0.999250\n",
      "test_loss: 0.176753, test_accuracy: 0.890155\n",
      "train_loss: 0.133417, train_accuracy: 0.999250\n",
      "test_loss: 0.176766, test_accuracy: 0.890155\n",
      "train_loss: 0.133410, train_accuracy: 0.999250\n",
      "test_loss: 0.176778, test_accuracy: 0.890155\n",
      "train_loss: 0.133404, train_accuracy: 0.999250\n",
      "test_loss: 0.176791, test_accuracy: 0.890155\n",
      "train_loss: 0.133398, train_accuracy: 0.999250\n",
      "test_loss: 0.176803, test_accuracy: 0.890155\n",
      "train_loss: 0.133392, train_accuracy: 0.999250\n",
      "test_loss: 0.176816, test_accuracy: 0.890155\n",
      "train_loss: 0.133386, train_accuracy: 0.999250\n",
      "test_loss: 0.176829, test_accuracy: 0.890155\n",
      "train_loss: 0.133380, train_accuracy: 0.999250\n",
      "test_loss: 0.176843, test_accuracy: 0.890155\n",
      "train_loss: 0.133375, train_accuracy: 0.999250\n",
      "test_loss: 0.176856, test_accuracy: 0.890155\n",
      "train_loss: 0.133369, train_accuracy: 0.999250\n",
      "test_loss: 0.176869, test_accuracy: 0.890155\n",
      "train_loss: 0.133364, train_accuracy: 0.999250\n",
      "test_loss: 0.176883, test_accuracy: 0.890155\n",
      "train_loss: 0.133358, train_accuracy: 0.999250\n",
      "test_loss: 0.176896, test_accuracy: 0.890155\n",
      "train_loss: 0.133353, train_accuracy: 0.999250\n",
      "test_loss: 0.176910, test_accuracy: 0.890155\n",
      "train_loss: 0.133348, train_accuracy: 0.999250\n",
      "test_loss: 0.176924, test_accuracy: 0.890155\n",
      "train_loss: 0.133342, train_accuracy: 0.999250\n",
      "test_loss: 0.176938, test_accuracy: 0.890155\n",
      "train_loss: 0.133337, train_accuracy: 0.999250\n",
      "test_loss: 0.176952, test_accuracy: 0.890155\n",
      "train_loss: 0.133332, train_accuracy: 0.999250\n",
      "test_loss: 0.176966, test_accuracy: 0.890155\n",
      "train_loss: 0.133327, train_accuracy: 0.999250\n",
      "test_loss: 0.176980, test_accuracy: 0.890155\n",
      "train_loss: 0.133322, train_accuracy: 0.999250\n",
      "test_loss: 0.176994, test_accuracy: 0.890155\n",
      "train_loss: 0.133317, train_accuracy: 0.999250\n",
      "test_loss: 0.177008, test_accuracy: 0.890155\n",
      "train_loss: 0.133313, train_accuracy: 0.999250\n",
      "test_loss: 0.177023, test_accuracy: 0.890155\n",
      "train_loss: 0.133308, train_accuracy: 0.999250\n",
      "test_loss: 0.177037, test_accuracy: 0.890155\n",
      "train_loss: 0.133303, train_accuracy: 0.999250\n",
      "test_loss: 0.177051, test_accuracy: 0.890155\n",
      "train_loss: 0.133298, train_accuracy: 0.999250\n",
      "test_loss: 0.177066, test_accuracy: 0.890155\n",
      "train_loss: 0.133294, train_accuracy: 0.999250\n",
      "test_loss: 0.177081, test_accuracy: 0.890155\n",
      "train_loss: 0.133289, train_accuracy: 0.999250\n",
      "test_loss: 0.177095, test_accuracy: 0.890155\n",
      "train_loss: 0.133285, train_accuracy: 0.999250\n",
      "test_loss: 0.177110, test_accuracy: 0.890155\n",
      "train_loss: 0.133280, train_accuracy: 0.999250\n",
      "test_loss: 0.177125, test_accuracy: 0.890155\n",
      "train_loss: 0.133276, train_accuracy: 0.999250\n",
      "test_loss: 0.177139, test_accuracy: 0.890155\n",
      "train_loss: 0.133272, train_accuracy: 0.999250\n",
      "test_loss: 0.177154, test_accuracy: 0.890155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.133267, train_accuracy: 0.999250\n",
      "test_loss: 0.177169, test_accuracy: 0.890155\n",
      "train_loss: 0.133263, train_accuracy: 0.999250\n",
      "test_loss: 0.177184, test_accuracy: 0.890155\n",
      "train_loss: 0.133259, train_accuracy: 0.999250\n",
      "test_loss: 0.177199, test_accuracy: 0.890155\n",
      "train_loss: 0.133254, train_accuracy: 0.999250\n",
      "test_loss: 0.177214, test_accuracy: 0.890155\n",
      "train_loss: 0.133250, train_accuracy: 0.999250\n",
      "test_loss: 0.177229, test_accuracy: 0.890155\n",
      "train_loss: 0.133246, train_accuracy: 0.999250\n",
      "test_loss: 0.177244, test_accuracy: 0.890155\n",
      "train_loss: 0.133242, train_accuracy: 0.999250\n",
      "test_loss: 0.177259, test_accuracy: 0.890155\n",
      "train_loss: 0.133238, train_accuracy: 0.999250\n",
      "test_loss: 0.177274, test_accuracy: 0.890155\n",
      "train_loss: 0.133234, train_accuracy: 0.999250\n",
      "test_loss: 0.177289, test_accuracy: 0.890398\n",
      "train_loss: 0.133230, train_accuracy: 0.999250\n",
      "test_loss: 0.177304, test_accuracy: 0.890398\n",
      "train_loss: 0.133226, train_accuracy: 0.999250\n",
      "test_loss: 0.177319, test_accuracy: 0.890398\n",
      "train_loss: 0.133222, train_accuracy: 0.999250\n",
      "test_loss: 0.177335, test_accuracy: 0.890398\n",
      "train_loss: 0.133218, train_accuracy: 0.999250\n",
      "test_loss: 0.177350, test_accuracy: 0.890398\n",
      "train_loss: 0.133215, train_accuracy: 0.999250\n",
      "test_loss: 0.177365, test_accuracy: 0.890640\n",
      "train_loss: 0.133211, train_accuracy: 0.999250\n",
      "test_loss: 0.177380, test_accuracy: 0.890640\n",
      "train_loss: 0.133207, train_accuracy: 0.999250\n",
      "test_loss: 0.177396, test_accuracy: 0.890640\n",
      "train_loss: 0.133203, train_accuracy: 0.999250\n",
      "test_loss: 0.177411, test_accuracy: 0.890640\n",
      "train_loss: 0.133199, train_accuracy: 0.999250\n",
      "test_loss: 0.177426, test_accuracy: 0.890640\n",
      "train_loss: 0.133196, train_accuracy: 0.999250\n",
      "test_loss: 0.177441, test_accuracy: 0.890640\n",
      "train_loss: 0.133192, train_accuracy: 0.999250\n",
      "test_loss: 0.177457, test_accuracy: 0.890640\n",
      "train_loss: 0.133188, train_accuracy: 0.999250\n",
      "test_loss: 0.177472, test_accuracy: 0.890640\n",
      "train_loss: 0.133184, train_accuracy: 0.999250\n",
      "test_loss: 0.177487, test_accuracy: 0.890640\n",
      "train_loss: 0.133181, train_accuracy: 0.999250\n",
      "test_loss: 0.177502, test_accuracy: 0.890640\n",
      "train_loss: 0.133177, train_accuracy: 0.999250\n",
      "test_loss: 0.177518, test_accuracy: 0.890640\n",
      "train_loss: 0.133174, train_accuracy: 0.999250\n",
      "test_loss: 0.177533, test_accuracy: 0.890640\n",
      "train_loss: 0.133170, train_accuracy: 0.999250\n",
      "test_loss: 0.177548, test_accuracy: 0.890640\n",
      "train_loss: 0.133167, train_accuracy: 0.999250\n",
      "test_loss: 0.177564, test_accuracy: 0.890640\n",
      "train_loss: 0.133163, train_accuracy: 0.999250\n",
      "test_loss: 0.177579, test_accuracy: 0.890640\n",
      "train_loss: 0.133160, train_accuracy: 0.999250\n",
      "test_loss: 0.177594, test_accuracy: 0.890883\n",
      "train_loss: 0.133156, train_accuracy: 0.999250\n",
      "test_loss: 0.177610, test_accuracy: 0.890883\n",
      "train_loss: 0.133153, train_accuracy: 0.999250\n",
      "test_loss: 0.177625, test_accuracy: 0.890883\n",
      "train_loss: 0.133149, train_accuracy: 0.999250\n",
      "test_loss: 0.177640, test_accuracy: 0.890883\n",
      "train_loss: 0.133146, train_accuracy: 0.999250\n",
      "test_loss: 0.177656, test_accuracy: 0.891125\n",
      "train_loss: 0.133142, train_accuracy: 0.999250\n",
      "test_loss: 0.177671, test_accuracy: 0.891125\n",
      "train_loss: 0.133139, train_accuracy: 0.999250\n",
      "test_loss: 0.177686, test_accuracy: 0.891125\n",
      "train_loss: 0.133136, train_accuracy: 0.999250\n",
      "test_loss: 0.177701, test_accuracy: 0.891125\n",
      "train_loss: 0.133132, train_accuracy: 0.999250\n",
      "test_loss: 0.177717, test_accuracy: 0.891368\n",
      "train_loss: 0.133129, train_accuracy: 0.999250\n",
      "test_loss: 0.177732, test_accuracy: 0.891368\n",
      "train_loss: 0.133126, train_accuracy: 0.999250\n",
      "test_loss: 0.177747, test_accuracy: 0.891368\n",
      "train_loss: 0.133122, train_accuracy: 0.999250\n",
      "test_loss: 0.177762, test_accuracy: 0.891368\n",
      "train_loss: 0.133119, train_accuracy: 0.999250\n",
      "test_loss: 0.177778, test_accuracy: 0.891368\n",
      "train_loss: 0.133116, train_accuracy: 0.999250\n",
      "test_loss: 0.177793, test_accuracy: 0.891610\n",
      "train_loss: 0.133113, train_accuracy: 0.999250\n",
      "test_loss: 0.177808, test_accuracy: 0.891610\n",
      "train_loss: 0.133109, train_accuracy: 0.999250\n",
      "test_loss: 0.177823, test_accuracy: 0.891610\n",
      "train_loss: 0.133106, train_accuracy: 0.999250\n",
      "test_loss: 0.177839, test_accuracy: 0.891610\n",
      "train_loss: 0.133103, train_accuracy: 0.999250\n",
      "test_loss: 0.177854, test_accuracy: 0.891610\n",
      "train_loss: 0.133100, train_accuracy: 0.999250\n",
      "test_loss: 0.177869, test_accuracy: 0.891610\n",
      "train_loss: 0.133097, train_accuracy: 0.999250\n",
      "test_loss: 0.177884, test_accuracy: 0.891610\n",
      "train_loss: 0.133093, train_accuracy: 0.999250\n",
      "test_loss: 0.177899, test_accuracy: 0.891610\n",
      "train_loss: 0.133090, train_accuracy: 0.999250\n",
      "test_loss: 0.177914, test_accuracy: 0.891610\n",
      "train_loss: 0.133087, train_accuracy: 0.999250\n",
      "test_loss: 0.177930, test_accuracy: 0.891610\n",
      "train_loss: 0.133084, train_accuracy: 0.999250\n",
      "test_loss: 0.177945, test_accuracy: 0.891610\n",
      "train_loss: 0.133081, train_accuracy: 0.999250\n",
      "test_loss: 0.177960, test_accuracy: 0.891610\n",
      "train_loss: 0.133078, train_accuracy: 0.999250\n",
      "test_loss: 0.177975, test_accuracy: 0.891610\n",
      "train_loss: 0.133075, train_accuracy: 0.999250\n",
      "test_loss: 0.177990, test_accuracy: 0.891610\n",
      "train_loss: 0.133071, train_accuracy: 0.999250\n",
      "test_loss: 0.178005, test_accuracy: 0.891610\n",
      "train_loss: 0.133068, train_accuracy: 0.999250\n",
      "test_loss: 0.178020, test_accuracy: 0.891610\n",
      "train_loss: 0.133065, train_accuracy: 0.999250\n",
      "test_loss: 0.178035, test_accuracy: 0.891610\n",
      "train_loss: 0.133062, train_accuracy: 0.999250\n",
      "test_loss: 0.178050, test_accuracy: 0.891853\n",
      "train_loss: 0.133059, train_accuracy: 0.999250\n",
      "test_loss: 0.178065, test_accuracy: 0.891853\n",
      "train_loss: 0.133056, train_accuracy: 0.999250\n",
      "test_loss: 0.178080, test_accuracy: 0.891853\n",
      "train_loss: 0.133053, train_accuracy: 0.999250\n",
      "test_loss: 0.178095, test_accuracy: 0.891853\n",
      "train_loss: 0.133050, train_accuracy: 0.999250\n",
      "test_loss: 0.178110, test_accuracy: 0.891853\n",
      "train_loss: 0.133047, train_accuracy: 0.999250\n",
      "test_loss: 0.178125, test_accuracy: 0.892095\n",
      "train_loss: 0.133044, train_accuracy: 0.999250\n",
      "test_loss: 0.178140, test_accuracy: 0.892095\n",
      "train_loss: 0.133041, train_accuracy: 0.999250\n",
      "test_loss: 0.178155, test_accuracy: 0.892095\n",
      "train_loss: 0.133038, train_accuracy: 0.999250\n",
      "test_loss: 0.178170, test_accuracy: 0.892095\n",
      "train_loss: 0.133035, train_accuracy: 0.999250\n",
      "test_loss: 0.178185, test_accuracy: 0.892095\n",
      "train_loss: 0.133032, train_accuracy: 0.999250\n",
      "test_loss: 0.178199, test_accuracy: 0.892095\n",
      "train_loss: 0.133029, train_accuracy: 0.999250\n",
      "test_loss: 0.178214, test_accuracy: 0.892095\n",
      "train_loss: 0.133026, train_accuracy: 0.999250\n",
      "test_loss: 0.178229, test_accuracy: 0.891610\n",
      "train_loss: 0.133023, train_accuracy: 0.999250\n",
      "test_loss: 0.178244, test_accuracy: 0.891610\n",
      "train_loss: 0.133020, train_accuracy: 0.999250\n",
      "test_loss: 0.178259, test_accuracy: 0.891610\n",
      "train_loss: 0.133017, train_accuracy: 0.999250\n",
      "test_loss: 0.178273, test_accuracy: 0.891610\n",
      "train_loss: 0.133015, train_accuracy: 0.999250\n",
      "test_loss: 0.178288, test_accuracy: 0.891610\n",
      "train_loss: 0.133012, train_accuracy: 0.999250\n",
      "test_loss: 0.178303, test_accuracy: 0.891610\n",
      "train_loss: 0.133009, train_accuracy: 0.999250\n",
      "test_loss: 0.178318, test_accuracy: 0.891610\n",
      "train_loss: 0.133006, train_accuracy: 0.999250\n",
      "test_loss: 0.178332, test_accuracy: 0.891610\n",
      "train_loss: 0.133003, train_accuracy: 0.999250\n",
      "test_loss: 0.178347, test_accuracy: 0.891610\n",
      "train_loss: 0.133000, train_accuracy: 0.999250\n",
      "test_loss: 0.178362, test_accuracy: 0.891610\n",
      "train_loss: 0.132997, train_accuracy: 0.999250\n",
      "test_loss: 0.178376, test_accuracy: 0.891610\n",
      "train_loss: 0.132995, train_accuracy: 0.999250\n",
      "test_loss: 0.178391, test_accuracy: 0.891610\n",
      "train_loss: 0.132992, train_accuracy: 0.999250\n",
      "test_loss: 0.178405, test_accuracy: 0.891610\n",
      "train_loss: 0.132989, train_accuracy: 0.999250\n",
      "test_loss: 0.178420, test_accuracy: 0.891610\n",
      "train_loss: 0.132986, train_accuracy: 0.999250\n",
      "test_loss: 0.178435, test_accuracy: 0.891610\n",
      "train_loss: 0.132983, train_accuracy: 0.999250\n",
      "test_loss: 0.178449, test_accuracy: 0.891610\n",
      "train_loss: 0.132981, train_accuracy: 0.999250\n",
      "test_loss: 0.178464, test_accuracy: 0.891610\n",
      "train_loss: 0.132978, train_accuracy: 0.999250\n",
      "test_loss: 0.178478, test_accuracy: 0.891610\n",
      "train_loss: 0.132975, train_accuracy: 0.999250\n",
      "test_loss: 0.178493, test_accuracy: 0.891610\n",
      "train_loss: 0.132972, train_accuracy: 0.999250\n",
      "test_loss: 0.178507, test_accuracy: 0.891610\n",
      "train_loss: 0.132969, train_accuracy: 0.999250\n",
      "test_loss: 0.178521, test_accuracy: 0.891610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.132966, train_accuracy: 0.999250\n",
      "test_loss: 0.178536, test_accuracy: 0.891610\n",
      "train_loss: 0.132964, train_accuracy: 0.999250\n",
      "test_loss: 0.178550, test_accuracy: 0.891610\n",
      "train_loss: 0.132961, train_accuracy: 0.999250\n",
      "test_loss: 0.178565, test_accuracy: 0.891610\n",
      "train_loss: 0.132958, train_accuracy: 0.999250\n",
      "test_loss: 0.178579, test_accuracy: 0.891610\n",
      "train_loss: 0.132956, train_accuracy: 0.999250\n",
      "test_loss: 0.178593, test_accuracy: 0.891610\n",
      "train_loss: 0.132953, train_accuracy: 0.999250\n",
      "test_loss: 0.178607, test_accuracy: 0.891610\n",
      "train_loss: 0.132950, train_accuracy: 0.999250\n",
      "test_loss: 0.178622, test_accuracy: 0.891610\n",
      "train_loss: 0.132948, train_accuracy: 0.999250\n",
      "test_loss: 0.178636, test_accuracy: 0.891610\n",
      "train_loss: 0.132945, train_accuracy: 0.999250\n",
      "test_loss: 0.178650, test_accuracy: 0.891610\n",
      "train_loss: 0.132942, train_accuracy: 0.999250\n",
      "test_loss: 0.178664, test_accuracy: 0.891610\n",
      "train_loss: 0.132939, train_accuracy: 0.999250\n",
      "test_loss: 0.178679, test_accuracy: 0.891610\n",
      "train_loss: 0.132937, train_accuracy: 0.999250\n",
      "test_loss: 0.178693, test_accuracy: 0.891610\n",
      "train_loss: 0.132934, train_accuracy: 0.999250\n",
      "test_loss: 0.178707, test_accuracy: 0.891610\n",
      "train_loss: 0.132931, train_accuracy: 0.999250\n",
      "test_loss: 0.178721, test_accuracy: 0.891610\n",
      "train_loss: 0.132929, train_accuracy: 0.999250\n",
      "test_loss: 0.178735, test_accuracy: 0.891610\n",
      "train_loss: 0.132926, train_accuracy: 0.999250\n",
      "test_loss: 0.178749, test_accuracy: 0.891610\n",
      "train_loss: 0.132924, train_accuracy: 0.999250\n",
      "test_loss: 0.178763, test_accuracy: 0.891610\n",
      "train_loss: 0.132921, train_accuracy: 0.999250\n",
      "test_loss: 0.178777, test_accuracy: 0.891610\n",
      "train_loss: 0.132918, train_accuracy: 0.999250\n",
      "test_loss: 0.178791, test_accuracy: 0.891610\n",
      "train_loss: 0.132916, train_accuracy: 0.999250\n",
      "test_loss: 0.178805, test_accuracy: 0.891610\n",
      "train_loss: 0.132913, train_accuracy: 0.999250\n",
      "test_loss: 0.178819, test_accuracy: 0.891610\n",
      "train_loss: 0.132910, train_accuracy: 0.999250\n",
      "test_loss: 0.178833, test_accuracy: 0.891610\n",
      "train_loss: 0.132908, train_accuracy: 0.999250\n",
      "test_loss: 0.178847, test_accuracy: 0.891610\n",
      "train_loss: 0.132905, train_accuracy: 0.999250\n",
      "test_loss: 0.178861, test_accuracy: 0.891853\n",
      "train_loss: 0.132903, train_accuracy: 0.999250\n",
      "test_loss: 0.178875, test_accuracy: 0.891853\n",
      "train_loss: 0.132900, train_accuracy: 0.999250\n",
      "test_loss: 0.178889, test_accuracy: 0.891853\n",
      "train_loss: 0.132898, train_accuracy: 0.999250\n",
      "test_loss: 0.178903, test_accuracy: 0.891853\n",
      "train_loss: 0.132895, train_accuracy: 0.999250\n",
      "test_loss: 0.178916, test_accuracy: 0.891853\n",
      "train_loss: 0.132893, train_accuracy: 0.999250\n",
      "test_loss: 0.178930, test_accuracy: 0.891853\n",
      "train_loss: 0.132890, train_accuracy: 0.999250\n",
      "test_loss: 0.178944, test_accuracy: 0.892338\n",
      "train_loss: 0.132887, train_accuracy: 0.999250\n",
      "test_loss: 0.178958, test_accuracy: 0.892338\n",
      "train_loss: 0.132885, train_accuracy: 0.999250\n",
      "test_loss: 0.178972, test_accuracy: 0.892338\n",
      "train_loss: 0.132882, train_accuracy: 0.999250\n",
      "test_loss: 0.178985, test_accuracy: 0.892338\n",
      "train_loss: 0.132880, train_accuracy: 0.999250\n",
      "test_loss: 0.178999, test_accuracy: 0.892338\n",
      "train_loss: 0.132877, train_accuracy: 0.999250\n",
      "test_loss: 0.179013, test_accuracy: 0.892580\n",
      "train_loss: 0.132875, train_accuracy: 0.999250\n",
      "test_loss: 0.179026, test_accuracy: 0.892580\n",
      "train_loss: 0.132872, train_accuracy: 0.999250\n",
      "test_loss: 0.179040, test_accuracy: 0.892580\n",
      "train_loss: 0.132870, train_accuracy: 0.999250\n",
      "test_loss: 0.179054, test_accuracy: 0.892580\n",
      "train_loss: 0.132867, train_accuracy: 0.999250\n",
      "test_loss: 0.179067, test_accuracy: 0.892580\n",
      "train_loss: 0.132865, train_accuracy: 0.999250\n",
      "test_loss: 0.179081, test_accuracy: 0.892823\n",
      "train_loss: 0.132862, train_accuracy: 0.999250\n",
      "test_loss: 0.179094, test_accuracy: 0.892823\n",
      "train_loss: 0.132860, train_accuracy: 0.999250\n",
      "test_loss: 0.179108, test_accuracy: 0.892823\n",
      "train_loss: 0.132857, train_accuracy: 0.999250\n",
      "test_loss: 0.179121, test_accuracy: 0.892823\n",
      "train_loss: 0.132855, train_accuracy: 0.999250\n",
      "test_loss: 0.179135, test_accuracy: 0.893065\n",
      "train_loss: 0.132853, train_accuracy: 0.999250\n",
      "test_loss: 0.179149, test_accuracy: 0.893307\n",
      "train_loss: 0.132850, train_accuracy: 0.999250\n",
      "test_loss: 0.179162, test_accuracy: 0.893307\n",
      "train_loss: 0.132848, train_accuracy: 0.999250\n",
      "test_loss: 0.179175, test_accuracy: 0.893307\n",
      "train_loss: 0.132845, train_accuracy: 0.999250\n",
      "test_loss: 0.179189, test_accuracy: 0.893307\n",
      "train_loss: 0.132843, train_accuracy: 0.999250\n",
      "test_loss: 0.179202, test_accuracy: 0.893550\n",
      "train_loss: 0.132841, train_accuracy: 0.999250\n",
      "test_loss: 0.179216, test_accuracy: 0.893550\n",
      "train_loss: 0.132838, train_accuracy: 0.999250\n",
      "test_loss: 0.179229, test_accuracy: 0.893550\n",
      "train_loss: 0.132836, train_accuracy: 0.999250\n",
      "test_loss: 0.179242, test_accuracy: 0.893550\n",
      "train_loss: 0.132833, train_accuracy: 0.999250\n",
      "test_loss: 0.179256, test_accuracy: 0.893550\n",
      "train_loss: 0.132831, train_accuracy: 0.999250\n",
      "test_loss: 0.179269, test_accuracy: 0.893550\n",
      "train_loss: 0.132829, train_accuracy: 0.999250\n",
      "test_loss: 0.179282, test_accuracy: 0.893550\n",
      "train_loss: 0.132826, train_accuracy: 0.999250\n",
      "test_loss: 0.179295, test_accuracy: 0.893550\n",
      "train_loss: 0.132824, train_accuracy: 0.999250\n",
      "test_loss: 0.179309, test_accuracy: 0.893550\n",
      "train_loss: 0.132822, train_accuracy: 0.999250\n",
      "test_loss: 0.179322, test_accuracy: 0.893550\n",
      "train_loss: 0.132819, train_accuracy: 0.999250\n",
      "test_loss: 0.179335, test_accuracy: 0.893550\n",
      "train_loss: 0.132817, train_accuracy: 0.999250\n",
      "test_loss: 0.179348, test_accuracy: 0.893550\n",
      "train_loss: 0.132815, train_accuracy: 0.999250\n",
      "test_loss: 0.179361, test_accuracy: 0.893550\n",
      "train_loss: 0.132812, train_accuracy: 0.999250\n",
      "test_loss: 0.179374, test_accuracy: 0.893550\n",
      "train_loss: 0.132810, train_accuracy: 0.999250\n",
      "test_loss: 0.179387, test_accuracy: 0.893550\n",
      "train_loss: 0.132808, train_accuracy: 0.999250\n",
      "test_loss: 0.179401, test_accuracy: 0.893550\n",
      "train_loss: 0.132805, train_accuracy: 0.999250\n",
      "test_loss: 0.179414, test_accuracy: 0.893550\n",
      "train_loss: 0.132803, train_accuracy: 0.999250\n",
      "test_loss: 0.179427, test_accuracy: 0.893550\n",
      "train_loss: 0.132801, train_accuracy: 0.999250\n",
      "test_loss: 0.179440, test_accuracy: 0.893550\n",
      "train_loss: 0.132798, train_accuracy: 0.999250\n",
      "test_loss: 0.179453, test_accuracy: 0.893792\n",
      "train_loss: 0.132796, train_accuracy: 0.999250\n",
      "test_loss: 0.179466, test_accuracy: 0.893792\n",
      "train_loss: 0.132794, train_accuracy: 0.999250\n",
      "test_loss: 0.179479, test_accuracy: 0.894035\n",
      "train_loss: 0.132791, train_accuracy: 0.999250\n",
      "test_loss: 0.179492, test_accuracy: 0.894035\n",
      "train_loss: 0.132789, train_accuracy: 0.999250\n",
      "test_loss: 0.179504, test_accuracy: 0.894035\n",
      "train_loss: 0.132787, train_accuracy: 0.999250\n",
      "test_loss: 0.179517, test_accuracy: 0.894035\n",
      "train_loss: 0.132785, train_accuracy: 0.999250\n",
      "test_loss: 0.179530, test_accuracy: 0.894277\n",
      "train_loss: 0.132782, train_accuracy: 0.999250\n",
      "test_loss: 0.179543, test_accuracy: 0.894277\n",
      "train_loss: 0.132780, train_accuracy: 0.999250\n",
      "test_loss: 0.179556, test_accuracy: 0.894520\n",
      "train_loss: 0.132778, train_accuracy: 0.999250\n",
      "test_loss: 0.179569, test_accuracy: 0.894520\n",
      "train_loss: 0.132776, train_accuracy: 0.999250\n",
      "test_loss: 0.179582, test_accuracy: 0.894520\n",
      "train_loss: 0.132774, train_accuracy: 0.999250\n",
      "test_loss: 0.179594, test_accuracy: 0.894520\n",
      "train_loss: 0.132771, train_accuracy: 0.999250\n",
      "test_loss: 0.179607, test_accuracy: 0.894520\n",
      "train_loss: 0.132769, train_accuracy: 0.999250\n",
      "test_loss: 0.179620, test_accuracy: 0.894520\n",
      "train_loss: 0.132767, train_accuracy: 0.999250\n",
      "test_loss: 0.179633, test_accuracy: 0.894520\n",
      "train_loss: 0.132765, train_accuracy: 0.999250\n",
      "test_loss: 0.179645, test_accuracy: 0.894762\n",
      "train_loss: 0.132762, train_accuracy: 0.999250\n",
      "test_loss: 0.179658, test_accuracy: 0.895005\n",
      "train_loss: 0.132760, train_accuracy: 0.999250\n",
      "test_loss: 0.179671, test_accuracy: 0.895005\n",
      "train_loss: 0.132758, train_accuracy: 0.999250\n",
      "test_loss: 0.179683, test_accuracy: 0.895005\n",
      "train_loss: 0.132756, train_accuracy: 0.999250\n",
      "test_loss: 0.179696, test_accuracy: 0.895005\n",
      "train_loss: 0.132754, train_accuracy: 0.999250\n",
      "test_loss: 0.179709, test_accuracy: 0.895005\n",
      "train_loss: 0.132752, train_accuracy: 0.999250\n",
      "test_loss: 0.179721, test_accuracy: 0.895247\n",
      "train_loss: 0.132749, train_accuracy: 0.999250\n",
      "test_loss: 0.179734, test_accuracy: 0.895490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.132747, train_accuracy: 0.999250\n",
      "test_loss: 0.179746, test_accuracy: 0.895490\n",
      "train_loss: 0.132745, train_accuracy: 0.999250\n",
      "test_loss: 0.179759, test_accuracy: 0.895490\n",
      "train_loss: 0.132743, train_accuracy: 0.999250\n",
      "test_loss: 0.179771, test_accuracy: 0.895490\n",
      "train_loss: 0.132741, train_accuracy: 0.999250\n",
      "test_loss: 0.179784, test_accuracy: 0.895490\n",
      "train_loss: 0.132739, train_accuracy: 0.999250\n",
      "test_loss: 0.179796, test_accuracy: 0.895490\n",
      "train_loss: 0.132737, train_accuracy: 0.999250\n",
      "test_loss: 0.179809, test_accuracy: 0.895490\n",
      "train_loss: 0.132735, train_accuracy: 0.999250\n",
      "test_loss: 0.179821, test_accuracy: 0.895490\n",
      "train_loss: 0.132732, train_accuracy: 0.999250\n",
      "test_loss: 0.179833, test_accuracy: 0.895490\n",
      "train_loss: 0.132730, train_accuracy: 0.999250\n",
      "test_loss: 0.179846, test_accuracy: 0.895490\n",
      "train_loss: 0.132728, train_accuracy: 0.999250\n",
      "test_loss: 0.179858, test_accuracy: 0.895490\n",
      "train_loss: 0.132726, train_accuracy: 0.999250\n",
      "test_loss: 0.179871, test_accuracy: 0.895490\n",
      "train_loss: 0.132724, train_accuracy: 0.999250\n",
      "test_loss: 0.179883, test_accuracy: 0.895490\n",
      "train_loss: 0.132722, train_accuracy: 0.999250\n",
      "test_loss: 0.179895, test_accuracy: 0.895490\n",
      "train_loss: 0.132720, train_accuracy: 0.999250\n",
      "test_loss: 0.179908, test_accuracy: 0.895490\n",
      "train_loss: 0.132718, train_accuracy: 0.999250\n",
      "test_loss: 0.179920, test_accuracy: 0.895490\n",
      "train_loss: 0.132716, train_accuracy: 0.999250\n",
      "test_loss: 0.179932, test_accuracy: 0.895490\n",
      "train_loss: 0.132714, train_accuracy: 0.999250\n",
      "test_loss: 0.179944, test_accuracy: 0.895490\n",
      "train_loss: 0.132712, train_accuracy: 0.999250\n",
      "test_loss: 0.179957, test_accuracy: 0.894520\n",
      "train_loss: 0.132710, train_accuracy: 0.999250\n",
      "test_loss: 0.179969, test_accuracy: 0.894520\n",
      "train_loss: 0.132708, train_accuracy: 0.999250\n",
      "test_loss: 0.179981, test_accuracy: 0.894520\n",
      "train_loss: 0.132706, train_accuracy: 0.999250\n",
      "test_loss: 0.179993, test_accuracy: 0.894520\n",
      "train_loss: 0.132704, train_accuracy: 0.999250\n",
      "test_loss: 0.180005, test_accuracy: 0.894520\n",
      "train_loss: 0.132702, train_accuracy: 0.999250\n",
      "test_loss: 0.180018, test_accuracy: 0.894520\n",
      "train_loss: 0.132699, train_accuracy: 0.999250\n",
      "test_loss: 0.180030, test_accuracy: 0.894520\n",
      "train_loss: 0.132697, train_accuracy: 0.999250\n",
      "test_loss: 0.180042, test_accuracy: 0.894520\n",
      "train_loss: 0.132695, train_accuracy: 0.999250\n",
      "test_loss: 0.180054, test_accuracy: 0.894520\n",
      "train_loss: 0.132693, train_accuracy: 0.999250\n",
      "test_loss: 0.180066, test_accuracy: 0.894520\n",
      "train_loss: 0.132691, train_accuracy: 0.999250\n",
      "test_loss: 0.180078, test_accuracy: 0.894520\n",
      "train_loss: 0.132689, train_accuracy: 0.999250\n",
      "test_loss: 0.180090, test_accuracy: 0.894520\n",
      "train_loss: 0.132687, train_accuracy: 0.999250\n",
      "test_loss: 0.180102, test_accuracy: 0.894520\n",
      "train_loss: 0.132686, train_accuracy: 0.999250\n",
      "test_loss: 0.180114, test_accuracy: 0.894520\n",
      "train_loss: 0.132684, train_accuracy: 0.999250\n",
      "test_loss: 0.180126, test_accuracy: 0.894520\n",
      "train_loss: 0.132682, train_accuracy: 0.999250\n",
      "test_loss: 0.180138, test_accuracy: 0.894520\n",
      "train_loss: 0.132680, train_accuracy: 0.999250\n",
      "test_loss: 0.180150, test_accuracy: 0.894520\n",
      "train_loss: 0.132678, train_accuracy: 0.999250\n",
      "test_loss: 0.180162, test_accuracy: 0.894520\n",
      "train_loss: 0.132676, train_accuracy: 0.999250\n",
      "test_loss: 0.180174, test_accuracy: 0.894520\n",
      "train_loss: 0.132674, train_accuracy: 0.999250\n",
      "test_loss: 0.180185, test_accuracy: 0.894762\n",
      "train_loss: 0.132672, train_accuracy: 0.999250\n",
      "test_loss: 0.180197, test_accuracy: 0.894762\n",
      "train_loss: 0.132670, train_accuracy: 0.999250\n",
      "test_loss: 0.180209, test_accuracy: 0.894762\n",
      "train_loss: 0.132668, train_accuracy: 0.999250\n",
      "test_loss: 0.180221, test_accuracy: 0.894762\n",
      "train_loss: 0.132666, train_accuracy: 0.999250\n",
      "test_loss: 0.180233, test_accuracy: 0.894762\n",
      "train_loss: 0.132664, train_accuracy: 0.999250\n",
      "test_loss: 0.180245, test_accuracy: 0.894762\n",
      "train_loss: 0.132662, train_accuracy: 0.999250\n",
      "test_loss: 0.180256, test_accuracy: 0.895005\n",
      "train_loss: 0.132660, train_accuracy: 0.999250\n",
      "test_loss: 0.180268, test_accuracy: 0.895005\n",
      "train_loss: 0.132658, train_accuracy: 0.999250\n",
      "test_loss: 0.180280, test_accuracy: 0.895005\n",
      "train_loss: 0.132657, train_accuracy: 0.999250\n",
      "test_loss: 0.180292, test_accuracy: 0.895005\n",
      "train_loss: 0.132655, train_accuracy: 0.999250\n",
      "test_loss: 0.180303, test_accuracy: 0.895247\n",
      "train_loss: 0.132653, train_accuracy: 0.999250\n",
      "test_loss: 0.180315, test_accuracy: 0.895247\n",
      "train_loss: 0.132651, train_accuracy: 0.999250\n",
      "test_loss: 0.180327, test_accuracy: 0.895247\n",
      "train_loss: 0.132649, train_accuracy: 0.999250\n",
      "test_loss: 0.180338, test_accuracy: 0.895247\n",
      "train_loss: 0.132647, train_accuracy: 0.999250\n",
      "test_loss: 0.180350, test_accuracy: 0.895247\n",
      "train_loss: 0.132645, train_accuracy: 0.999250\n",
      "test_loss: 0.180362, test_accuracy: 0.895247\n",
      "train_loss: 0.132644, train_accuracy: 0.999250\n",
      "test_loss: 0.180373, test_accuracy: 0.895490\n",
      "train_loss: 0.132642, train_accuracy: 0.999250\n",
      "test_loss: 0.180385, test_accuracy: 0.895490\n",
      "train_loss: 0.132640, train_accuracy: 0.999250\n",
      "test_loss: 0.180396, test_accuracy: 0.895490\n",
      "train_loss: 0.132638, train_accuracy: 0.999250\n",
      "test_loss: 0.180408, test_accuracy: 0.895490\n",
      "train_loss: 0.132636, train_accuracy: 0.999250\n",
      "test_loss: 0.180419, test_accuracy: 0.895490\n",
      "train_loss: 0.132634, train_accuracy: 0.999250\n",
      "test_loss: 0.180431, test_accuracy: 0.895490\n",
      "train_loss: 0.132633, train_accuracy: 0.999250\n",
      "test_loss: 0.180442, test_accuracy: 0.895490\n",
      "train_loss: 0.132631, train_accuracy: 0.999250\n",
      "test_loss: 0.180454, test_accuracy: 0.895490\n",
      "train_loss: 0.132629, train_accuracy: 0.999250\n",
      "test_loss: 0.180465, test_accuracy: 0.895490\n",
      "train_loss: 0.132627, train_accuracy: 0.999250\n",
      "test_loss: 0.180477, test_accuracy: 0.895490\n",
      "train_loss: 0.132625, train_accuracy: 0.999250\n",
      "test_loss: 0.180488, test_accuracy: 0.895490\n",
      "train_loss: 0.132624, train_accuracy: 0.999250\n",
      "test_loss: 0.180500, test_accuracy: 0.895490\n",
      "train_loss: 0.132622, train_accuracy: 0.999250\n",
      "test_loss: 0.180511, test_accuracy: 0.895490\n",
      "train_loss: 0.132620, train_accuracy: 0.999250\n",
      "test_loss: 0.180522, test_accuracy: 0.895490\n",
      "train_loss: 0.132618, train_accuracy: 0.999250\n",
      "test_loss: 0.180534, test_accuracy: 0.895490\n",
      "train_loss: 0.132616, train_accuracy: 0.999250\n",
      "test_loss: 0.180545, test_accuracy: 0.895490\n",
      "train_loss: 0.132615, train_accuracy: 0.999250\n",
      "test_loss: 0.180556, test_accuracy: 0.895490\n",
      "train_loss: 0.132613, train_accuracy: 0.999250\n",
      "test_loss: 0.180568, test_accuracy: 0.895490\n",
      "train_loss: 0.132611, train_accuracy: 0.999250\n",
      "test_loss: 0.180579, test_accuracy: 0.895490\n",
      "train_loss: 0.132609, train_accuracy: 0.999250\n",
      "test_loss: 0.180590, test_accuracy: 0.895490\n",
      "train_loss: 0.132608, train_accuracy: 0.999250\n",
      "test_loss: 0.180602, test_accuracy: 0.895490\n",
      "train_loss: 0.132606, train_accuracy: 0.999250\n",
      "test_loss: 0.180613, test_accuracy: 0.895490\n",
      "train_loss: 0.132604, train_accuracy: 0.999250\n",
      "test_loss: 0.180624, test_accuracy: 0.895490\n",
      "train_loss: 0.132602, train_accuracy: 0.999250\n",
      "test_loss: 0.180635, test_accuracy: 0.895490\n",
      "train_loss: 0.132601, train_accuracy: 0.999250\n",
      "test_loss: 0.180646, test_accuracy: 0.895490\n",
      "train_loss: 0.132599, train_accuracy: 0.999250\n",
      "test_loss: 0.180657, test_accuracy: 0.895490\n",
      "train_loss: 0.132597, train_accuracy: 0.999250\n",
      "test_loss: 0.180669, test_accuracy: 0.895490\n",
      "train_loss: 0.132596, train_accuracy: 0.999250\n",
      "test_loss: 0.180680, test_accuracy: 0.895490\n",
      "train_loss: 0.132594, train_accuracy: 0.999250\n",
      "test_loss: 0.180691, test_accuracy: 0.895490\n",
      "train_loss: 0.132592, train_accuracy: 0.999250\n",
      "test_loss: 0.180702, test_accuracy: 0.895490\n",
      "train_loss: 0.132591, train_accuracy: 0.999250\n",
      "test_loss: 0.180713, test_accuracy: 0.895490\n",
      "train_loss: 0.132589, train_accuracy: 0.999250\n",
      "test_loss: 0.180724, test_accuracy: 0.895490\n",
      "train_loss: 0.132587, train_accuracy: 0.999250\n",
      "test_loss: 0.180735, test_accuracy: 0.895490\n",
      "train_loss: 0.132585, train_accuracy: 0.999250\n",
      "test_loss: 0.180746, test_accuracy: 0.895490\n",
      "train_loss: 0.132584, train_accuracy: 0.999250\n",
      "test_loss: 0.180757, test_accuracy: 0.895490\n",
      "train_loss: 0.132582, train_accuracy: 0.999250\n",
      "test_loss: 0.180768, test_accuracy: 0.895732\n",
      "train_loss: 0.132580, train_accuracy: 0.999250\n",
      "test_loss: 0.180779, test_accuracy: 0.895732\n",
      "train_loss: 0.132579, train_accuracy: 0.999250\n",
      "test_loss: 0.180790, test_accuracy: 0.895732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.132577, train_accuracy: 0.999250\n",
      "test_loss: 0.180801, test_accuracy: 0.895732\n",
      "train_loss: 0.132575, train_accuracy: 0.999250\n",
      "test_loss: 0.180812, test_accuracy: 0.895732\n",
      "train_loss: 0.132574, train_accuracy: 0.999250\n",
      "test_loss: 0.180823, test_accuracy: 0.895732\n",
      "train_loss: 0.132572, train_accuracy: 0.999250\n",
      "test_loss: 0.180834, test_accuracy: 0.895732\n",
      "train_loss: 0.132570, train_accuracy: 0.999250\n",
      "test_loss: 0.180845, test_accuracy: 0.895975\n",
      "train_loss: 0.132569, train_accuracy: 0.999250\n",
      "test_loss: 0.180856, test_accuracy: 0.896217\n",
      "train_loss: 0.132567, train_accuracy: 0.999250\n",
      "test_loss: 0.180867, test_accuracy: 0.896217\n",
      "train_loss: 0.132566, train_accuracy: 0.999250\n",
      "test_loss: 0.180878, test_accuracy: 0.896217\n",
      "train_loss: 0.132564, train_accuracy: 0.999250\n",
      "test_loss: 0.180888, test_accuracy: 0.896217\n",
      "train_loss: 0.132562, train_accuracy: 0.999250\n",
      "test_loss: 0.180899, test_accuracy: 0.896217\n",
      "train_loss: 0.132561, train_accuracy: 0.999250\n",
      "test_loss: 0.180910, test_accuracy: 0.896217\n",
      "train_loss: 0.132559, train_accuracy: 0.999250\n",
      "test_loss: 0.180921, test_accuracy: 0.896217\n",
      "train_loss: 0.132558, train_accuracy: 0.999250\n",
      "test_loss: 0.180932, test_accuracy: 0.896460\n",
      "train_loss: 0.132556, train_accuracy: 0.999250\n",
      "test_loss: 0.180942, test_accuracy: 0.896460\n",
      "train_loss: 0.132554, train_accuracy: 0.999250\n",
      "test_loss: 0.180953, test_accuracy: 0.896460\n",
      "train_loss: 0.132553, train_accuracy: 0.999250\n",
      "test_loss: 0.180964, test_accuracy: 0.896460\n",
      "train_loss: 0.132551, train_accuracy: 0.999250\n",
      "test_loss: 0.180975, test_accuracy: 0.896460\n",
      "train_loss: 0.132550, train_accuracy: 0.999250\n",
      "test_loss: 0.180985, test_accuracy: 0.896460\n",
      "train_loss: 0.132548, train_accuracy: 0.999250\n",
      "test_loss: 0.180996, test_accuracy: 0.896460\n",
      "train_loss: 0.132547, train_accuracy: 0.999250\n",
      "test_loss: 0.181007, test_accuracy: 0.896460\n",
      "train_loss: 0.132545, train_accuracy: 0.999250\n",
      "test_loss: 0.181017, test_accuracy: 0.896460\n",
      "train_loss: 0.132543, train_accuracy: 0.999250\n",
      "test_loss: 0.181028, test_accuracy: 0.896460\n",
      "train_loss: 0.132542, train_accuracy: 0.999250\n",
      "test_loss: 0.181039, test_accuracy: 0.896460\n",
      "train_loss: 0.132540, train_accuracy: 0.999250\n",
      "test_loss: 0.181049, test_accuracy: 0.896460\n",
      "train_loss: 0.132539, train_accuracy: 0.999250\n",
      "test_loss: 0.181060, test_accuracy: 0.896460\n",
      "train_loss: 0.132537, train_accuracy: 0.999250\n",
      "test_loss: 0.181070, test_accuracy: 0.896460\n",
      "train_loss: 0.132536, train_accuracy: 0.999250\n",
      "test_loss: 0.181081, test_accuracy: 0.896460\n",
      "train_loss: 0.132534, train_accuracy: 0.999250\n",
      "test_loss: 0.181091, test_accuracy: 0.896460\n",
      "train_loss: 0.132533, train_accuracy: 0.999250\n",
      "test_loss: 0.181102, test_accuracy: 0.896460\n",
      "train_loss: 0.132531, train_accuracy: 0.999250\n",
      "test_loss: 0.181112, test_accuracy: 0.896460\n",
      "train_loss: 0.132530, train_accuracy: 0.999250\n",
      "test_loss: 0.181123, test_accuracy: 0.896460\n",
      "train_loss: 0.132528, train_accuracy: 0.999250\n",
      "test_loss: 0.181133, test_accuracy: 0.896460\n",
      "train_loss: 0.132527, train_accuracy: 0.999250\n",
      "test_loss: 0.181144, test_accuracy: 0.896460\n",
      "train_loss: 0.132525, train_accuracy: 0.999250\n",
      "test_loss: 0.181154, test_accuracy: 0.896460\n",
      "train_loss: 0.132524, train_accuracy: 0.999250\n",
      "test_loss: 0.181165, test_accuracy: 0.896460\n",
      "train_loss: 0.132522, train_accuracy: 0.999250\n",
      "test_loss: 0.181175, test_accuracy: 0.896460\n",
      "train_loss: 0.132521, train_accuracy: 0.999250\n",
      "test_loss: 0.181186, test_accuracy: 0.896460\n",
      "train_loss: 0.132519, train_accuracy: 0.999250\n",
      "test_loss: 0.181196, test_accuracy: 0.896460\n",
      "train_loss: 0.132518, train_accuracy: 0.999250\n",
      "test_loss: 0.181206, test_accuracy: 0.896460\n",
      "train_loss: 0.132516, train_accuracy: 0.999250\n",
      "test_loss: 0.181217, test_accuracy: 0.896460\n",
      "train_loss: 0.132515, train_accuracy: 0.999250\n",
      "test_loss: 0.181227, test_accuracy: 0.896460\n",
      "train_loss: 0.132514, train_accuracy: 0.999250\n",
      "test_loss: 0.181237, test_accuracy: 0.895975\n",
      "train_loss: 0.132512, train_accuracy: 0.999250\n",
      "test_loss: 0.181248, test_accuracy: 0.895975\n",
      "train_loss: 0.132511, train_accuracy: 0.999250\n",
      "test_loss: 0.181258, test_accuracy: 0.895975\n",
      "train_loss: 0.132509, train_accuracy: 0.999250\n",
      "test_loss: 0.181268, test_accuracy: 0.895975\n",
      "train_loss: 0.132508, train_accuracy: 0.999250\n",
      "test_loss: 0.181278, test_accuracy: 0.895975\n",
      "train_loss: 0.132506, train_accuracy: 0.999250\n",
      "test_loss: 0.181289, test_accuracy: 0.895975\n",
      "train_loss: 0.132505, train_accuracy: 0.999250\n",
      "test_loss: 0.181299, test_accuracy: 0.895975\n",
      "train_loss: 0.132503, train_accuracy: 0.999250\n",
      "test_loss: 0.181309, test_accuracy: 0.895975\n",
      "train_loss: 0.132502, train_accuracy: 0.999250\n",
      "test_loss: 0.181319, test_accuracy: 0.895975\n",
      "train_loss: 0.132501, train_accuracy: 0.999250\n",
      "test_loss: 0.181330, test_accuracy: 0.895975\n",
      "train_loss: 0.132499, train_accuracy: 0.999250\n",
      "test_loss: 0.181340, test_accuracy: 0.895975\n",
      "train_loss: 0.132498, train_accuracy: 0.999250\n",
      "test_loss: 0.181350, test_accuracy: 0.895975\n",
      "train_loss: 0.132496, train_accuracy: 0.999250\n",
      "test_loss: 0.181360, test_accuracy: 0.895975\n",
      "train_loss: 0.132495, train_accuracy: 0.999250\n",
      "test_loss: 0.181370, test_accuracy: 0.895975\n",
      "train_loss: 0.132494, train_accuracy: 0.999250\n",
      "test_loss: 0.181380, test_accuracy: 0.895975\n",
      "train_loss: 0.132492, train_accuracy: 0.999250\n",
      "test_loss: 0.181390, test_accuracy: 0.895975\n",
      "train_loss: 0.132491, train_accuracy: 0.999250\n",
      "test_loss: 0.181400, test_accuracy: 0.895975\n",
      "train_loss: 0.132490, train_accuracy: 0.999250\n",
      "test_loss: 0.181411, test_accuracy: 0.895975\n",
      "train_loss: 0.132488, train_accuracy: 0.999250\n",
      "test_loss: 0.181421, test_accuracy: 0.895975\n",
      "train_loss: 0.132487, train_accuracy: 0.999250\n",
      "test_loss: 0.181431, test_accuracy: 0.895975\n",
      "train_loss: 0.132485, train_accuracy: 0.999250\n",
      "test_loss: 0.181441, test_accuracy: 0.895975\n",
      "train_loss: 0.132484, train_accuracy: 0.999250\n",
      "test_loss: 0.181451, test_accuracy: 0.895975\n",
      "train_loss: 0.132483, train_accuracy: 0.999250\n",
      "test_loss: 0.181461, test_accuracy: 0.895975\n",
      "train_loss: 0.132481, train_accuracy: 0.999250\n",
      "test_loss: 0.181471, test_accuracy: 0.895975\n",
      "train_loss: 0.132480, train_accuracy: 0.999250\n",
      "test_loss: 0.181481, test_accuracy: 0.895975\n",
      "train_loss: 0.132479, train_accuracy: 0.999250\n",
      "test_loss: 0.181491, test_accuracy: 0.895975\n",
      "train_loss: 0.132477, train_accuracy: 0.999250\n",
      "test_loss: 0.181501, test_accuracy: 0.895975\n",
      "train_loss: 0.132476, train_accuracy: 0.999250\n",
      "test_loss: 0.181511, test_accuracy: 0.895975\n",
      "train_loss: 0.132475, train_accuracy: 0.999250\n",
      "test_loss: 0.181521, test_accuracy: 0.895490\n",
      "train_loss: 0.132473, train_accuracy: 0.999250\n",
      "test_loss: 0.181530, test_accuracy: 0.895490\n",
      "train_loss: 0.132472, train_accuracy: 0.999250\n",
      "test_loss: 0.181540, test_accuracy: 0.895490\n",
      "train_loss: 0.132471, train_accuracy: 0.999250\n",
      "test_loss: 0.181550, test_accuracy: 0.895005\n",
      "train_loss: 0.132469, train_accuracy: 0.999250\n",
      "test_loss: 0.181560, test_accuracy: 0.895005\n",
      "train_loss: 0.132468, train_accuracy: 0.999250\n",
      "test_loss: 0.181570, test_accuracy: 0.895005\n",
      "train_loss: 0.132467, train_accuracy: 0.999250\n",
      "test_loss: 0.181580, test_accuracy: 0.895005\n",
      "train_loss: 0.132465, train_accuracy: 0.999250\n",
      "test_loss: 0.181590, test_accuracy: 0.895005\n",
      "train_loss: 0.132464, train_accuracy: 0.999250\n",
      "test_loss: 0.181599, test_accuracy: 0.895005\n",
      "train_loss: 0.132463, train_accuracy: 0.999250\n",
      "test_loss: 0.181609, test_accuracy: 0.895005\n",
      "train_loss: 0.132462, train_accuracy: 0.999250\n",
      "test_loss: 0.181619, test_accuracy: 0.895005\n",
      "train_loss: 0.132460, train_accuracy: 0.999250\n",
      "test_loss: 0.181629, test_accuracy: 0.895005\n",
      "train_loss: 0.132459, train_accuracy: 0.999250\n",
      "test_loss: 0.181638, test_accuracy: 0.895005\n",
      "train_loss: 0.132458, train_accuracy: 0.999250\n",
      "test_loss: 0.181648, test_accuracy: 0.895005\n",
      "train_loss: 0.132456, train_accuracy: 0.999250\n",
      "test_loss: 0.181658, test_accuracy: 0.895005\n",
      "train_loss: 0.132455, train_accuracy: 0.999250\n",
      "test_loss: 0.181668, test_accuracy: 0.895005\n",
      "train_loss: 0.132454, train_accuracy: 0.999250\n",
      "test_loss: 0.181677, test_accuracy: 0.895005\n",
      "train_loss: 0.132453, train_accuracy: 0.999250\n",
      "test_loss: 0.181687, test_accuracy: 0.895005\n",
      "train_loss: 0.132451, train_accuracy: 0.999250\n",
      "test_loss: 0.181697, test_accuracy: 0.895005\n",
      "train_loss: 0.132450, train_accuracy: 0.999250\n",
      "test_loss: 0.181706, test_accuracy: 0.895005\n",
      "train_loss: 0.132449, train_accuracy: 0.999250\n",
      "test_loss: 0.181716, test_accuracy: 0.895005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.132448, train_accuracy: 0.999250\n",
      "test_loss: 0.181726, test_accuracy: 0.895005\n",
      "train_loss: 0.132446, train_accuracy: 0.999250\n",
      "test_loss: 0.181735, test_accuracy: 0.895005\n",
      "train_loss: 0.132445, train_accuracy: 0.999250\n",
      "test_loss: 0.181745, test_accuracy: 0.895005\n",
      "train_loss: 0.132444, train_accuracy: 0.999250\n",
      "test_loss: 0.181755, test_accuracy: 0.895005\n",
      "train_loss: 0.132443, train_accuracy: 0.999250\n",
      "test_loss: 0.181764, test_accuracy: 0.895005\n",
      "train_loss: 0.132442, train_accuracy: 0.999250\n",
      "test_loss: 0.181774, test_accuracy: 0.895005\n",
      "train_loss: 0.132440, train_accuracy: 0.999250\n",
      "test_loss: 0.181783, test_accuracy: 0.895005\n",
      "train_loss: 0.132439, train_accuracy: 0.999250\n",
      "test_loss: 0.181793, test_accuracy: 0.895005\n",
      "train_loss: 0.132438, train_accuracy: 0.999250\n",
      "test_loss: 0.181802, test_accuracy: 0.895005\n",
      "train_loss: 0.132437, train_accuracy: 0.999250\n",
      "test_loss: 0.181812, test_accuracy: 0.895005\n",
      "train_loss: 0.132435, train_accuracy: 0.999250\n",
      "test_loss: 0.181821, test_accuracy: 0.895005\n",
      "train_loss: 0.132434, train_accuracy: 0.999250\n",
      "test_loss: 0.181831, test_accuracy: 0.895005\n",
      "train_loss: 0.132433, train_accuracy: 0.999250\n",
      "test_loss: 0.181840, test_accuracy: 0.895005\n",
      "train_loss: 0.132432, train_accuracy: 0.999250\n",
      "test_loss: 0.181850, test_accuracy: 0.895005\n",
      "train_loss: 0.132431, train_accuracy: 0.999250\n",
      "test_loss: 0.181859, test_accuracy: 0.895005\n",
      "train_loss: 0.132430, train_accuracy: 0.999250\n",
      "test_loss: 0.181869, test_accuracy: 0.895005\n",
      "train_loss: 0.132428, train_accuracy: 0.999250\n",
      "test_loss: 0.181878, test_accuracy: 0.895005\n",
      "train_loss: 0.132427, train_accuracy: 0.999250\n",
      "test_loss: 0.181887, test_accuracy: 0.895005\n",
      "train_loss: 0.132426, train_accuracy: 0.999250\n",
      "test_loss: 0.181897, test_accuracy: 0.895005\n",
      "train_loss: 0.132425, train_accuracy: 0.999250\n",
      "test_loss: 0.181906, test_accuracy: 0.895005\n",
      "train_loss: 0.132424, train_accuracy: 0.999250\n",
      "test_loss: 0.181916, test_accuracy: 0.895005\n",
      "train_loss: 0.132422, train_accuracy: 0.999250\n",
      "test_loss: 0.181925, test_accuracy: 0.895005\n",
      "train_loss: 0.132421, train_accuracy: 0.999250\n",
      "test_loss: 0.181934, test_accuracy: 0.895005\n",
      "train_loss: 0.132420, train_accuracy: 0.999250\n",
      "test_loss: 0.181944, test_accuracy: 0.895005\n",
      "train_loss: 0.132419, train_accuracy: 0.999250\n",
      "test_loss: 0.181953, test_accuracy: 0.895005\n",
      "train_loss: 0.132418, train_accuracy: 0.999250\n",
      "test_loss: 0.181962, test_accuracy: 0.895005\n",
      "train_loss: 0.132417, train_accuracy: 0.999250\n",
      "test_loss: 0.181971, test_accuracy: 0.895005\n",
      "train_loss: 0.132416, train_accuracy: 0.999250\n",
      "test_loss: 0.181981, test_accuracy: 0.895005\n",
      "train_loss: 0.132414, train_accuracy: 0.999250\n",
      "test_loss: 0.181990, test_accuracy: 0.895005\n",
      "train_loss: 0.132413, train_accuracy: 0.999250\n",
      "test_loss: 0.181999, test_accuracy: 0.895005\n",
      "train_loss: 0.132412, train_accuracy: 0.999250\n",
      "test_loss: 0.182008, test_accuracy: 0.895005\n",
      "train_loss: 0.132411, train_accuracy: 0.999250\n",
      "test_loss: 0.182018, test_accuracy: 0.895005\n",
      "train_loss: 0.132410, train_accuracy: 0.999250\n",
      "test_loss: 0.182027, test_accuracy: 0.895005\n",
      "train_loss: 0.132409, train_accuracy: 0.999250\n",
      "test_loss: 0.182036, test_accuracy: 0.895005\n",
      "train_loss: 0.132408, train_accuracy: 0.999250\n",
      "test_loss: 0.182045, test_accuracy: 0.895005\n",
      "train_loss: 0.132407, train_accuracy: 0.999250\n",
      "test_loss: 0.182054, test_accuracy: 0.895005\n",
      "train_loss: 0.132406, train_accuracy: 0.999250\n",
      "test_loss: 0.182064, test_accuracy: 0.895005\n",
      "train_loss: 0.132404, train_accuracy: 0.999250\n",
      "test_loss: 0.182073, test_accuracy: 0.895005\n",
      "train_loss: 0.132403, train_accuracy: 0.999250\n",
      "test_loss: 0.182082, test_accuracy: 0.895005\n",
      "train_loss: 0.132402, train_accuracy: 0.999250\n",
      "test_loss: 0.182091, test_accuracy: 0.895005\n",
      "train_loss: 0.132401, train_accuracy: 0.999250\n",
      "test_loss: 0.182100, test_accuracy: 0.895005\n",
      "train_loss: 0.132400, train_accuracy: 0.999250\n",
      "test_loss: 0.182109, test_accuracy: 0.895005\n",
      "train_loss: 0.132399, train_accuracy: 0.999250\n",
      "test_loss: 0.182118, test_accuracy: 0.895005\n",
      "train_loss: 0.132398, train_accuracy: 0.999250\n",
      "test_loss: 0.182127, test_accuracy: 0.895005\n",
      "train_loss: 0.132397, train_accuracy: 0.999250\n",
      "test_loss: 0.182136, test_accuracy: 0.895005\n",
      "train_loss: 0.132396, train_accuracy: 0.999250\n",
      "test_loss: 0.182145, test_accuracy: 0.895005\n",
      "train_loss: 0.132395, train_accuracy: 0.999250\n",
      "test_loss: 0.182154, test_accuracy: 0.895005\n",
      "train_loss: 0.132394, train_accuracy: 0.999250\n",
      "test_loss: 0.182163, test_accuracy: 0.895005\n",
      "train_loss: 0.132393, train_accuracy: 0.999250\n",
      "test_loss: 0.182173, test_accuracy: 0.895005\n",
      "train_loss: 0.132392, train_accuracy: 0.999250\n",
      "test_loss: 0.182181, test_accuracy: 0.895005\n",
      "train_loss: 0.132390, train_accuracy: 0.999250\n",
      "test_loss: 0.182190, test_accuracy: 0.895005\n",
      "train_loss: 0.132390, train_accuracy: 0.999250\n",
      "test_loss: 0.182199, test_accuracy: 0.895005\n",
      "train_loss: 0.132388, train_accuracy: 0.999250\n",
      "test_loss: 0.182208, test_accuracy: 0.895005\n",
      "train_loss: 0.132387, train_accuracy: 0.999250\n",
      "test_loss: 0.182217, test_accuracy: 0.895005\n",
      "train_loss: 0.132386, train_accuracy: 0.999250\n",
      "test_loss: 0.182226, test_accuracy: 0.895005\n",
      "train_loss: 0.132385, train_accuracy: 0.999250\n",
      "test_loss: 0.182235, test_accuracy: 0.895005\n",
      "train_loss: 0.132384, train_accuracy: 0.999250\n",
      "test_loss: 0.182244, test_accuracy: 0.895005\n",
      "train_loss: 0.132383, train_accuracy: 0.999250\n",
      "test_loss: 0.182253, test_accuracy: 0.895005\n",
      "train_loss: 0.132382, train_accuracy: 0.999250\n",
      "test_loss: 0.182262, test_accuracy: 0.895005\n",
      "train_loss: 0.132381, train_accuracy: 0.999250\n",
      "test_loss: 0.182271, test_accuracy: 0.895005\n",
      "train_loss: 0.132380, train_accuracy: 0.999250\n",
      "test_loss: 0.182280, test_accuracy: 0.895005\n",
      "train_loss: 0.132379, train_accuracy: 0.999250\n",
      "test_loss: 0.182288, test_accuracy: 0.895005\n",
      "train_loss: 0.132378, train_accuracy: 0.999250\n",
      "test_loss: 0.182297, test_accuracy: 0.895005\n",
      "train_loss: 0.132377, train_accuracy: 0.999250\n",
      "test_loss: 0.182306, test_accuracy: 0.895005\n",
      "train_loss: 0.132376, train_accuracy: 0.999250\n",
      "test_loss: 0.182315, test_accuracy: 0.895005\n",
      "train_loss: 0.132375, train_accuracy: 0.999250\n",
      "test_loss: 0.182324, test_accuracy: 0.895005\n",
      "train_loss: 0.132374, train_accuracy: 0.999250\n",
      "test_loss: 0.182332, test_accuracy: 0.895005\n",
      "train_loss: 0.132373, train_accuracy: 0.999250\n",
      "test_loss: 0.182341, test_accuracy: 0.895005\n",
      "train_loss: 0.132372, train_accuracy: 0.999250\n",
      "test_loss: 0.182350, test_accuracy: 0.895005\n",
      "train_loss: 0.132371, train_accuracy: 0.999250\n",
      "test_loss: 0.182359, test_accuracy: 0.894520\n",
      "train_loss: 0.132370, train_accuracy: 0.999250\n",
      "test_loss: 0.182367, test_accuracy: 0.894520\n",
      "train_loss: 0.132369, train_accuracy: 0.999250\n",
      "test_loss: 0.182376, test_accuracy: 0.894520\n",
      "train_loss: 0.132368, train_accuracy: 0.999250\n",
      "test_loss: 0.182385, test_accuracy: 0.894035\n",
      "train_loss: 0.132367, train_accuracy: 0.999250\n",
      "test_loss: 0.182394, test_accuracy: 0.894035\n",
      "train_loss: 0.132366, train_accuracy: 0.999250\n",
      "test_loss: 0.182402, test_accuracy: 0.894035\n",
      "train_loss: 0.132365, train_accuracy: 0.999250\n",
      "test_loss: 0.182411, test_accuracy: 0.894035\n",
      "train_loss: 0.132364, train_accuracy: 0.999250\n",
      "test_loss: 0.182420, test_accuracy: 0.894035\n",
      "train_loss: 0.132363, train_accuracy: 0.999250\n",
      "test_loss: 0.182428, test_accuracy: 0.894035\n",
      "train_loss: 0.132362, train_accuracy: 0.999250\n",
      "test_loss: 0.182437, test_accuracy: 0.894035\n",
      "train_loss: 0.132361, train_accuracy: 0.999250\n",
      "test_loss: 0.182446, test_accuracy: 0.894035\n",
      "train_loss: 0.132360, train_accuracy: 0.999250\n",
      "test_loss: 0.182454, test_accuracy: 0.894035\n",
      "train_loss: 0.132360, train_accuracy: 0.999250\n",
      "test_loss: 0.182463, test_accuracy: 0.894035\n",
      "train_loss: 0.132359, train_accuracy: 0.999250\n",
      "test_loss: 0.182471, test_accuracy: 0.894035\n",
      "train_loss: 0.132358, train_accuracy: 0.999250\n",
      "test_loss: 0.182480, test_accuracy: 0.894035\n",
      "train_loss: 0.132357, train_accuracy: 0.999250\n",
      "test_loss: 0.182489, test_accuracy: 0.894035\n",
      "train_loss: 0.132356, train_accuracy: 0.999250\n",
      "test_loss: 0.182497, test_accuracy: 0.894035\n",
      "train_loss: 0.132355, train_accuracy: 0.999250\n",
      "test_loss: 0.182506, test_accuracy: 0.894035\n",
      "train_loss: 0.132354, train_accuracy: 0.999250\n",
      "test_loss: 0.182514, test_accuracy: 0.894035\n",
      "train_loss: 0.132353, train_accuracy: 0.999250\n",
      "test_loss: 0.182523, test_accuracy: 0.894035\n",
      "train_loss: 0.132352, train_accuracy: 0.999250\n",
      "test_loss: 0.182531, test_accuracy: 0.894035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.132351, train_accuracy: 0.999250\n",
      "test_loss: 0.182540, test_accuracy: 0.894035\n",
      "train_loss: 0.132350, train_accuracy: 0.999250\n",
      "test_loss: 0.182548, test_accuracy: 0.894035\n",
      "train_loss: 0.132349, train_accuracy: 0.999250\n",
      "test_loss: 0.182557, test_accuracy: 0.894035\n",
      "train_loss: 0.132348, train_accuracy: 0.999250\n",
      "test_loss: 0.182565, test_accuracy: 0.894035\n",
      "train_loss: 0.132347, train_accuracy: 0.999250\n",
      "test_loss: 0.182574, test_accuracy: 0.894035\n",
      "train_loss: 0.132347, train_accuracy: 0.999250\n",
      "test_loss: 0.182582, test_accuracy: 0.894035\n",
      "train_loss: 0.132346, train_accuracy: 0.999250\n",
      "test_loss: 0.182590, test_accuracy: 0.894035\n",
      "train_loss: 0.132345, train_accuracy: 0.999250\n",
      "test_loss: 0.182599, test_accuracy: 0.894035\n",
      "train_loss: 0.132344, train_accuracy: 0.999250\n",
      "test_loss: 0.182607, test_accuracy: 0.894035\n",
      "train_loss: 0.132343, train_accuracy: 0.999250\n",
      "test_loss: 0.182616, test_accuracy: 0.894035\n",
      "train_loss: 0.132342, train_accuracy: 0.999250\n",
      "test_loss: 0.182624, test_accuracy: 0.894035\n",
      "train_loss: 0.132341, train_accuracy: 0.999250\n",
      "test_loss: 0.182632, test_accuracy: 0.894035\n",
      "train_loss: 0.132340, train_accuracy: 0.999250\n",
      "test_loss: 0.182641, test_accuracy: 0.894035\n",
      "train_loss: 0.132339, train_accuracy: 0.999250\n",
      "test_loss: 0.182649, test_accuracy: 0.894035\n",
      "train_loss: 0.132338, train_accuracy: 0.999250\n",
      "test_loss: 0.182657, test_accuracy: 0.894035\n",
      "train_loss: 0.132338, train_accuracy: 0.999250\n",
      "test_loss: 0.182666, test_accuracy: 0.894035\n",
      "train_loss: 0.132337, train_accuracy: 0.999250\n",
      "test_loss: 0.182674, test_accuracy: 0.894035\n",
      "train_loss: 0.132336, train_accuracy: 0.999250\n",
      "test_loss: 0.182682, test_accuracy: 0.894035\n",
      "train_loss: 0.132335, train_accuracy: 0.999250\n",
      "test_loss: 0.182691, test_accuracy: 0.894035\n",
      "train_loss: 0.132334, train_accuracy: 0.999250\n",
      "test_loss: 0.182699, test_accuracy: 0.894035\n",
      "train_loss: 0.132333, train_accuracy: 0.999250\n",
      "test_loss: 0.182707, test_accuracy: 0.894035\n",
      "train_loss: 0.132333, train_accuracy: 0.999250\n",
      "test_loss: 0.182716, test_accuracy: 0.894035\n",
      "train_loss: 0.132332, train_accuracy: 0.999250\n",
      "test_loss: 0.182724, test_accuracy: 0.894035\n",
      "train_loss: 0.132331, train_accuracy: 0.999250\n",
      "test_loss: 0.182732, test_accuracy: 0.894035\n",
      "train_loss: 0.132330, train_accuracy: 0.999250\n",
      "test_loss: 0.182740, test_accuracy: 0.894035\n",
      "train_loss: 0.132329, train_accuracy: 0.999250\n",
      "test_loss: 0.182748, test_accuracy: 0.894035\n",
      "train_loss: 0.132328, train_accuracy: 0.999250\n",
      "test_loss: 0.182757, test_accuracy: 0.894035\n",
      "train_loss: 0.132328, train_accuracy: 0.999250\n",
      "test_loss: 0.182765, test_accuracy: 0.894035\n",
      "train_loss: 0.132327, train_accuracy: 0.999250\n",
      "test_loss: 0.182773, test_accuracy: 0.894035\n",
      "train_loss: 0.132326, train_accuracy: 0.999250\n",
      "test_loss: 0.182781, test_accuracy: 0.894035\n",
      "train_loss: 0.132325, train_accuracy: 0.999250\n",
      "test_loss: 0.182789, test_accuracy: 0.894035\n",
      "train_loss: 0.132324, train_accuracy: 0.999250\n",
      "test_loss: 0.182798, test_accuracy: 0.894035\n",
      "train_loss: 0.132323, train_accuracy: 0.999250\n",
      "test_loss: 0.182806, test_accuracy: 0.893550\n",
      "train_loss: 0.132323, train_accuracy: 0.999250\n",
      "test_loss: 0.182814, test_accuracy: 0.893550\n",
      "train_loss: 0.132322, train_accuracy: 0.999250\n",
      "test_loss: 0.182822, test_accuracy: 0.893550\n",
      "train_loss: 0.132321, train_accuracy: 0.999250\n",
      "test_loss: 0.182830, test_accuracy: 0.893065\n",
      "train_loss: 0.132320, train_accuracy: 0.999250\n",
      "test_loss: 0.182838, test_accuracy: 0.893065\n",
      "train_loss: 0.132319, train_accuracy: 0.999250\n",
      "test_loss: 0.182846, test_accuracy: 0.893065\n",
      "train_loss: 0.132319, train_accuracy: 0.999250\n",
      "test_loss: 0.182854, test_accuracy: 0.893065\n",
      "train_loss: 0.132318, train_accuracy: 0.999250\n",
      "test_loss: 0.182862, test_accuracy: 0.893065\n",
      "train_loss: 0.132317, train_accuracy: 0.999250\n",
      "test_loss: 0.182870, test_accuracy: 0.893065\n",
      "train_loss: 0.132316, train_accuracy: 0.999250\n",
      "test_loss: 0.182878, test_accuracy: 0.893065\n",
      "train_loss: 0.132315, train_accuracy: 0.999250\n",
      "test_loss: 0.182887, test_accuracy: 0.893065\n",
      "train_loss: 0.132315, train_accuracy: 0.999250\n",
      "test_loss: 0.182895, test_accuracy: 0.893065\n",
      "train_loss: 0.132314, train_accuracy: 0.999250\n",
      "test_loss: 0.182902, test_accuracy: 0.893065\n",
      "train_loss: 0.132313, train_accuracy: 0.999250\n",
      "test_loss: 0.182911, test_accuracy: 0.893065\n",
      "train_loss: 0.132312, train_accuracy: 0.999250\n",
      "test_loss: 0.182919, test_accuracy: 0.893065\n",
      "train_loss: 0.132311, train_accuracy: 0.999250\n",
      "test_loss: 0.182926, test_accuracy: 0.893065\n",
      "train_loss: 0.132311, train_accuracy: 0.999250\n",
      "test_loss: 0.182934, test_accuracy: 0.893065\n",
      "train_loss: 0.132310, train_accuracy: 0.999250\n",
      "test_loss: 0.182942, test_accuracy: 0.893065\n",
      "train_loss: 0.132309, train_accuracy: 0.999250\n",
      "test_loss: 0.182950, test_accuracy: 0.893065\n",
      "train_loss: 0.132308, train_accuracy: 0.999250\n",
      "test_loss: 0.182958, test_accuracy: 0.893065\n",
      "train_loss: 0.132308, train_accuracy: 0.999250\n",
      "test_loss: 0.182966, test_accuracy: 0.893065\n",
      "train_loss: 0.132307, train_accuracy: 0.999250\n",
      "test_loss: 0.182974, test_accuracy: 0.893065\n",
      "train_loss: 0.132306, train_accuracy: 0.999250\n",
      "test_loss: 0.182982, test_accuracy: 0.893065\n",
      "train_loss: 0.132305, train_accuracy: 0.999250\n",
      "test_loss: 0.182990, test_accuracy: 0.893065\n",
      "train_loss: 0.132305, train_accuracy: 0.999250\n",
      "test_loss: 0.182998, test_accuracy: 0.893065\n",
      "train_loss: 0.132304, train_accuracy: 0.999250\n",
      "test_loss: 0.183006, test_accuracy: 0.893065\n",
      "train_loss: 0.132303, train_accuracy: 0.999250\n",
      "test_loss: 0.183014, test_accuracy: 0.893065\n",
      "train_loss: 0.132302, train_accuracy: 0.999250\n",
      "test_loss: 0.183021, test_accuracy: 0.893065\n",
      "train_loss: 0.132302, train_accuracy: 0.999250\n",
      "test_loss: 0.183029, test_accuracy: 0.893065\n",
      "train_loss: 0.132301, train_accuracy: 0.999250\n",
      "test_loss: 0.183037, test_accuracy: 0.893065\n",
      "train_loss: 0.132300, train_accuracy: 0.999250\n",
      "test_loss: 0.183045, test_accuracy: 0.893065\n",
      "train_loss: 0.132299, train_accuracy: 0.999250\n",
      "test_loss: 0.183053, test_accuracy: 0.893065\n",
      "train_loss: 0.132299, train_accuracy: 0.999250\n",
      "test_loss: 0.183061, test_accuracy: 0.893065\n",
      "train_loss: 0.132298, train_accuracy: 0.999250\n",
      "test_loss: 0.183068, test_accuracy: 0.893065\n",
      "train_loss: 0.132297, train_accuracy: 0.999250\n",
      "test_loss: 0.183076, test_accuracy: 0.893065\n",
      "train_loss: 0.132297, train_accuracy: 0.999250\n",
      "test_loss: 0.183084, test_accuracy: 0.893065\n",
      "train_loss: 0.132296, train_accuracy: 0.999250\n",
      "test_loss: 0.183092, test_accuracy: 0.893065\n",
      "train_loss: 0.132295, train_accuracy: 0.999250\n",
      "test_loss: 0.183099, test_accuracy: 0.893065\n",
      "train_loss: 0.132294, train_accuracy: 0.999250\n",
      "test_loss: 0.183107, test_accuracy: 0.893065\n",
      "train_loss: 0.132294, train_accuracy: 0.999250\n",
      "test_loss: 0.183115, test_accuracy: 0.893065\n",
      "train_loss: 0.132293, train_accuracy: 0.999250\n",
      "test_loss: 0.183122, test_accuracy: 0.893065\n",
      "train_loss: 0.132292, train_accuracy: 0.999250\n",
      "test_loss: 0.183130, test_accuracy: 0.893065\n",
      "train_loss: 0.132292, train_accuracy: 0.999250\n",
      "test_loss: 0.183138, test_accuracy: 0.893065\n",
      "train_loss: 0.132291, train_accuracy: 0.999250\n",
      "test_loss: 0.183146, test_accuracy: 0.893065\n",
      "train_loss: 0.132290, train_accuracy: 0.999250\n",
      "test_loss: 0.183153, test_accuracy: 0.893065\n",
      "train_loss: 0.132290, train_accuracy: 0.999250\n",
      "test_loss: 0.183161, test_accuracy: 0.893065\n",
      "train_loss: 0.132289, train_accuracy: 0.999250\n",
      "test_loss: 0.183169, test_accuracy: 0.893065\n",
      "train_loss: 0.132288, train_accuracy: 0.999250\n",
      "test_loss: 0.183176, test_accuracy: 0.893065\n",
      "train_loss: 0.132287, train_accuracy: 0.999250\n",
      "test_loss: 0.183184, test_accuracy: 0.893065\n",
      "train_loss: 0.132287, train_accuracy: 0.999250\n",
      "test_loss: 0.183191, test_accuracy: 0.893065\n",
      "train_loss: 0.132286, train_accuracy: 0.999250\n",
      "test_loss: 0.183199, test_accuracy: 0.893065\n",
      "train_loss: 0.132285, train_accuracy: 0.999250\n",
      "test_loss: 0.183207, test_accuracy: 0.893065\n",
      "train_loss: 0.132285, train_accuracy: 0.999250\n",
      "test_loss: 0.183214, test_accuracy: 0.893065\n",
      "train_loss: 0.132284, train_accuracy: 0.999250\n",
      "test_loss: 0.183222, test_accuracy: 0.893065\n",
      "train_loss: 0.132283, train_accuracy: 0.999250\n",
      "test_loss: 0.183230, test_accuracy: 0.893065\n",
      "train_loss: 0.132283, train_accuracy: 0.999250\n",
      "test_loss: 0.183237, test_accuracy: 0.893065\n",
      "train_loss: 0.132282, train_accuracy: 0.999250\n",
      "test_loss: 0.183245, test_accuracy: 0.893065\n",
      "train_loss: 0.132281, train_accuracy: 0.999250\n",
      "test_loss: 0.183252, test_accuracy: 0.893065\n",
      "train_loss: 0.132281, train_accuracy: 0.999250\n",
      "test_loss: 0.183260, test_accuracy: 0.893065\n",
      "train_loss: 0.132280, train_accuracy: 0.999250\n",
      "test_loss: 0.183267, test_accuracy: 0.893065\n",
      "train_loss: 0.132279, train_accuracy: 0.999250\n",
      "test_loss: 0.183275, test_accuracy: 0.893065\n",
      "train_loss: 0.132279, train_accuracy: 0.999250\n",
      "test_loss: 0.183282, test_accuracy: 0.893065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.132278, train_accuracy: 0.999250\n",
      "test_loss: 0.183290, test_accuracy: 0.893065\n",
      "train_loss: 0.132278, train_accuracy: 0.999250\n",
      "test_loss: 0.183297, test_accuracy: 0.893065\n",
      "train_loss: 0.132277, train_accuracy: 0.999250\n",
      "test_loss: 0.183305, test_accuracy: 0.893065\n",
      "train_loss: 0.132276, train_accuracy: 0.999250\n",
      "test_loss: 0.183312, test_accuracy: 0.893065\n",
      "train_loss: 0.132275, train_accuracy: 0.999250\n",
      "test_loss: 0.183320, test_accuracy: 0.893065\n",
      "train_loss: 0.132275, train_accuracy: 0.999250\n",
      "test_loss: 0.183327, test_accuracy: 0.893065\n",
      "train_loss: 0.132274, train_accuracy: 0.999250\n",
      "test_loss: 0.183334, test_accuracy: 0.893065\n",
      "train_loss: 0.132273, train_accuracy: 0.999250\n",
      "test_loss: 0.183342, test_accuracy: 0.893065\n",
      "train_loss: 0.132273, train_accuracy: 0.999250\n",
      "test_loss: 0.183349, test_accuracy: 0.893065\n",
      "train_loss: 0.132272, train_accuracy: 0.999250\n",
      "test_loss: 0.183357, test_accuracy: 0.893065\n",
      "train_loss: 0.132272, train_accuracy: 0.999250\n",
      "test_loss: 0.183364, test_accuracy: 0.893065\n",
      "train_loss: 0.132271, train_accuracy: 0.999250\n",
      "test_loss: 0.183371, test_accuracy: 0.893065\n",
      "train_loss: 0.132270, train_accuracy: 0.999250\n",
      "test_loss: 0.183379, test_accuracy: 0.893065\n",
      "train_loss: 0.132270, train_accuracy: 0.999250\n",
      "test_loss: 0.183386, test_accuracy: 0.893065\n",
      "train_loss: 0.132269, train_accuracy: 0.999250\n",
      "test_loss: 0.183394, test_accuracy: 0.893065\n",
      "train_loss: 0.132269, train_accuracy: 0.999250\n",
      "test_loss: 0.183401, test_accuracy: 0.892580\n",
      "train_loss: 0.132268, train_accuracy: 0.999250\n",
      "test_loss: 0.183408, test_accuracy: 0.892580\n",
      "train_loss: 0.132268, train_accuracy: 0.999250\n",
      "test_loss: 0.183416, test_accuracy: 0.892095\n",
      "train_loss: 0.132267, train_accuracy: 0.999250\n",
      "test_loss: 0.183423, test_accuracy: 0.892095\n",
      "train_loss: 0.132266, train_accuracy: 0.999250\n",
      "test_loss: 0.183430, test_accuracy: 0.892095\n",
      "train_loss: 0.132266, train_accuracy: 0.999250\n",
      "test_loss: 0.183438, test_accuracy: 0.892095\n",
      "train_loss: 0.132265, train_accuracy: 0.999250\n",
      "test_loss: 0.183445, test_accuracy: 0.892095\n",
      "train_loss: 0.132264, train_accuracy: 0.999250\n",
      "test_loss: 0.183452, test_accuracy: 0.892095\n",
      "train_loss: 0.132264, train_accuracy: 0.999250\n",
      "test_loss: 0.183459, test_accuracy: 0.892095\n",
      "train_loss: 0.132263, train_accuracy: 0.999250\n",
      "test_loss: 0.183467, test_accuracy: 0.892095\n",
      "train_loss: 0.132262, train_accuracy: 0.999250\n",
      "test_loss: 0.183474, test_accuracy: 0.892095\n",
      "train_loss: 0.132262, train_accuracy: 0.999250\n",
      "test_loss: 0.183481, test_accuracy: 0.892095\n",
      "train_loss: 0.132261, train_accuracy: 0.999250\n",
      "test_loss: 0.183488, test_accuracy: 0.892095\n",
      "train_loss: 0.132261, train_accuracy: 0.999250\n",
      "test_loss: 0.183496, test_accuracy: 0.892095\n",
      "train_loss: 0.132260, train_accuracy: 0.999250\n",
      "test_loss: 0.183503, test_accuracy: 0.892095\n",
      "train_loss: 0.132260, train_accuracy: 0.999250\n",
      "test_loss: 0.183510, test_accuracy: 0.892095\n",
      "train_loss: 0.132259, train_accuracy: 0.999250\n",
      "test_loss: 0.183517, test_accuracy: 0.892095\n",
      "train_loss: 0.132259, train_accuracy: 0.999250\n",
      "test_loss: 0.183524, test_accuracy: 0.892095\n",
      "train_loss: 0.132258, train_accuracy: 0.999250\n",
      "test_loss: 0.183532, test_accuracy: 0.892095\n",
      "train_loss: 0.132257, train_accuracy: 0.999250\n",
      "test_loss: 0.183539, test_accuracy: 0.892095\n",
      "train_loss: 0.132257, train_accuracy: 0.999250\n",
      "test_loss: 0.183546, test_accuracy: 0.892095\n",
      "train_loss: 0.132256, train_accuracy: 0.999250\n",
      "test_loss: 0.183553, test_accuracy: 0.892095\n",
      "train_loss: 0.132256, train_accuracy: 0.999250\n",
      "test_loss: 0.183560, test_accuracy: 0.892095\n",
      "train_loss: 0.132255, train_accuracy: 0.999250\n",
      "test_loss: 0.183567, test_accuracy: 0.892095\n",
      "train_loss: 0.132255, train_accuracy: 0.999250\n",
      "test_loss: 0.183574, test_accuracy: 0.892095\n",
      "train_loss: 0.132254, train_accuracy: 0.999250\n",
      "test_loss: 0.183582, test_accuracy: 0.892095\n",
      "train_loss: 0.132254, train_accuracy: 0.999250\n",
      "test_loss: 0.183589, test_accuracy: 0.892095\n",
      "train_loss: 0.132253, train_accuracy: 0.999250\n",
      "test_loss: 0.183596, test_accuracy: 0.892095\n",
      "train_loss: 0.132252, train_accuracy: 0.999250\n",
      "test_loss: 0.183603, test_accuracy: 0.892095\n",
      "train_loss: 0.132252, train_accuracy: 0.999250\n",
      "test_loss: 0.183610, test_accuracy: 0.892095\n",
      "train_loss: 0.132251, train_accuracy: 0.999250\n",
      "test_loss: 0.183617, test_accuracy: 0.892095\n",
      "train_loss: 0.132251, train_accuracy: 0.999250\n",
      "test_loss: 0.183624, test_accuracy: 0.892095\n",
      "train_loss: 0.132250, train_accuracy: 0.999250\n",
      "test_loss: 0.183631, test_accuracy: 0.892095\n",
      "train_loss: 0.132250, train_accuracy: 0.999250\n",
      "test_loss: 0.183638, test_accuracy: 0.892095\n",
      "train_loss: 0.132249, train_accuracy: 0.999250\n",
      "test_loss: 0.183645, test_accuracy: 0.892095\n",
      "train_loss: 0.132249, train_accuracy: 0.999250\n",
      "test_loss: 0.183652, test_accuracy: 0.892095\n",
      "train_loss: 0.132248, train_accuracy: 0.999250\n",
      "test_loss: 0.183659, test_accuracy: 0.892095\n",
      "train_loss: 0.132248, train_accuracy: 0.999250\n",
      "test_loss: 0.183666, test_accuracy: 0.892095\n",
      "train_loss: 0.132247, train_accuracy: 0.999250\n",
      "test_loss: 0.183673, test_accuracy: 0.892095\n",
      "train_loss: 0.132247, train_accuracy: 0.999250\n",
      "test_loss: 0.183680, test_accuracy: 0.892095\n",
      "train_loss: 0.132246, train_accuracy: 0.999250\n",
      "test_loss: 0.183687, test_accuracy: 0.892095\n",
      "train_loss: 0.132245, train_accuracy: 0.999250\n",
      "test_loss: 0.183694, test_accuracy: 0.892095\n",
      "train_loss: 0.132245, train_accuracy: 0.999250\n",
      "test_loss: 0.183701, test_accuracy: 0.892095\n",
      "train_loss: 0.132244, train_accuracy: 0.999250\n",
      "test_loss: 0.183708, test_accuracy: 0.892095\n",
      "train_loss: 0.132244, train_accuracy: 0.999250\n",
      "test_loss: 0.183715, test_accuracy: 0.892095\n",
      "train_loss: 0.132243, train_accuracy: 0.999250\n",
      "test_loss: 0.183722, test_accuracy: 0.892095\n",
      "train_loss: 0.132243, train_accuracy: 0.999250\n",
      "test_loss: 0.183729, test_accuracy: 0.892095\n",
      "train_loss: 0.132242, train_accuracy: 0.999250\n",
      "test_loss: 0.183736, test_accuracy: 0.892095\n",
      "train_loss: 0.132242, train_accuracy: 0.999250\n",
      "test_loss: 0.183743, test_accuracy: 0.892095\n",
      "train_loss: 0.132241, train_accuracy: 0.999250\n",
      "test_loss: 0.183749, test_accuracy: 0.892095\n",
      "Sequential training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 250\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "for epoch in range(700):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(E_2_seq, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate initial-training graph\"\"\"\n",
    "logits_seq =  subnet_output(alpha_1, beta_1, X_) \n",
    "#logits_init = subnet_output(alpha_1, beta_1, X_) + subnet_output(alpha_2, beta_2, X_)\n",
    "loss_seq = tf.losses.mean_squared_error(labels=Y_, predictions=logits_seq)\n",
    "accuracy_seq = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y_, axis=1), tf.argmax(logits_seq, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize variables\"\"\"\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.156346, train_accuracy: 0.827250\n",
      "test_loss: 0.356628, test_accuracy: 0.217992\n",
      "train_loss: 0.139132, train_accuracy: 0.827250\n",
      "test_loss: 0.334477, test_accuracy: 0.217992\n",
      "train_loss: 0.127112, train_accuracy: 0.827250\n",
      "test_loss: 0.310640, test_accuracy: 0.217992\n",
      "train_loss: 0.115784, train_accuracy: 0.887250\n",
      "test_loss: 0.287823, test_accuracy: 0.417071\n",
      "train_loss: 0.105274, train_accuracy: 0.965750\n",
      "test_loss: 0.266905, test_accuracy: 0.475994\n",
      "train_loss: 0.096003, train_accuracy: 0.998500\n",
      "test_loss: 0.248398, test_accuracy: 0.500970\n",
      "train_loss: 0.088182, train_accuracy: 0.988000\n",
      "test_loss: 0.232520, test_accuracy: 0.548739\n",
      "train_loss: 0.081778, train_accuracy: 0.982250\n",
      "test_loss: 0.219195, test_accuracy: 0.600630\n",
      "train_loss: 0.076612, train_accuracy: 0.975750\n",
      "test_loss: 0.208148, test_accuracy: 0.650097\n",
      "train_loss: 0.072458, train_accuracy: 0.975250\n",
      "test_loss: 0.199027, test_accuracy: 0.685015\n",
      "train_loss: 0.069101, train_accuracy: 0.975250\n",
      "test_loss: 0.191482, test_accuracy: 0.716052\n",
      "train_loss: 0.066356, train_accuracy: 0.975250\n",
      "test_loss: 0.185201, test_accuracy: 0.735209\n",
      "train_loss: 0.064080, train_accuracy: 0.975250\n",
      "test_loss: 0.179928, test_accuracy: 0.752425\n",
      "train_loss: 0.062161, train_accuracy: 0.975250\n",
      "test_loss: 0.175454, test_accuracy: 0.768429\n",
      "train_loss: 0.060516, train_accuracy: 0.975250\n",
      "test_loss: 0.171619, test_accuracy: 0.784190\n",
      "train_loss: 0.059083, train_accuracy: 0.975250\n",
      "test_loss: 0.168295, test_accuracy: 0.791950\n",
      "train_loss: 0.057814, train_accuracy: 0.975250\n",
      "test_loss: 0.165384, test_accuracy: 0.797284\n",
      "train_loss: 0.056674, train_accuracy: 0.975250\n",
      "test_loss: 0.162809, test_accuracy: 0.803104\n",
      "train_loss: 0.055638, train_accuracy: 0.975250\n",
      "test_loss: 0.160509, test_accuracy: 0.808923\n",
      "train_loss: 0.054686, train_accuracy: 0.975250\n",
      "test_loss: 0.158437, test_accuracy: 0.815228\n",
      "train_loss: 0.053802, train_accuracy: 0.975250\n",
      "test_loss: 0.156556, test_accuracy: 0.819835\n",
      "train_loss: 0.052974, train_accuracy: 0.975250\n",
      "test_loss: 0.154835, test_accuracy: 0.824200\n",
      "train_loss: 0.052194, train_accuracy: 0.975250\n",
      "test_loss: 0.153250, test_accuracy: 0.827837\n",
      "train_loss: 0.051454, train_accuracy: 0.975250\n",
      "test_loss: 0.151783, test_accuracy: 0.832929\n",
      "train_loss: 0.050750, train_accuracy: 0.975250\n",
      "test_loss: 0.150416, test_accuracy: 0.835354\n",
      "train_loss: 0.050075, train_accuracy: 0.975250\n",
      "test_loss: 0.149136, test_accuracy: 0.835354\n",
      "train_loss: 0.049427, train_accuracy: 0.975250\n",
      "test_loss: 0.147934, test_accuracy: 0.836081\n",
      "train_loss: 0.048803, train_accuracy: 0.975250\n",
      "test_loss: 0.146800, test_accuracy: 0.837294\n",
      "train_loss: 0.048200, train_accuracy: 0.975250\n",
      "test_loss: 0.145727, test_accuracy: 0.838991\n",
      "train_loss: 0.047617, train_accuracy: 0.975250\n",
      "test_loss: 0.144707, test_accuracy: 0.840931\n",
      "train_loss: 0.047051, train_accuracy: 0.975250\n",
      "test_loss: 0.143736, test_accuracy: 0.842386\n",
      "train_loss: 0.046502, train_accuracy: 0.975250\n",
      "test_loss: 0.142809, test_accuracy: 0.845053\n",
      "train_loss: 0.045968, train_accuracy: 0.975250\n",
      "test_loss: 0.141923, test_accuracy: 0.846993\n",
      "train_loss: 0.045448, train_accuracy: 0.975250\n",
      "test_loss: 0.141073, test_accuracy: 0.848691\n",
      "train_loss: 0.044941, train_accuracy: 0.975250\n",
      "test_loss: 0.140256, test_accuracy: 0.850630\n",
      "train_loss: 0.044447, train_accuracy: 0.975250\n",
      "test_loss: 0.139471, test_accuracy: 0.852085\n",
      "train_loss: 0.043965, train_accuracy: 0.975250\n",
      "test_loss: 0.138715, test_accuracy: 0.853783\n",
      "train_loss: 0.043494, train_accuracy: 0.975250\n",
      "test_loss: 0.137986, test_accuracy: 0.855238\n",
      "train_loss: 0.043033, train_accuracy: 0.975250\n",
      "test_loss: 0.137281, test_accuracy: 0.855965\n",
      "train_loss: 0.042583, train_accuracy: 0.975250\n",
      "test_loss: 0.136600, test_accuracy: 0.856450\n",
      "Sequential training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sequential training evaluation'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Sequential training\"\"\"\n",
    "batch_size = 250\n",
    "\n",
    "epoch_train_accuracy = []\n",
    "epoch_test_accuracy = []\n",
    "for epoch in range(40):\n",
    "    #pbar = tqdm.tqdm(total=len(x_train), desc='sequential training phase')\n",
    "    for i in range(0, len(x_train_seq), batch_size):\n",
    "        x_batch = x_train_seq[i:i+batch_size]\n",
    "        y_batch = y_train_seq[i:i+batch_size]\n",
    "        if len(x_batch) != batch_size:\n",
    "            break\n",
    "        sess.run(E_1_seq, feed_dict={X_: x_batch, Y: y_batch})\n",
    "        #pbar.update(n=len(x_batch))\n",
    "    '''epoch evaluation'''\n",
    "    [train_loss, train_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_train, Y: y_train})\n",
    "    [test_loss, test_accuracy] = sess.run([loss_seq, accuracy_seq], feed_dict={X_: x_test, Y: y_test})\n",
    "    print('train_loss: %f, train_accuracy: %f' % (train_loss, train_accuracy))\n",
    "    print('test_loss: %f, test_accuracy: %f' % (test_loss, test_accuracy))\n",
    "    epoch_train_accuracy.append(train_accuracy)\n",
    "    epoch_test_accuracy.append(test_accuracy)\n",
    "#sess.run(init_train_graph, feed_dict={X: x_train_init, Y: y_train_init})\n",
    "print(\"Sequential training done\")\n",
    "\n",
    "\"\"\"Sequential training evaluation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7953381f8c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogits_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubnet_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "logits_ = subnet_output(alpha_1, beta_1, X_) \n",
    "logits__ = sess.run(logits_, feed_dict={X: [x_test[4000]]})\n",
    "print(logits__)\n",
    "print(np.argmax(logits__))\n",
    "print(y_test[4000])\n",
    "plt.imshow(x_test[4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_alpha(alpha, size):\n",
    "    tmp = sess.run(alpha)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            plt.subplot(2,5,i*5+j+1)\n",
    "            plt.imshow(np.reshape(tmp[:,i*5+j], [size,size]))\n",
    "\n",
    "def visualize_beta(beta):\n",
    "    tmp = sess.run(beta)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(tmp)\n",
    "    \n",
    "            \n",
    "\"\"\"visualize subnet nodes\"\"\"            \n",
    "visualize_alpha(alpha_1, 10)\n",
    "visualize_beta(beta_1)\n",
    "visualize_alpha(alpha_2, 10)\n",
    "visualize_beta(beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_elm import ML_ELM\n",
    "\n",
    "mlelm1 = ML_ELM(input_size=input_size, output_size=output_size, name='mlelm1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.math.sin(tf.constant([0.9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
